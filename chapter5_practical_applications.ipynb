{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: 実践的応用例\n",
    "\n",
    "## 学習目標\n",
    "- ベイズ線形回帰をMCMCで実装する\n",
    "- ロジスティック回帰のベイズ推定を学ぶ\n",
    "- 階層モデルの構築と推定を理解する\n",
    "- 状態空間モデルへの応用を習得する\n",
    "- 変化点検出問題を解く\n",
    "- 実際のデータを用いた分析を実践する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import expit  # ロジスティック関数\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 ベイズ線形回帰\n",
    "\n",
    "線形回帰モデルに対するベイズ推論をMCMCで実装します。\n",
    "\n",
    "### モデル設定\n",
    "$$y_i = \\mathbf{x}_i^T \\boldsymbol{\\beta} + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "### 事前分布\n",
    "- $\\boldsymbol{\\beta} \\sim N(\\mathbf{0}, \\tau^2 \\mathbf{I})$\n",
    "- $\\sigma^2 \\sim \\text{InvGamma}(a, b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "def generate_regression_data(n_samples=100, n_features=3, noise_std=0.5, seed=42):\n",
    "    \"\"\"\n",
    "    回帰データの生成\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 真の回帰係数\n",
    "    true_beta = np.array([2.0, -1.5, 0.8, 1.2])  # intercept + 3 features\n",
    "    \n",
    "    # 説明変数\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    X = np.column_stack([np.ones(n_samples), X])  # intercept項を追加\n",
    "    \n",
    "    # 目的変数\n",
    "    y = X @ true_beta + np.random.normal(0, noise_std, n_samples)\n",
    "    \n",
    "    return X, y, true_beta, noise_std**2\n",
    "\n",
    "# データ生成\n",
    "X, y, true_beta, true_sigma2 = generate_regression_data()\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(f\"データサイズ: {n_samples} x {n_features}\")\n",
    "print(f\"真の回帰係数: {true_beta}\")\n",
    "print(f\"真の誤差分散: {true_sigma2:.3f}\")\n",
    "\n",
    "# データの可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 目的変数の分布\n",
    "axes[0].hist(y, bins=20, alpha=0.7, density=True)\n",
    "axes[0].set_title('Distribution of y')\n",
    "axes[0].set_xlabel('y')\n",
    "axes[0].set_ylabel('Density')\n",
    "\n",
    "# 説明変数と目的変数の関係（最初の説明変数のみ）\n",
    "axes[1].scatter(X[:, 1], y, alpha=0.6)\n",
    "axes[1].set_title('y vs X1')\n",
    "axes[1].set_xlabel('X1')\n",
    "axes[1].set_ylabel('y')\n",
    "\n",
    "# 相関行列\n",
    "corr_matrix = np.corrcoef(X[:, 1:].T, y)\n",
    "im = axes[2].imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[2].set_title('Correlation Matrix')\n",
    "axes[2].set_xticks(range(n_features))\n",
    "axes[2].set_yticks(range(n_features))\n",
    "axes[2].set_xticklabels(['X1', 'X2', 'X3', 'y'])\n",
    "axes[2].set_yticklabels(['X1', 'X2', 'X3', 'y'])\n",
    "plt.colorbar(im, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_linear_regression_gibbs(X, y, n_iterations=5000, \n",
    "                                   prior_beta_var=10.0,\n",
    "                                   prior_sigma_shape=1.0, prior_sigma_rate=1.0):\n",
    "    \"\"\"\n",
    "    ベイズ線形回帰のギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - X: 説明変数行列 (n x p)\n",
    "    - y: 目的変数 (n,)\n",
    "    - n_iterations: イテレーション数\n",
    "    - prior_beta_var: 回帰係数の事前分散\n",
    "    - prior_sigma_shape, prior_sigma_rate: 誤差分散の事前分布パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    - beta_samples: 回帰係数のサンプル (n_iterations x p)\n",
    "    - sigma2_samples: 誤差分散のサンプル (n_iterations,)\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    \n",
    "    # 事前分布のパラメータ\n",
    "    prior_beta_precision = np.eye(p) / prior_beta_var\n",
    "    \n",
    "    # 初期値\n",
    "    beta = np.zeros(p)\n",
    "    sigma2 = 1.0\n",
    "    \n",
    "    # サンプル保存用\n",
    "    beta_samples = np.zeros((n_iterations, p))\n",
    "    sigma2_samples = np.zeros(n_iterations)\n",
    "    \n",
    "    # 事前計算（効率化のため）\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Step 1: beta | sigma2, y のサンプリング\n",
    "        # 事後分布は多変量正規分布\n",
    "        posterior_precision = XtX / sigma2 + prior_beta_precision\n",
    "        posterior_cov = np.linalg.inv(posterior_precision)\n",
    "        posterior_mean = posterior_cov @ (Xty / sigma2)\n",
    "        \n",
    "        beta = np.random.multivariate_normal(posterior_mean, posterior_cov)\n",
    "        \n",
    "        # Step 2: sigma2 | beta, y のサンプリング\n",
    "        # 事後分布は逆ガンマ分布\n",
    "        residuals = y - X @ beta\n",
    "        posterior_shape = prior_sigma_shape + n / 2\n",
    "        posterior_rate = prior_sigma_rate + np.sum(residuals**2) / 2\n",
    "        \n",
    "        # 逆ガンマからのサンプリング（ガンマの逆数）\n",
    "        sigma2 = 1 / np.random.gamma(posterior_shape, 1 / posterior_rate)\n",
    "        \n",
    "        # サンプル保存\n",
    "        beta_samples[i] = beta\n",
    "        sigma2_samples[i] = sigma2\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Iteration {i+1}/{n_iterations}\")\n",
    "    \n",
    "    return beta_samples, sigma2_samples\n",
    "\n",
    "# ベイズ線形回帰の実行\n",
    "print(\"ベイズ線形回帰のギブスサンプリング実行中...\")\n",
    "beta_samples, sigma2_samples = bayesian_linear_regression_gibbs(X, y)\n",
    "\n",
    "# 結果の統計\n",
    "burnin = 1000\n",
    "beta_post_mean = np.mean(beta_samples[burnin:], axis=0)\n",
    "beta_post_std = np.std(beta_samples[burnin:], axis=0)\n",
    "sigma2_post_mean = np.mean(sigma2_samples[burnin:])\n",
    "sigma2_post_std = np.std(sigma2_samples[burnin:])\n",
    "\n",
    "print(f\"\\n=== ベイズ推定結果 ===\")\n",
    "print(f\"{'Parameter':<10} {'True':<8} {'Post Mean':<12} {'Post Std':<10} {'95% CI':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i in range(len(true_beta)):\n",
    "    param_samples = beta_samples[burnin:, i]\n",
    "    ci_lower = np.percentile(param_samples, 2.5)\n",
    "    ci_upper = np.percentile(param_samples, 97.5)\n",
    "    \n",
    "    param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "    print(f\"{param_name:<10} {true_beta[i]:<8.3f} {beta_post_mean[i]:<12.3f} \"\n",
    "          f\"{beta_post_std[i]:<10.3f} [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "\n",
    "sigma2_ci_lower = np.percentile(sigma2_samples[burnin:], 2.5)\n",
    "sigma2_ci_upper = np.percentile(sigma2_samples[burnin:], 97.5)\n",
    "print(f\"{'Sigma2':<10} {true_sigma2:<8.3f} {sigma2_post_mean:<12.3f} \"\n",
    "      f\"{sigma2_post_std:<10.3f} [{sigma2_ci_lower:.3f}, {sigma2_ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベイズ線形回帰結果の可視化\n",
    "def plot_bayesian_regression_results(beta_samples, sigma2_samples, true_beta, true_sigma2, \n",
    "                                    X, y, burnin=1000):\n",
    "    \"\"\"\n",
    "    ベイズ線形回帰結果の包括的可視化\n",
    "    \"\"\"\n",
    "    n_params = beta_samples.shape[1]\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    # パラメータのトレースプロット\n",
    "    for i in range(min(4, n_params)):\n",
    "        axes[0, i].plot(beta_samples[:, i], alpha=0.8, linewidth=0.8)\n",
    "        axes[0, i].axhline(true_beta[i], color='red', linestyle='--', linewidth=2)\n",
    "        axes[0, i].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "        param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "        axes[0, i].set_title(f'{param_name} Trace')\n",
    "        axes[0, i].set_xlabel('Iteration')\n",
    "        axes[0, i].set_ylabel('Value')\n",
    "        axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # パラメータの事後分布\n",
    "    for i in range(min(4, n_params)):\n",
    "        param_samples = beta_samples[burnin:, i]\n",
    "        axes[1, i].hist(param_samples, bins=50, density=True, alpha=0.7, color='skyblue')\n",
    "        axes[1, i].axvline(true_beta[i], color='red', linestyle='--', linewidth=2, label='True')\n",
    "        axes[1, i].axvline(np.mean(param_samples), color='blue', linestyle='-', linewidth=2, label='Posterior mean')\n",
    "        \n",
    "        param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "        axes[1, i].set_title(f'{param_name} Posterior')\n",
    "        axes[1, i].set_xlabel('Value')\n",
    "        axes[1, i].set_ylabel('Density')\n",
    "        axes[1, i].legend()\n",
    "    \n",
    "    # 誤差分散の結果\n",
    "    # トレースプロット\n",
    "    axes[2, 0].plot(sigma2_samples, alpha=0.8, linewidth=0.8, color='green')\n",
    "    axes[2, 0].axhline(true_sigma2, color='red', linestyle='--', linewidth=2)\n",
    "    axes[2, 0].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "    axes[2, 0].set_title('Sigma2 Trace')\n",
    "    axes[2, 0].set_xlabel('Iteration')\n",
    "    axes[2, 0].set_ylabel('Sigma2')\n",
    "    axes[2, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 事後分布\n",
    "    sigma2_post = sigma2_samples[burnin:]\n",
    "    axes[2, 1].hist(sigma2_post, bins=50, density=True, alpha=0.7, color='lightgreen')\n",
    "    axes[2, 1].axvline(true_sigma2, color='red', linestyle='--', linewidth=2, label='True')\n",
    "    axes[2, 1].axvline(np.mean(sigma2_post), color='green', linestyle='-', linewidth=2, label='Posterior mean')\n",
    "    axes[2, 1].set_title('Sigma2 Posterior')\n",
    "    axes[2, 1].set_xlabel('Sigma2')\n",
    "    axes[2, 1].set_ylabel('Density')\n",
    "    axes[2, 1].legend()\n",
    "    \n",
    "    # 予測区間の可視化（最初の説明変数について）\n",
    "    if X.shape[1] > 1:  # intercept以外の変数がある場合\n",
    "        x_pred_range = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "        \n",
    "        # 他の変数は平均値に固定\n",
    "        X_pred = np.zeros((len(x_pred_range), X.shape[1]))\n",
    "        X_pred[:, 0] = 1  # intercept\n",
    "        X_pred[:, 1] = x_pred_range  # 対象変数\n",
    "        for j in range(2, X.shape[1]):\n",
    "            X_pred[:, j] = np.mean(X[:, j])  # 他の変数は平均値\n",
    "        \n",
    "        # 事後サンプルから予測分布を計算\n",
    "        n_pred_samples = min(500, len(beta_samples[burnin:]))\n",
    "        pred_samples = np.zeros((n_pred_samples, len(x_pred_range)))\n",
    "        \n",
    "        for i in range(n_pred_samples):\n",
    "            idx = burnin + i\n",
    "            beta_i = beta_samples[idx]\n",
    "            sigma2_i = sigma2_samples[idx]\n",
    "            \n",
    "            # 平均の予測\n",
    "            mu_pred = X_pred @ beta_i\n",
    "            # 予測分布（観測ノイズを含む）\n",
    "            pred_samples[i] = np.random.normal(mu_pred, np.sqrt(sigma2_i))\n",
    "        \n",
    "        # 予測区間の計算\n",
    "        pred_mean = np.mean(pred_samples, axis=0)\n",
    "        pred_lower = np.percentile(pred_samples, 2.5, axis=0)\n",
    "        pred_upper = np.percentile(pred_samples, 97.5, axis=0)\n",
    "        \n",
    "        # プロット\n",
    "        axes[2, 2].scatter(X[:, 1], y, alpha=0.6, s=20, label='Data')\n",
    "        axes[2, 2].plot(x_pred_range, pred_mean, 'b-', linewidth=2, label='Posterior mean')\n",
    "        axes[2, 2].fill_between(x_pred_range, pred_lower, pred_upper, alpha=0.3, color='blue', label='95% Prediction interval')\n",
    "        \n",
    "        # 真の関係\n",
    "        true_pred = X_pred @ true_beta\n",
    "        axes[2, 2].plot(x_pred_range, true_pred, 'r--', linewidth=2, label='True relationship')\n",
    "        \n",
    "        axes[2, 2].set_title('Prediction with Uncertainty')\n",
    "        axes[2, 2].set_xlabel('X1')\n",
    "        axes[2, 2].set_ylabel('y')\n",
    "        axes[2, 2].legend()\n",
    "        axes[2, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 残差分析\n",
    "    # 事後平均を使った予測\n",
    "    beta_mean = np.mean(beta_samples[burnin:], axis=0)\n",
    "    y_pred = X @ beta_mean\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    axes[2, 3].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[2, 3].axhline(0, color='red', linestyle='--')\n",
    "    axes[2, 3].set_title('Residuals vs Fitted')\n",
    "    axes[2, 3].set_xlabel('Fitted values')\n",
    "    axes[2, 3].set_ylabel('Residuals')\n",
    "    axes[2, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 結果の可視化\n",
    "plot_bayesian_regression_results(beta_samples, sigma2_samples, true_beta, true_sigma2, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 ベイズロジスティック回帰\n",
    "\n",
    "二値分類問題に対するベイズ推論を実装します。\n",
    "\n",
    "### モデル設定\n",
    "$$P(y_i = 1 | \\mathbf{x}_i) = \\text{logit}^{-1}(\\mathbf{x}_i^T \\boldsymbol{\\beta})$$\n",
    "\n",
    "ロジスティック回帰では解析的な共役事前分布がないため、メトロポリス・ヘイスティングス法を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰データの生成\n",
    "def generate_logistic_data(n_samples=200, n_features=2, seed=42):\n",
    "    \"\"\"\n",
    "    ロジスティック回帰データの生成\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 真の回帰係数\n",
    "    true_beta = np.array([0.5, 2.0, -1.5])  # intercept + 2 features\n",
    "    \n",
    "    # 説明変数\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    X = np.column_stack([np.ones(n_samples), X])  # intercept項を追加\n",
    "    \n",
    "    # ロジット変換\n",
    "    logits = X @ true_beta\n",
    "    probabilities = expit(logits)  # ロジスティック関数\n",
    "    \n",
    "    # 二値目的変数\n",
    "    y = np.random.binomial(1, probabilities)\n",
    "    \n",
    "    return X, y, true_beta, probabilities\n",
    "\n",
    "# データ生成\n",
    "X_log, y_log, true_beta_log, true_probs = generate_logistic_data()\n",
    "n_samples_log, n_features_log = X_log.shape\n",
    "\n",
    "print(f\"データサイズ: {n_samples_log} x {n_features_log}\")\n",
    "print(f\"真の回帰係数: {true_beta_log}\")\n",
    "print(f\"正例の割合: {np.mean(y_log):.3f}\")\n",
    "\n",
    "# データの可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# クラス別の散布図\n",
    "class_0 = y_log == 0\n",
    "class_1 = y_log == 1\n",
    "\n",
    "axes[0].scatter(X_log[class_0, 1], X_log[class_0, 2], alpha=0.7, c='red', label='Class 0')\n",
    "axes[0].scatter(X_log[class_1, 1], X_log[class_1, 2], alpha=0.7, c='blue', label='Class 1')\n",
    "axes[0].set_title('Data Distribution by Class')\n",
    "axes[0].set_xlabel('X1')\n",
    "axes[0].set_ylabel('X2')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 真の確率 vs 説明変数\n",
    "axes[1].scatter(X_log[:, 1], true_probs, c=y_log, cmap='RdYlBu', alpha=0.7)\n",
    "axes[1].set_title('True Probabilities vs X1')\n",
    "axes[1].set_xlabel('X1')\n",
    "axes[1].set_ylabel('P(y=1)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 目的変数の分布\n",
    "axes[2].bar([0, 1], [np.sum(y_log == 0), np.sum(y_log == 1)], alpha=0.7, color=['red', 'blue'])\n",
    "axes[2].set_title('Class Distribution')\n",
    "axes[2].set_xlabel('Class')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_xticks([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_logistic_regression_mh(X, y, n_iterations=10000, \n",
    "                                   prior_beta_var=10.0, step_size=0.1):\n",
    "    \"\"\"\n",
    "    ベイズロジスティック回帰のメトロポリス・ヘイスティングス法\n",
    "    \n",
    "    Parameters:\n",
    "    - X: 説明変数行列 (n x p)\n",
    "    - y: 二値目的変数 (n,)\n",
    "    - n_iterations: イテレーション数\n",
    "    - prior_beta_var: 回帰係数の事前分散\n",
    "    - step_size: 提案分布のステップサイズ\n",
    "    \n",
    "    Returns:\n",
    "    - beta_samples: 回帰係数のサンプル (n_iterations x p)\n",
    "    - acceptance_rate: 受理率\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    \n",
    "    def log_likelihood(beta):\n",
    "        \"\"\"対数尤度関数\"\"\"\n",
    "        logits = X @ beta\n",
    "        # 数値安定性のための計算\n",
    "        log_lik = np.sum(y * logits - np.log(1 + np.exp(np.clip(logits, -500, 500))))\n",
    "        return log_lik\n",
    "    \n",
    "    def log_prior(beta):\n",
    "        \"\"\"対数事前分布\"\"\"\n",
    "        return -0.5 * np.sum(beta**2) / prior_beta_var\n",
    "    \n",
    "    def log_posterior(beta):\n",
    "        \"\"\"対数事後分布\"\"\"\n",
    "        return log_likelihood(beta) + log_prior(beta)\n",
    "    \n",
    "    # 初期値（最尤推定から開始）\n",
    "    try:\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        def neg_log_lik(beta):\n",
    "            return -log_likelihood(beta)\n",
    "        \n",
    "        result = minimize(neg_log_lik, np.zeros(p), method='BFGS')\n",
    "        beta_current = result.x\n",
    "    except:\n",
    "        beta_current = np.zeros(p)\n",
    "    \n",
    "    # サンプル保存用\n",
    "    beta_samples = np.zeros((n_iterations, p))\n",
    "    n_accepted = 0\n",
    "    \n",
    "    # 提案分布の共分散行列（適応的に調整）\n",
    "    proposal_cov = step_size * np.eye(p)\n",
    "    \n",
    "    current_log_posterior = log_posterior(beta_current)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # 提案\n",
    "        beta_proposed = np.random.multivariate_normal(beta_current, proposal_cov)\n",
    "        proposed_log_posterior = log_posterior(beta_proposed)\n",
    "        \n",
    "        # 受理確率\n",
    "        log_alpha = proposed_log_posterior - current_log_posterior\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却\n",
    "        if np.random.rand() < alpha:\n",
    "            beta_current = beta_proposed\n",
    "            current_log_posterior = proposed_log_posterior\n",
    "            n_accepted += 1\n",
    "        \n",
    "        beta_samples[i] = beta_current\n",
    "        \n",
    "        # 適応的ステップサイズ調整（簡易版）\n",
    "        if i > 0 and i % 500 == 0:\n",
    "            recent_acceptance = n_accepted / i\n",
    "            if recent_acceptance < 0.2:  # 受理率が低すぎる\n",
    "                proposal_cov *= 0.9\n",
    "            elif recent_acceptance > 0.6:  # 受理率が高すぎる\n",
    "                proposal_cov *= 1.1\n",
    "        \n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print(f\"Iteration {i+1}/{n_iterations}, Acceptance rate: {n_accepted/(i+1):.3f}\")\n",
    "    \n",
    "    acceptance_rate = n_accepted / n_iterations\n",
    "    return beta_samples, acceptance_rate\n",
    "\n",
    "# ベイズロジスティック回帰の実行\n",
    "print(\"ベイズロジスティック回帰のMCMCサンプリング実行中...\")\n",
    "beta_samples_log, acceptance_rate_log = bayesian_logistic_regression_mh(X_log, y_log)\n",
    "\n",
    "print(f\"\\n最終受理率: {acceptance_rate_log:.3f}\")\n",
    "\n",
    "# 結果の統計\n",
    "burnin_log = 2000\n",
    "beta_post_mean_log = np.mean(beta_samples_log[burnin_log:], axis=0)\n",
    "beta_post_std_log = np.std(beta_samples_log[burnin_log:], axis=0)\n",
    "\n",
    "print(f\"\\n=== ベイズロジスティック回帰結果 ===\")\n",
    "print(f\"{'Parameter':<10} {'True':<8} {'Post Mean':<12} {'Post Std':<10} {'95% CI':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i in range(len(true_beta_log)):\n",
    "    param_samples = beta_samples_log[burnin_log:, i]\n",
    "    ci_lower = np.percentile(param_samples, 2.5)\n",
    "    ci_upper = np.percentile(param_samples, 97.5)\n",
    "    \n",
    "    param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "    print(f\"{param_name:<10} {true_beta_log[i]:<8.3f} {beta_post_mean_log[i]:<12.3f} \"\n",
    "          f\"{beta_post_std_log[i]:<10.3f} [{ci_lower:.3f}, {ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰結果の可視化\n",
    "def plot_logistic_regression_results(beta_samples, X, y, true_beta, burnin=2000):\n",
    "    \"\"\"\n",
    "    ベイズロジスティック回帰結果の可視化\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    n_params = beta_samples.shape[1]\n",
    "    \n",
    "    # パラメータのトレースプロット\n",
    "    for i in range(min(3, n_params)):\n",
    "        axes[0, i].plot(beta_samples[:, i], alpha=0.8, linewidth=0.8)\n",
    "        axes[0, i].axhline(true_beta[i], color='red', linestyle='--', linewidth=2)\n",
    "        axes[0, i].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "        param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "        axes[0, i].set_title(f'{param_name} Trace')\n",
    "        axes[0, i].set_xlabel('Iteration')\n",
    "        axes[0, i].set_ylabel('Value')\n",
    "        axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # パラメータの事後分布\n",
    "    for i in range(min(3, n_params)):\n",
    "        param_samples = beta_samples[burnin:, i]\n",
    "        axes[1, i].hist(param_samples, bins=50, density=True, alpha=0.7, color='lightcoral')\n",
    "        axes[1, i].axvline(true_beta[i], color='red', linestyle='--', linewidth=2, label='True')\n",
    "        axes[1, i].axvline(np.mean(param_samples), color='darkred', linestyle='-', linewidth=2, label='Posterior mean')\n",
    "        \n",
    "        param_name = 'Intercept' if i == 0 else f'Beta_{i}'\n",
    "        axes[1, i].set_title(f'{param_name} Posterior')\n",
    "        axes[1, i].set_xlabel('Value')\n",
    "        axes[1, i].set_ylabel('Density')\n",
    "        axes[1, i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 決定境界の可視化（2次元の場合）\n",
    "    if X.shape[1] == 3:  # intercept + 2 features\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # 事後平均による決定境界\n",
    "        beta_mean = np.mean(beta_samples[burnin:], axis=0)\n",
    "        \n",
    "        # グリッドの作成\n",
    "        x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        x2_min, x2_max = X[:, 2].min() - 1, X[:, 2].max() + 1\n",
    "        xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 100),\n",
    "                               np.linspace(x2_min, x2_max, 100))\n",
    "        \n",
    "        grid_points = np.c_[np.ones(xx1.ravel().shape[0]), xx1.ravel(), xx2.ravel()]\n",
    "        \n",
    "        # 事後平均による予測確率\n",
    "        prob_mean = expit(grid_points @ beta_mean).reshape(xx1.shape)\n",
    "        \n",
    "        # 等高線プロット\n",
    "        class_0 = y == 0\n",
    "        class_1 = y == 1\n",
    "        \n",
    "        axes[0].contourf(xx1, xx2, prob_mean, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "        axes[0].contour(xx1, xx2, prob_mean, levels=[0.5], colors='black', linewidths=2)\n",
    "        axes[0].scatter(X[class_0, 1], X[class_0, 2], c='red', alpha=0.7, label='Class 0')\n",
    "        axes[0].scatter(X[class_1, 1], X[class_1, 2], c='blue', alpha=0.7, label='Class 1')\n",
    "        axes[0].set_title('Decision Boundary (Posterior Mean)')\n",
    "        axes[0].set_xlabel('X1')\n",
    "        axes[0].set_ylabel('X2')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # 不確実性の可視化\n",
    "        # 複数の事後サンプルから予測確率の不確実性を計算\n",
    "        n_uncertainty_samples = min(100, len(beta_samples[burnin:]))\n",
    "        prob_samples = np.zeros((n_uncertainty_samples, xx1.size))\n",
    "        \n",
    "        for i in range(n_uncertainty_samples):\n",
    "            beta_i = beta_samples[burnin + i]\n",
    "            prob_samples[i] = expit(grid_points @ beta_i)\n",
    "        \n",
    "        prob_std = np.std(prob_samples, axis=0).reshape(xx1.shape)\n",
    "        \n",
    "        im = axes[1].contourf(xx1, xx2, prob_std, levels=20, cmap='Reds')\n",
    "        axes[1].scatter(X[class_0, 1], X[class_0, 2], c='white', edgecolors='black', alpha=0.7, label='Class 0')\n",
    "        axes[1].scatter(X[class_1, 1], X[class_1, 2], c='black', alpha=0.7, label='Class 1')\n",
    "        axes[1].set_title('Prediction Uncertainty (Std Dev)')\n",
    "        axes[1].set_xlabel('X1')\n",
    "        axes[1].set_ylabel('X2')\n",
    "        axes[1].legend()\n",
    "        plt.colorbar(im, ax=axes[1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 結果の可視化\n",
    "plot_logistic_regression_results(beta_samples_log, X_log, y_log, true_beta_log)\n",
    "\n",
    "# 予測性能の評価\n",
    "burnin_log = 2000\n",
    "beta_mean = np.mean(beta_samples_log[burnin_log:], axis=0)\n",
    "prob_pred = expit(X_log @ beta_mean)\n",
    "y_pred = (prob_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_log)\n",
    "print(f\"\\n予測精度: {accuracy:.3f}\")\n",
    "\n",
    "# 混同行列\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_log, y_pred)\n",
    "print(f\"\\n混同行列:\")\n",
    "print(cm)\n",
    "print(f\"\\n分類レポート:\")\n",
    "print(classification_report(y_log, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 階層モデル（Hierarchical Model）\n",
    "\n",
    "異なるグループ間で共通の構造を持つモデルを考えます。学校別の学生成績データを例として使用します。\n",
    "\n",
    "### モデル設定\n",
    "- レベル1（個人レベル）: $y_{ij} \\sim N(\\mu_j, \\sigma^2)$\n",
    "- レベル2（グループレベル）: $\\mu_j \\sim N(\\alpha, \\tau^2)$\n",
    "\nここで、$i$は個人、$j$はグループを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階層データの生成\n",
    "def generate_hierarchical_data(n_groups=8, n_per_group=15, seed=42):\n",
    "    \"\"\"\n",
    "    階層構造データの生成（学校別学生成績の例）\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 超パラメータ\n",
    "    alpha_true = 75.0  # 全体平均\n",
    "    tau_true = 8.0     # グループ間のばらつき\n",
    "    sigma_true = 5.0   # 個人内のばらつき\n",
    "    \n",
    "    # グループ平均\n",
    "    group_means = np.random.normal(alpha_true, tau_true, n_groups)\n",
    "    \n",
    "    # 個人データ\n",
    "    data = []\n",
    "    group_ids = []\n",
    "    \n",
    "    for j in range(n_groups):\n",
    "        group_data = np.random.normal(group_means[j], sigma_true, n_per_group)\n",
    "        data.extend(group_data)\n",
    "        group_ids.extend([j] * n_per_group)\n",
    "    \n",
    "    return np.array(data), np.array(group_ids), group_means, alpha_true, tau_true, sigma_true\n",
    "\n",
    "# データ生成\n",
    "y_hier, group_ids, true_group_means, true_alpha, true_tau, true_sigma = generate_hierarchical_data()\n",
    "n_groups = len(np.unique(group_ids))\n",
    "n_total = len(y_hier)\n",
    "\n",
    "print(f\"データサイズ: {n_total} observations, {n_groups} groups\")\n",
    "print(f\"真の超パラメータ: α = {true_alpha:.1f}, τ = {true_tau:.1f}, σ = {true_sigma:.1f}\")\n",
    "print(f\"真のグループ平均: {true_group_means.round(1)}\")\n",
    "\n",
    "# データの可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# グループ別ボックスプロット\n",
    "group_data = [y_hier[group_ids == j] for j in range(n_groups)]\n",
    "axes[0].boxplot(group_data, labels=[f'Group {j+1}' for j in range(n_groups)])\n",
    "axes[0].scatter(range(1, n_groups+1), true_group_means, color='red', s=50, label='True means')\n",
    "axes[0].axhline(true_alpha, color='red', linestyle='--', alpha=0.7, label='Overall mean')\n",
    "axes[0].set_title('Data by Group')\n",
    "axes[0].set_xlabel('Group')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 全体分布\n",
    "axes[1].hist(y_hier, bins=30, alpha=0.7, density=True, color='skyblue')\n",
    "axes[1].axvline(true_alpha, color='red', linestyle='--', linewidth=2, label='True overall mean')\n",
    "axes[1].axvline(np.mean(y_hier), color='blue', linestyle='-', linewidth=2, label='Sample mean')\n",
    "axes[1].set_title('Overall Distribution')\n",
    "axes[1].set_xlabel('Score')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].legend()\n",
    "\n",
    "# グループ平均の分布\n",
    "sample_group_means = [np.mean(y_hier[group_ids == j]) for j in range(n_groups)]\n",
    "axes[2].scatter(range(1, n_groups+1), sample_group_means, color='blue', s=50, label='Sample means')\n",
    "axes[2].scatter(range(1, n_groups+1), true_group_means, color='red', s=50, label='True means')\n",
    "axes[2].axhline(true_alpha, color='red', linestyle='--', alpha=0.7, label='Overall mean')\n",
    "axes[2].set_title('Group Means Comparison')\n",
    "axes[2].set_xlabel('Group')\n",
    "axes[2].set_ylabel('Mean Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# グループ別統計\n",
    "print(f\"\\n=== グループ別統計 ===\")\n",
    "print(f\"{'Group':<8} {'N':<5} {'Sample Mean':<12} {'True Mean':<10} {'Sample Std':<12}\")\n",
    "print(\"-\" * 55)\n",
    "for j in range(n_groups):\n",
    "    group_data_j = y_hier[group_ids == j]\n",
    "    print(f\"{j+1:<8} {len(group_data_j):<5} {np.mean(group_data_j):<12.2f} \"\n",
    "          f\"{true_group_means[j]:<10.2f} {np.std(group_data_j, ddof=1):<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_model_gibbs(y, group_ids, n_iterations=8000,\n",
    "                           prior_alpha_mean=70, prior_alpha_var=100,\n",
    "                           prior_tau_shape=1, prior_tau_rate=1,\n",
    "                           prior_sigma_shape=1, prior_sigma_rate=1):\n",
    "    \"\"\"\n",
    "    階層モデルのギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - y: 観測値\n",
    "    - group_ids: グループID\n",
    "    - n_iterations: イテレーション数\n",
    "    - prior_*: 事前分布のパラメータ\n",
    "    \n",
    "    Returns:\n",
    "    - alpha_samples: 全体平均のサンプル\n",
    "    - tau2_samples: グループ間分散のサンプル\n",
    "    - sigma2_samples: 個人内分散のサンプル\n",
    "    - mu_samples: グループ平均のサンプル\n",
    "    \"\"\"\n",
    "    n_groups = len(np.unique(group_ids))\n",
    "    n_total = len(y)\n",
    "    \n",
    "    # グループごとのデータ\n",
    "    group_data = [y[group_ids == j] for j in range(n_groups)]\n",
    "    group_sizes = [len(group_data[j]) for j in range(n_groups)]\n",
    "    \n",
    "    # 初期値\n",
    "    alpha = np.mean(y)\n",
    "    tau2 = 1.0\n",
    "    sigma2 = 1.0\n",
    "    mu = np.array([np.mean(group_data[j]) for j in range(n_groups)])\n",
    "    \n",
    "    # サンプル保存用\n",
    "    alpha_samples = np.zeros(n_iterations)\n",
    "    tau2_samples = np.zeros(n_iterations)\n",
    "    sigma2_samples = np.zeros(n_iterations)\n",
    "    mu_samples = np.zeros((n_iterations, n_groups))\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Step 1: μ_j | α, τ², σ², y のサンプリング\n",
    "        for j in range(n_groups):\n",
    "            n_j = group_sizes[j]\n",
    "            y_j_bar = np.mean(group_data[j])\n",
    "            \n",
    "            # 事後分布のパラメータ\n",
    "            posterior_precision = 1/tau2 + n_j/sigma2\n",
    "            posterior_var = 1 / posterior_precision\n",
    "            posterior_mean = posterior_var * (alpha/tau2 + n_j*y_j_bar/sigma2)\n",
    "            \n",
    "            mu[j] = np.random.normal(posterior_mean, np.sqrt(posterior_var))\n",
    "        \n",
    "        # Step 2: α | μ, τ² のサンプリング\n",
    "        posterior_precision_alpha = 1/prior_alpha_var + n_groups/tau2\n",
    "        posterior_var_alpha = 1 / posterior_precision_alpha\n",
    "        posterior_mean_alpha = posterior_var_alpha * (prior_alpha_mean/prior_alpha_var + np.sum(mu)/tau2)\n",
    "        \n",
    "        alpha = np.random.normal(posterior_mean_alpha, np.sqrt(posterior_var_alpha))\n",
    "        \n",
    "        # Step 3: τ² | α, μ のサンプリング\n",
    "        posterior_shape_tau = prior_tau_shape + n_groups / 2\n",
    "        posterior_rate_tau = prior_tau_rate + np.sum((mu - alpha)**2) / 2\n",
    "        \n",
    "        tau2 = 1 / np.random.gamma(posterior_shape_tau, 1/posterior_rate_tau)\n",
    "        \n",
    "        # Step 4: σ² | μ, y のサンプリング\n",
    "        total_ss = 0\n",
    "        for j in range(n_groups):\n",
    "            total_ss += np.sum((group_data[j] - mu[j])**2)\n",
    "        \n",
    "        posterior_shape_sigma = prior_sigma_shape + n_total / 2\n",
    "        posterior_rate_sigma = prior_sigma_rate + total_ss / 2\n",
    "        \n",
    "        sigma2 = 1 / np.random.gamma(posterior_shape_sigma, 1/posterior_rate_sigma)\n",
    "        \n",
    "        # サンプル保存\n",
    "        alpha_samples[i] = alpha\n",
    "        tau2_samples[i] = tau2\n",
    "        sigma2_samples[i] = sigma2\n",
    "        mu_samples[i] = mu\n",
    "        \n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print(f\"Iteration {i+1}/{n_iterations}\")\n",
    "    \n",
    "    return alpha_samples, tau2_samples, sigma2_samples, mu_samples\n",
    "\n",
    "# 階層モデルの実行\n",
    "print(\"階層モデルのギブスサンプリング実行中...\")\n",
    "alpha_samples, tau2_samples, sigma2_samples, mu_samples = hierarchical_model_gibbs(y_hier, group_ids)\n",
    "\n",
    "# 結果の統計\n",
    "burnin_hier = 2000\n",
    "\n",
    "alpha_post_mean = np.mean(alpha_samples[burnin_hier:])\n",
    "tau_post_mean = np.sqrt(np.mean(tau2_samples[burnin_hier:]))\n",
    "sigma_post_mean = np.sqrt(np.mean(sigma2_samples[burnin_hier:]))\n",
    "mu_post_mean = np.mean(mu_samples[burnin_hier:], axis=0)\n",
    "\n",
    "print(f\"\\n=== 階層モデル推定結果 ===\")\n",
    "print(f\"{'Parameter':<15} {'True':<8} {'Post Mean':<12} {'95% CI':<20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 超パラメータ\n",
    "alpha_ci = np.percentile(alpha_samples[burnin_hier:], [2.5, 97.5])\n",
    "print(f\"{'Alpha (mean)':<15} {true_alpha:<8.2f} {alpha_post_mean:<12.2f} \"\n",
    "      f\"[{alpha_ci[0]:.2f}, {alpha_ci[1]:.2f}]\")\n",
    "\n",
    "tau_ci = np.percentile(np.sqrt(tau2_samples[burnin_hier:]), [2.5, 97.5])\n",
    "print(f\"{'Tau (group SD)':<15} {true_tau:<8.2f} {tau_post_mean:<12.2f} \"\n",
    "      f\"[{tau_ci[0]:.2f}, {tau_ci[1]:.2f}]\")\n",
    "\n",
    "sigma_ci = np.percentile(np.sqrt(sigma2_samples[burnin_hier:]), [2.5, 97.5])\n",
    "print(f\"{'Sigma (ind SD)':<15} {true_sigma:<8.2f} {sigma_post_mean:<12.2f} \"\n",
    "      f\"[{sigma_ci[0]:.2f}, {sigma_ci[1]:.2f}]\")\n",
    "\n",
    "print(\"\\n=== グループ平均の推定 ===\")\n",
    "print(f\"{'Group':<8} {'True':<8} {'Post Mean':<12} {'95% CI':<20}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for j in range(n_groups):\n",
    "    mu_j_ci = np.percentile(mu_samples[burnin_hier:, j], [2.5, 97.5])\n",
    "    print(f\"{j+1:<8} {true_group_means[j]:<8.2f} {mu_post_mean[j]:<12.2f} \"\n",
    "          f\"[{mu_j_ci[0]:.2f}, {mu_j_ci[1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階層モデル結果の可視化\n",
    "def plot_hierarchical_results(alpha_samples, tau2_samples, sigma2_samples, mu_samples,\n",
    "                            y, group_ids, true_alpha, true_tau, true_sigma, true_group_means,\n",
    "                            burnin=2000):\n",
    "    \"\"\"\n",
    "    階層モデル結果の包括的可視化\n",
    "    \"\"\"\n",
    "    n_groups = mu_samples.shape[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    # 超パラメータのトレースプロット\n",
    "    axes[0, 0].plot(alpha_samples, alpha=0.8, linewidth=0.8)\n",
    "    axes[0, 0].axhline(true_alpha, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 0].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "    axes[0, 0].set_title('Alpha (Overall Mean)')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Alpha')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(np.sqrt(tau2_samples), alpha=0.8, linewidth=0.8, color='green')\n",
    "    axes[0, 1].axhline(true_tau, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "    axes[0, 1].set_title('Tau (Between-group SD)')\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('Tau')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 2].plot(np.sqrt(sigma2_samples), alpha=0.8, linewidth=0.8, color='orange')\n",
    "    axes[0, 2].axhline(true_sigma, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 2].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "    axes[0, 2].set_title('Sigma (Within-group SD)')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Sigma')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 分散成分の比較\n",
    "    tau_post = np.sqrt(tau2_samples[burnin:])\n",
    "    sigma_post = np.sqrt(sigma2_samples[burnin:])\n",
    "    icc_post = tau2_samples[burnin:] / (tau2_samples[burnin:] + sigma2_samples[burnin:])\n",
    "    \n",
    "    axes[0, 3].hist(icc_post, bins=50, alpha=0.7, density=True, color='purple')\n",
    "    true_icc = true_tau**2 / (true_tau**2 + true_sigma**2)\n",
    "    axes[0, 3].axvline(true_icc, color='red', linestyle='--', linewidth=2, label='True ICC')\n",
    "    axes[0, 3].axvline(np.mean(icc_post), color='purple', linestyle='-', linewidth=2, label='Post mean')\n",
    "    axes[0, 3].set_title('Intraclass Correlation (ICC)')\n",
    "    axes[0, 3].set_xlabel('ICC')\n",
    "    axes[0, 3].set_ylabel('Density')\n",
    "    axes[0, 3].legend()\n",
    "    \n",
    "    # 超パラメータの事後分布\n",
    "    axes[1, 0].hist(alpha_samples[burnin:], bins=50, alpha=0.7, density=True, color='skyblue')\n",
    "    axes[1, 0].axvline(true_alpha, color='red', linestyle='--', linewidth=2, label='True')\n",
    "    axes[1, 0].axvline(np.mean(alpha_samples[burnin:]), color='blue', linestyle='-', linewidth=2, label='Post mean')\n",
    "    axes[1, 0].set_title('Alpha Posterior')\n",
    "    axes[1, 0].set_xlabel('Alpha')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    axes[1, 1].hist(tau_post, bins=50, alpha=0.7, density=True, color='lightgreen')\n",
    "    axes[1, 1].axvline(true_tau, color='red', linestyle='--', linewidth=2, label='True')\n",
    "    axes[1, 1].axvline(np.mean(tau_post), color='green', linestyle='-', linewidth=2, label='Post mean')\n",
    "    axes[1, 1].set_title('Tau Posterior')\n",
    "    axes[1, 1].set_xlabel('Tau')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    axes[1, 2].hist(sigma_post, bins=50, alpha=0.7, density=True, color='lightsalmon')\n",
    "    axes[1, 2].axvline(true_sigma, color='red', linestyle='--', linewidth=2, label='True')\n",
    "    axes[1, 2].axvline(np.mean(sigma_post), color='orange', linestyle='-', linewidth=2, label='Post mean')\n",
    "    axes[1, 2].set_title('Sigma Posterior')\n",
    "    axes[1, 2].set_xlabel('Sigma')\n",
    "    axes[1, 2].set_ylabel('Density')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    # グループ平均の収束（最初の4グループ）\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, min(4, n_groups)))\n",
    "    for j in range(min(4, n_groups)):\n",
    "        axes[1, 3].plot(mu_samples[:, j], alpha=0.7, color=colors[j], \n",
    "                       linewidth=0.8, label=f'Group {j+1}')\n",
    "        axes[1, 3].axhline(true_group_means[j], color=colors[j], linestyle='--', alpha=0.7)\n",
    "    axes[1, 3].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "    axes[1, 3].set_title('Group Means Convergence')\n",
    "    axes[1, 3].set_xlabel('Iteration')\n",
    "    axes[1, 3].set_ylabel('Group Mean')\n",
    "    axes[1, 3].legend()\n",
    "    axes[1, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 縮小効果の可視化\n",
    "    sample_group_means = np.array([np.mean(y[group_ids == j]) for j in range(n_groups)])\n",
    "    posterior_group_means = np.mean(mu_samples[burnin:], axis=0)\n",
    "    \n",
    "    axes[2, 0].scatter(sample_group_means, posterior_group_means, alpha=0.7, s=50)\n",
    "    axes[2, 0].plot([sample_group_means.min(), sample_group_means.max()], \n",
    "                   [sample_group_means.min(), sample_group_means.max()], \n",
    "                   'r--', alpha=0.7, label='No shrinkage')\n",
    "    axes[2, 0].set_title('Shrinkage Effect')\n",
    "    axes[2, 0].set_xlabel('Sample Group Mean')\n",
    "    axes[2, 0].set_ylabel('Posterior Group Mean')\n",
    "    axes[2, 0].legend()\n",
    "    axes[2, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # グループ平均の比較\n",
    "    x_pos = np.arange(n_groups)\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[2, 1].bar(x_pos - width, true_group_means, width, label='True', alpha=0.7, color='red')\n",
    "    axes[2, 1].bar(x_pos, sample_group_means, width, label='Sample', alpha=0.7, color='blue')\n",
    "    axes[2, 1].bar(x_pos + width, posterior_group_means, width, label='Posterior', alpha=0.7, color='green')\n",
    "    \n",
    "    # 信頼区間の追加\n",
    "    for j in range(n_groups):\n",
    "        ci = np.percentile(mu_samples[burnin:, j], [2.5, 97.5])\n",
    "        axes[2, 1].errorbar(j + width, posterior_group_means[j], \n",
    "                           yerr=[[posterior_group_means[j] - ci[0]], [ci[1] - posterior_group_means[j]]], \n",
    "                           fmt='none', color='black', capsize=3)\n",
    "    \n",
    "    axes[2, 1].set_title('Group Means Comparison')\n",
    "    axes[2, 1].set_xlabel('Group')\n",
    "    axes[2, 1].set_ylabel('Mean')\n",
    "    axes[2, 1].set_xticks(x_pos)\n",
    "    axes[2, 1].set_xticklabels([f'G{j+1}' for j in range(n_groups)])\n",
    "    axes[2, 1].legend()\n",
    "    axes[2, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 予測分布\n",
    "    # 新しいグループの予測分布\n",
    "    new_group_samples = np.random.normal(alpha_samples[burnin:], np.sqrt(tau2_samples[burnin:]))\n",
    "    \n",
    "    axes[2, 2].hist(new_group_samples, bins=50, alpha=0.7, density=True, color='lightcyan', label='New group prediction')\n",
    "    axes[2, 2].axvline(true_alpha, color='red', linestyle='--', linewidth=2, label='True overall mean')\n",
    "    axes[2, 2].set_title('Prediction for New Group')\n",
    "    axes[2, 2].set_xlabel('Predicted Group Mean')\n",
    "    axes[2, 2].set_ylabel('Density')\n",
    "    axes[2, 2].legend()\n",
    "    \n",
    "    # 個人レベル予測\n",
    "    # 既存グループの新しい個人の予測（グループ1の例）\n",
    "    group_0_individual_pred = np.random.normal(mu_samples[burnin:, 0], np.sqrt(sigma2_samples[burnin:]))\n",
    "    \n",
    "    axes[2, 3].hist(group_0_individual_pred, bins=50, alpha=0.7, density=True, color='lightpink', \n",
    "                   label='New individual in Group 1')\n",
    "    axes[2, 3].axvline(true_group_means[0], color='red', linestyle='--', linewidth=2, label='True Group 1 mean')\n",
    "    axes[2, 3].set_title('Individual Prediction (Group 1)')\n",
    "    axes[2, 3].set_xlabel('Predicted Score')\n",
    "    axes[2, 3].set_ylabel('Density')\n",
    "    axes[2, 3].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 結果の可視化\n",
    "plot_hierarchical_results(alpha_samples, tau2_samples, sigma2_samples, mu_samples,\n",
    "                         y_hier, group_ids, true_alpha, true_tau, true_sigma, true_group_means)\n",
    "\n",
    "# 縮小効果の定量化\n",
    "burnin_hier = 2000\n",
    "sample_group_means = np.array([np.mean(y_hier[group_ids == j]) for j in range(n_groups)])\n",
    "posterior_group_means = np.mean(mu_samples[burnin_hier:], axis=0)\n",
    "overall_mean = np.mean(y_hier)\n",
    "\n",
    "# 縮小率の計算\n",
    "shrinkage_factors = 1 - (posterior_group_means - overall_mean) / (sample_group_means - overall_mean)\n",
    "\n",
    "print(f\"\\n=== 縮小効果 ===\")\n",
    "print(f\"{'Group':<8} {'Sample Mean':<12} {'Posterior Mean':<15} {'Shrinkage':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for j in range(n_groups):\n",
    "    print(f\"{j+1:<8} {sample_group_means[j]:<12.2f} {posterior_group_means[j]:<15.2f} {shrinkage_factors[j]:<10.3f}\")\n",
    "\n",
    "print(f\"\\n平均縮小率: {np.mean(np.abs(shrinkage_factors)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 演習問題\n",
    "\n",
    "### 問題1：変化点検出\n",
    "時系列データにおいて平均が変化する点を検出するモデルを実装してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1: 変化点検出モデル\n",
    "def generate_changepoint_data(n=100, changepoint=50, mu1=0, mu2=3, sigma=1, seed=42):\n",
    "    \"\"\"\n",
    "    変化点のある時系列データを生成\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    y = np.zeros(n)\n",
    "    y[:changepoint] = np.random.normal(mu1, sigma, changepoint)\n",
    "    y[changepoint:] = np.random.normal(mu2, sigma, n - changepoint)\n",
    "    \n",
    "    return y, changepoint\n",
    "\n",
    "# データ生成\n",
    "y_cp, true_cp = generate_changepoint_data()\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_cp, 'b-', alpha=0.7, linewidth=1)\n",
    "plt.axvline(true_cp, color='red', linestyle='--', linewidth=2, label=f'True changepoint: {true_cp}')\n",
    "plt.title('Time Series with Changepoint')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ここに変化点検出のMCMCモデルを実装してください\n",
    "# ヒント：\n",
    "# 1. 変化点の位置をパラメータとして扱う\n",
    "# 2. 変化点前後の平均を別々にモデル化\n",
    "# 3. 変化点の事前分布を設定（一様分布など）\n",
    "\n",
    "def changepoint_detection_mcmc(y, n_iterations=5000):\n",
    "    \"\"\"\n",
    "    変化点検出のMCMC実装\n",
    "    \n",
    "    モデル:\n",
    "    y_t ~ N(mu1, sigma^2) for t < tau\n",
    "    y_t ~ N(mu2, sigma^2) for t >= tau\n",
    "    \n",
    "    tau ~ Uniform(1, n-1)\n",
    "    mu1, mu2 ~ N(0, 100)\n",
    "    sigma^2 ~ InvGamma(1, 1)\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テスト\n",
    "# cp_samples, mu1_samples, mu2_samples, sigma2_samples = changepoint_detection_mcmc(y_cp)\n",
    "# # 結果の分析と可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2：ポアソン回帰\n",
    "カウントデータに対するベイズポアソン回帰を実装してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2: ベイズポアソン回帰\n",
    "def generate_poisson_data(n_samples=150, n_features=2, seed=42):\n",
    "    \"\"\"\n",
    "    ポアソン回帰データの生成\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 真の回帰係数\n",
    "    true_beta = np.array([1.0, 0.5, -0.3])  # intercept + 2 features\n",
    "    \n",
    "    # 説明変数\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    X = np.column_stack([np.ones(n_samples), X])  # intercept項を追加\n",
    "    \n",
    "    # リンク関数（対数リンク）\n",
    "    log_lambda = X @ true_beta\n",
    "    lambda_param = np.exp(log_lambda)\n",
    "    \n",
    "    # ポアソン分布からサンプリング\n",
    "    y = np.random.poisson(lambda_param)\n",
    "    \n",
    "    return X, y, true_beta\n",
    "\n",
    "# データ生成\n",
    "X_pois, y_pois, true_beta_pois = generate_poisson_data()\n",
    "\n",
    "# データの可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# カウントデータの分布\n",
    "axes[0].hist(y_pois, bins=range(max(y_pois)+2), alpha=0.7, density=False)\n",
    "axes[0].set_title('Count Data Distribution')\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# 説明変数との関係\n",
    "axes[1].scatter(X_pois[:, 1], y_pois, alpha=0.6)\n",
    "axes[1].set_title('Count vs X1')\n",
    "axes[1].set_xlabel('X1')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "axes[2].scatter(X_pois[:, 2], y_pois, alpha=0.6)\n",
    "axes[2].set_title('Count vs X2')\n",
    "axes[2].set_xlabel('X2')\n",
    "axes[2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"データサイズ: {X_pois.shape[0]} x {X_pois.shape[1]}\")\n",
    "print(f\"真の回帰係数: {true_beta_pois}\")\n",
    "print(f\"カウントデータの平均: {np.mean(y_pois):.2f}\")\n",
    "print(f\"カウントデータの分散: {np.var(y_pois):.2f}\")\n",
    "\n",
    "# ここにベイズポアソン回帰を実装してください\n",
    "# ヒント：\n",
    "# 1. 対数尤度: Σ[y_i * log(λ_i) - λ_i - log(y_i!)]\n",
    "# 2. λ_i = exp(X_i @ β)\n",
    "# 3. MHサンプリングを使用（解析的共役がないため）\n",
    "\n",
    "def bayesian_poisson_regression_mh(X, y, n_iterations=8000, prior_beta_var=10.0, step_size=0.1):\n",
    "    \"\"\"\n",
    "    ベイズポアソン回帰のメトロポリス・ヘイスティングス法\n",
    "    \n",
    "    モデル:\n",
    "    y_i ~ Poisson(λ_i)\n",
    "    log(λ_i) = X_i @ β\n",
    "    β_j ~ N(0, prior_beta_var)\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テスト\n",
    "# beta_samples_pois, acceptance_rate_pois = bayesian_poisson_regression_mh(X_pois, y_pois)\n",
    "# # 結果の分析と可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "この章では、MCMCを用いた実践的なベイズ推論の応用例を学習しました：\n",
    "\n",
    "### 実装したモデル\n",
    "\n",
    "1. **ベイズ線形回帰**：\n",
    "   - ギブスサンプリングによる効率的な実装\n",
    "   - 予測区間の不確実性定量化\n",
    "   - 回帰診断とモデル検証\n",
    "\n",
    "2. **ベイズロジスティック回帰**：\n",
    "   - MHサンプリングによる非共役モデル\n",
    "   - 決定境界の可視化\n",
    "   - 予測不確実性の評価\n",
    "\n",
    "3. **階層モデル**：\n",
    "   - 多レベルデータ構造の処理\n",
    "   - 縮小推定（shrinkage estimation）の理解\n",
    "   - グループ間・グループ内変動の分解\n",
    "\n",
    "### 重要な概念\n",
    "\n",
    "- **共役性**：ギブス vs MHサンプリングの使い分け\n",
    "- **階層構造**：情報の借用（information borrowing）\n",
    "- **予測分布**：新しいデータの不確実性定量化\n",
    "- **モデル診断**：残差分析と適合度評価\n",
    "\n",
    "### 実践的テクニック\n",
    "\n",
    "- **数値安定性**：オーバーフロー/アンダーフローの回避\n",
    "- **適応的調整**：ステップサイズの自動調整\n",
    "- **効率的実装**：事前計算による高速化\n",
    "- **可視化**：結果の解釈と診断\n",
    "\n",
    "### モデル選択指針\n",
    "\n",
    "| データタイプ | モデル | サンプリング手法 |\n",
    "|-------------|--------|------------------|\n",
    "| 連続値（正規誤差） | 線形回帰 | ギブスサンプリング |\n",
    "| 二値 | ロジスティック回帰 | MHサンプリング |\n",
    "| カウント | ポアソン回帰 | MHサンプリング |\n",
    "| 階層構造 | 階層モデル | ギブスサンプリング |\n",
    "| 時系列（変化点） | 状態空間モデル | MHサンプリング |\n",
    "\n",
    "次の章では、より高度なMCMC手法（HMC、NUTS、変分推論など）を学習し、複雑なモデルへの対応方法を習得します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}