{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Chapter 6: ハミルトニアンモンテカルロ法（HMC）完全ガイド\n\n## 学習目標\n- ハミルトニアンモンテカルロ法の物理学的背景を理解する\n- HMCの数学的原理とアルゴリズムを習得する\n- リープフロッグ積分とエネルギー保存の重要性を学ぶ\n- 従来のMCMC手法との性能比較を行う\n- パラメータチューニングとデバッグ手法を身につける\n- 実際の問題への応用例を通じて実践的スキルを習得する"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"HMC教育モジュールを開始します...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 物理学的直感：なぜハミルトニアンなのか？\n",
    "\n",
    "### 従来のMCMC手法の限界\n",
    "\n",
    "従来のランダムウォーク・メトロポリス・ヘイスティングス法は「酔っ払いの歩行」に例えられます。高次元空間では、ランダムな提案の大部分が低確率領域に向かってしまい、探索が極めて非効率になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_walk_problems():\n",
    "    \"\"\"従来のランダムウォークMHの問題点を可視化\"\"\"\n",
    "    \n",
    "    def random_walk_trajectory(steps=1000):\n",
    "        \"\"\"酔っ払いの歩行をシミュレート\"\"\"\n",
    "        position = np.array([0.0, 0.0])\n",
    "        trajectory = [position.copy()]\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            # ランダムな方向に小さなステップ\n",
    "            step = np.random.normal(0, 0.5, 2)\n",
    "            position += step\n",
    "            trajectory.append(position.copy())\n",
    "        \n",
    "        return np.array(trajectory)\n",
    "    \n",
    "    trajectory = random_walk_trajectory()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 軌跡の可視化\n",
    "    axes[0].plot(trajectory[:, 0], trajectory[:, 1], 'b-', alpha=0.6, linewidth=0.5)\n",
    "    axes[0].plot(trajectory[0, 0], trajectory[0, 1], 'go', markersize=8, label='開始')\n",
    "    axes[0].plot(trajectory[-1, 0], trajectory[-1, 1], 'ro', markersize=8, label='終了')\n",
    "    axes[0].set_title('ランダムウォークの軌跡\\n（非効率な探索）')\n",
    "    axes[0].set_xlabel('X1')\n",
    "    axes[0].set_ylabel('X2')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 時系列\n",
    "    axes[1].plot(trajectory[:200, 0], alpha=0.8, label='X1', linewidth=0.8)\n",
    "    axes[1].plot(trajectory[:200, 1], alpha=0.8, label='X2', linewidth=0.8)\n",
    "    axes[1].set_title('座標の時系列\\n（強い自己相関）')\n",
    "    axes[1].set_xlabel('ステップ')\n",
    "    axes[1].set_ylabel('値')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ランダムウォークの問題点：\")\n",
    "    print(\"1. 小さなステップサイズ → 探索が遅い\")\n",
    "    print(\"2. ランダムな方向 → 効率的でない動き\")\n",
    "    print(\"3. 強い自己相関 → 独立サンプルが少ない\")\n",
    "\n",
    "visualize_random_walk_problems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハミルトニアン力学の基本概念\n",
    "\n",
    "HMCは古典力学のハミルトニアン形式から着想を得ています：\n",
    "\n",
    "- **従来のMCMC**: 目隠しをした人がランダムに歩き回る\n",
    "- **HMC**: 坂道を転がるボールの物理的な動き\n",
    "\n",
    "物理学と統計学の対応関係：\n",
    "- **位置 q**: パラメータ（推定したい量）\n",
    "- **運動量 p**: 補助変数（サンプリング用）\n",
    "- **ポテンシャルエネルギー U(q)**: 負の対数事後確率 -log π(q)\n",
    "- **運動エネルギー K(p)**: 補助変数の二次形式\n",
    "- **力 F = -∇U(q)**: 対数確率の勾配 ∇log π(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hamiltonian_concept():\n",
    "    \"\"\"ハミルトニアン力学の概念を可視化\"\"\"\n",
    "    \n",
    "    t = np.linspace(0, 4*np.pi, 1000)\n",
    "    \n",
    "    # 位置（パラメータ）\n",
    "    q = np.cos(t)\n",
    "    # 運動量（補助変数）\n",
    "    p = -np.sin(t)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 位相空間の軌跡\n",
    "    axes[0, 0].plot(q, p, 'b-', linewidth=2)\n",
    "    axes[0, 0].plot(q[0], p[0], 'go', markersize=8, label='開始')\n",
    "    axes[0, 0].plot(q[-1], p[-1], 'ro', markersize=8, label='終了')\n",
    "    axes[0, 0].set_xlabel('位置 q（パラメータ）')\n",
    "    axes[0, 0].set_ylabel('運動量 p（補助変数）')\n",
    "    axes[0, 0].set_title('位相空間での軌跡\\n（エネルギー保存による円軌道）')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_aspect('equal')\n",
    "    \n",
    "    # 時系列\n",
    "    axes[0, 1].plot(t, q, label='位置 q', linewidth=2)\n",
    "    axes[0, 1].plot(t, p, label='運動量 p', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('時間')\n",
    "    axes[0, 1].set_ylabel('値')\n",
    "    axes[0, 1].set_title('時間発展')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # エネルギーの時間変化\n",
    "    energy = 0.5 * (q**2 + p**2)\n",
    "    axes[1, 0].plot(t, energy, 'r-', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('時間')\n",
    "    axes[1, 0].set_ylabel('総エネルギー H(q,p)')\n",
    "    axes[1, 0].set_title('ハミルトニアン（総エネルギー）\\n理想的には一定値')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 確率密度との対応\n",
    "    q_range = np.linspace(-3, 3, 100)\n",
    "    prob_density = np.exp(-0.5 * q_range**2)  # 正規分布\n",
    "    axes[1, 1].plot(q_range, prob_density, 'k-', linewidth=2, label='目標分布')\n",
    "    axes[1, 1].hist(q[::10], bins=30, density=True, alpha=0.7, \n",
    "                   color='blue', label='HMCサンプル')\n",
    "    axes[1, 1].set_xlabel('位置 q')\n",
    "    axes[1, 1].set_ylabel('確率密度')\n",
    "    axes[1, 1].set_title('目標分布の再現')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ハミルトニアン力学の特徴：\")\n",
    "    print(\"1. エネルギー保存：系の総エネルギーが保存される\")\n",
    "    print(\"2. 位相空間：(位置, 運動量)の組み合わせで状態を表現\")\n",
    "    print(\"3. 決定論的発展：初期条件が決まれば軌跡が一意に決まる\")\n",
    "    print(\"4. 可逆性：時間を逆向きに進めることが可能\")\n",
    "\n",
    "visualize_hamiltonian_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 HMCの数学的基礎\n",
    "\n",
    "### ハミルトニアンの定義\n",
    "\n",
    "**MCMCにおけるハミルトニアン**：\n",
    "```\n",
    "H(q, p) = U(q) + K(p)\n",
    "```\n",
    "\n",
    "- **U(q)**: ポテンシャルエネルギー = -log π(q)\n",
    "- **K(p)**: 運動エネルギー = (1/2)p^T M^(-1) p\n",
    "\n",
    "### ハミルトンの運動方程式\n",
    "\n",
    "```\n",
    "dq/dt = ∂H/∂p = M^(-1) p    （位置の時間微分）\n",
    "dp/dt = -∂H/∂q = -∇U(q)     （運動量の時間微分）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamilton_equations_demo():\n",
    "    \"\"\"ハミルトンの運動方程式のデモンストレーション\"\"\"\n",
    "    \n",
    "    print(\"ハミルトンの運動方程式：\")\n",
    "    print(\"dq/dt = ∂H/∂p = M^(-1) p    （位置の時間微分）\")\n",
    "    print(\"dp/dt = -∂H/∂q = -∇U(q)     （運動量の時間微分）\")\n",
    "    print()\n",
    "    \n",
    "    # 1次元調和振動子の例\n",
    "    def harmonic_oscillator_exact(t, q0, p0):\n",
    "        \"\"\"解析解\"\"\"\n",
    "        q = q0 * np.cos(t) + p0 * np.sin(t)\n",
    "        p = -q0 * np.sin(t) + p0 * np.cos(t)\n",
    "        return q, p\n",
    "    \n",
    "    def harmonic_oscillator_euler(dt, steps, q0, p0):\n",
    "        \"\"\"オイラー法による数値解\"\"\"\n",
    "        q, p = q0, p0\n",
    "        trajectory = [(q, p)]\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            # オイラー法（不正確）\n",
    "            q_new = q + dt * p\n",
    "            p_new = p - dt * q\n",
    "            q, p = q_new, p_new\n",
    "            trajectory.append((q, p))\n",
    "        \n",
    "        return np.array(trajectory)\n",
    "    \n",
    "    def harmonic_oscillator_leapfrog(dt, steps, q0, p0):\n",
    "        \"\"\"リープフロッグ法による数値解\"\"\"\n",
    "        q, p = q0, p0\n",
    "        trajectory = [(q, p)]\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            # リープフロッグ法（シンプレクティック）\n",
    "            p_half = p - 0.5 * dt * q\n",
    "            q_new = q + dt * p_half  \n",
    "            p_new = p_half - 0.5 * dt * q_new\n",
    "            q, p = q_new, p_new\n",
    "            trajectory.append((q, p))\n",
    "        \n",
    "        return np.array(trajectory)\n",
    "    \n",
    "    # 初期条件\n",
    "    q0, p0 = 1.0, 0.0\n",
    "    dt = 0.1\n",
    "    steps = 100\n",
    "    t_points = np.arange(0, (steps+1)*dt, dt)\n",
    "    \n",
    "    # 解析解\n",
    "    q_exact, p_exact = harmonic_oscillator_exact(t_points, q0, p0)\n",
    "    \n",
    "    # 数値解\n",
    "    euler_traj = harmonic_oscillator_euler(dt, steps, q0, p0)\n",
    "    leapfrog_traj = harmonic_oscillator_leapfrog(dt, steps, q0, p0)\n",
    "    \n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 位相空間での軌跡\n",
    "    axes[0, 0].plot(q_exact, p_exact, 'k-', linewidth=3, label='解析解', alpha=0.8)\n",
    "    axes[0, 0].plot(euler_traj[:, 0], euler_traj[:, 1], 'r--', \n",
    "                   linewidth=2, label='オイラー法', alpha=0.7)\n",
    "    axes[0, 0].plot(leapfrog_traj[:, 0], leapfrog_traj[:, 1], 'b:', \n",
    "                   linewidth=2, label='リープフロッグ法', alpha=0.9)\n",
    "    axes[0, 0].set_xlabel('位置 q')\n",
    "    axes[0, 0].set_ylabel('運動量 p')\n",
    "    axes[0, 0].set_title('位相空間での軌跡比較')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_aspect('equal')\n",
    "    \n",
    "    # エネルギー保存\n",
    "    energy_exact = 0.5 * (q_exact**2 + p_exact**2)\n",
    "    energy_euler = 0.5 * (euler_traj[:, 0]**2 + euler_traj[:, 1]**2)\n",
    "    energy_leapfrog = 0.5 * (leapfrog_traj[:, 0]**2 + leapfrog_traj[:, 1]**2)\n",
    "    \n",
    "    axes[0, 1].plot(t_points, energy_exact, 'k-', linewidth=3, label='解析解')\n",
    "    axes[0, 1].plot(t_points, energy_euler, 'r--', linewidth=2, label='オイラー法')\n",
    "    axes[0, 1].plot(t_points, energy_leapfrog, 'b:', linewidth=2, label='リープフロッグ法')\n",
    "    axes[0, 1].set_xlabel('時間')\n",
    "    axes[0, 1].set_ylabel('エネルギー')\n",
    "    axes[0, 1].set_title('エネルギー保存性の比較')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 時系列\n",
    "    axes[1, 0].plot(t_points, q_exact, 'k-', linewidth=3, label='解析解 q')\n",
    "    axes[1, 0].plot(t_points, leapfrog_traj[:, 0], 'b:', linewidth=2, label='リープフロッグ q')\n",
    "    axes[1, 0].set_xlabel('時間')\n",
    "    axes[1, 0].set_ylabel('位置 q')\n",
    "    axes[1, 0].set_title('位置の時間発展')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # エネルギー誤差\n",
    "    axes[1, 1].plot(t_points, np.abs(energy_euler - energy_exact[0]), \n",
    "                   'r--', linewidth=2, label='オイラー法')\n",
    "    axes[1, 1].plot(t_points, np.abs(energy_leapfrog - energy_exact[0]), \n",
    "                   'b:', linewidth=2, label='リープフロッグ法')\n",
    "    axes[1, 1].set_xlabel('時間')\n",
    "    axes[1, 1].set_ylabel('|エネルギー誤差|')\n",
    "    axes[1, 1].set_title('エネルギー保存誤差')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"最終エネルギー誤差：\")\n",
    "    print(f\"オイラー法:     {abs(energy_euler[-1] - energy_exact[0]):.6f}\")\n",
    "    print(f\"リープフロッグ法: {abs(energy_leapfrog[-1] - energy_exact[0]):.6f}\")\n",
    "\n",
    "hamilton_equations_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 HMCアルゴリズムの完全実装\n",
    "\n",
    "### 基本的なHMCステップ\n",
    "\n",
    "1. **運動量のサンプリング**: p ~ N(0, M)\n",
    "2. **リープフロッグ積分**: ハミルトンの運動方程式を数値的に解く\n",
    "3. **メトロポリス受理**: エネルギー差に基づいて受理/棄却を決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveHMC:\n",
    "    \"\"\"\n",
    "    教育目的の包括的HMC実装\n",
    "    デバッグ情報と詳細な説明付き\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_prob_fn, grad_log_prob_fn, mass_matrix=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - log_prob_fn: 対数確率密度関数 log π(q)\n",
    "        - grad_log_prob_fn: 勾配関数 ∇log π(q)  \n",
    "        - mass_matrix: 質量行列 M（デフォルトは単位行列）\n",
    "        \"\"\"\n",
    "        self.log_prob_fn = log_prob_fn\n",
    "        self.grad_log_prob_fn = grad_log_prob_fn\n",
    "        self.mass_matrix = mass_matrix\n",
    "        \n",
    "        # 統計情報\n",
    "        self.stats = {\n",
    "            'n_accepted': 0,\n",
    "            'n_proposed': 0,\n",
    "            'hamiltonian_errors': [],\n",
    "            'step_sizes_used': [],\n",
    "            'accept_probs': []\n",
    "        }\n",
    "    \n",
    "    def sample_momentum(self, dim):\n",
    "        \"\"\"運動量のサンプリング\"\"\"\n",
    "        if self.mass_matrix is None:\n",
    "            return np.random.normal(0, 1, dim)\n",
    "        else:\n",
    "            return np.random.multivariate_normal(\n",
    "                np.zeros(dim), self.mass_matrix\n",
    "            )\n",
    "    \n",
    "    def kinetic_energy(self, p):\n",
    "        \"\"\"運動エネルギーの計算\"\"\"\n",
    "        if self.mass_matrix is None:\n",
    "            return 0.5 * np.sum(p**2)\n",
    "        else:\n",
    "            return 0.5 * p.T @ np.linalg.solve(self.mass_matrix, p)\n",
    "    \n",
    "    def potential_energy(self, q):\n",
    "        \"\"\"ポテンシャルエネルギーの計算\"\"\"\n",
    "        return -self.log_prob_fn(q)\n",
    "    \n",
    "    def hamiltonian(self, q, p):\n",
    "        \"\"\"ハミルトニアンの計算\"\"\"\n",
    "        return self.potential_energy(q) + self.kinetic_energy(p)\n",
    "    \n",
    "    def leapfrog_step(self, q, p, epsilon):\n",
    "        \"\"\"リープフロッグ積分による1ステップ\"\"\"\n",
    "        # 運動量の半ステップ更新\n",
    "        p_half = p + 0.5 * epsilon * self.grad_log_prob_fn(q)\n",
    "        \n",
    "        # 位置の全ステップ更新\n",
    "        if self.mass_matrix is None:\n",
    "            q_new = q + epsilon * p_half\n",
    "        else:\n",
    "            q_new = q + epsilon * np.linalg.solve(self.mass_matrix, p_half)\n",
    "        \n",
    "        # 運動量の残り半ステップ更新\n",
    "        p_new = p_half + 0.5 * epsilon * self.grad_log_prob_fn(q_new)\n",
    "        \n",
    "        return q_new, p_new\n",
    "    \n",
    "    def leapfrog_trajectory(self, q_initial, p_initial, epsilon, L):\n",
    "        \"\"\"完全なリープフロッグ軌跡の計算\"\"\"\n",
    "        q, p = q_initial.copy(), p_initial.copy()\n",
    "        trajectory = [(q.copy(), p.copy())]\n",
    "        \n",
    "        for step in range(L):\n",
    "            q, p = self.leapfrog_step(q, p, epsilon)\n",
    "            trajectory.append((q.copy(), p.copy()))\n",
    "        \n",
    "        return q, p, trajectory\n",
    "    \n",
    "    def hmc_step(self, q_current, epsilon, L, verbose=False):\n",
    "        \"\"\"\n",
    "        1回のHMCステップ\n",
    "        \n",
    "        Returns:\n",
    "        - q_new: 新しい位置\n",
    "        - accepted: 受理されたかどうか\n",
    "        - info: 詳細情報辞書\n",
    "        \"\"\"\n",
    "        dim = len(q_current)\n",
    "        \n",
    "        # 1. 運動量のサンプリング\n",
    "        p_current = self.sample_momentum(dim)\n",
    "        \n",
    "        # 2. 現在のハミルトニアン\n",
    "        H_current = self.hamiltonian(q_current, p_current)\n",
    "        \n",
    "        # 3. リープフロッグ積分\n",
    "        q_proposed, p_proposed, trajectory = self.leapfrog_trajectory(\n",
    "            q_current, p_current, epsilon, L\n",
    "        )\n",
    "        \n",
    "        # 4. 運動量の反転（時間反転対称性）\n",
    "        p_proposed = -p_proposed\n",
    "        \n",
    "        # 5. 提案後のハミルトニアン\n",
    "        H_proposed = self.hamiltonian(q_proposed, p_proposed)\n",
    "        \n",
    "        # 6. ハミルトニアン差\n",
    "        delta_H = H_proposed - H_current\n",
    "        \n",
    "        # 7. メトロポリス受理確率\n",
    "        accept_prob = min(1.0, np.exp(-delta_H))\n",
    "        \n",
    "        # 8. 受理/棄却\n",
    "        self.stats['n_proposed'] += 1\n",
    "        if np.random.rand() < accept_prob:\n",
    "            q_new = q_proposed\n",
    "            accepted = True\n",
    "            self.stats['n_accepted'] += 1\n",
    "        else:\n",
    "            q_new = q_current\n",
    "            accepted = False\n",
    "        \n",
    "        # 9. 統計情報の更新\n",
    "        self.stats['hamiltonian_errors'].append(abs(delta_H))\n",
    "        self.stats['step_sizes_used'].append(epsilon)\n",
    "        self.stats['accept_probs'].append(accept_prob)\n",
    "        \n",
    "        # 10. 詳細情報\n",
    "        info = {\n",
    "            'H_current': H_current,\n",
    "            'H_proposed': H_proposed,\n",
    "            'delta_H': delta_H,\n",
    "            'accept_prob': accept_prob,\n",
    "            'accepted': accepted,\n",
    "            'trajectory': trajectory,\n",
    "            'momentum_initial': p_current,\n",
    "            'momentum_final': p_proposed\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"HMCステップ詳細:\")\n",
    "            print(f\"  現在位置: {q_current}\")\n",
    "            print(f\"  提案位置: {q_proposed}\")\n",
    "            print(f\"  ΔH = {delta_H:.6f}\")\n",
    "            print(f\"  受理確率 = {accept_prob:.6f}\")\n",
    "            print(f\"  結果: {'受理' if accepted else '棄却'}\")\n",
    "            print()\n",
    "        \n",
    "        return q_new, accepted, info\n",
    "    \n",
    "    def sample(self, initial_q, n_samples, epsilon, L, verbose=False):\n",
    "        \"\"\"\n",
    "        HMCサンプリングの実行\n",
    "        \n",
    "        Parameters:\n",
    "        - initial_q: 初期位置\n",
    "        - n_samples: サンプル数\n",
    "        - epsilon: ステップサイズ\n",
    "        - L: リープフロッグステップ数\n",
    "        - verbose: 詳細出力フラグ\n",
    "        \n",
    "        Returns:\n",
    "        - samples: サンプル配列\n",
    "        - detailed_info: 各ステップの詳細情報\n",
    "        \"\"\"\n",
    "        dim = len(initial_q)\n",
    "        samples = np.zeros((n_samples, dim))\n",
    "        detailed_info = []\n",
    "        \n",
    "        q_current = initial_q.copy()\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            q_current, accepted, info = self.hmc_step(\n",
    "                q_current, epsilon, L, verbose and i < 5  # 最初の5ステップのみ詳細出力\n",
    "            )\n",
    "            \n",
    "            samples[i] = q_current\n",
    "            detailed_info.append(info)\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                current_accept_rate = self.stats['n_accepted'] / self.stats['n_proposed']\n",
    "                print(f\"Iteration {i+1}/{n_samples}, \"\n",
    "                      f\"Acceptance rate: {current_accept_rate:.3f}, \"\n",
    "                      f\"Mean |ΔH|: {np.mean(self.stats['hamiltonian_errors'][-100:]):.6f}\")\n",
    "        \n",
    "        return samples, detailed_info\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"統計情報の取得\"\"\"\n",
    "        if self.stats['n_proposed'] == 0:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'acceptance_rate': self.stats['n_accepted'] / self.stats['n_proposed'],\n",
    "            'mean_hamiltonian_error': np.mean(self.stats['hamiltonian_errors']),\n",
    "            'std_hamiltonian_error': np.std(self.stats['hamiltonian_errors']),\n",
    "            'mean_accept_prob': np.mean(self.stats['accept_probs']),\n",
    "            'n_samples': self.stats['n_proposed']\n",
    "        }\n",
    "\n",
    "print(\"HMC実装クラスが定義されました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMC実装のテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comprehensive_hmc():\n",
    "    \"\"\"包括的HMC実装のテスト\"\"\"\n",
    "    \n",
    "    # 目標分布：2次元正規分布\n",
    "    mu = np.array([1.0, -0.5])\n",
    "    cov = np.array([[2.0, 1.2], [1.2, 1.5]])\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    \n",
    "    def log_prob(q):\n",
    "        diff = q - mu\n",
    "        return -0.5 * diff.T @ cov_inv @ diff\n",
    "    \n",
    "    def grad_log_prob(q):\n",
    "        return -cov_inv @ (q - mu)\n",
    "    \n",
    "    # HMCサンプラーの作成\n",
    "    hmc = ComprehensiveHMC(log_prob, grad_log_prob)\n",
    "    \n",
    "    print(\"=== HMC実装テスト開始 ===\")\n",
    "    print()\n",
    "    \n",
    "    # サンプリング実行\n",
    "    initial_q = np.array([0.0, 0.0])\n",
    "    samples, detailed_info = hmc.sample(\n",
    "        initial_q=initial_q,\n",
    "        n_samples=1000,\n",
    "        epsilon=0.2,\n",
    "        L=25,\n",
    "        verbose=True  # 最初の5ステップの詳細を表示\n",
    "    )\n",
    "    \n",
    "    # 統計情報の表示\n",
    "    stats = hmc.get_statistics()\n",
    "    print(\"\\n=== 最終統計 ===\")\n",
    "    for key, value in stats.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    return samples, detailed_info, hmc\n",
    "\n",
    "# テスト実行\n",
    "samples, detailed_info, hmc_instance = test_comprehensive_hmc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の可視化\n",
    "def visualize_hmc_results(samples, detailed_info, mu, cov):\n",
    "    \"\"\"HMC結果の包括的可視化\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # サンプル散布図\n",
    "    burnin = 100\n",
    "    clean_samples = samples[burnin:]\n",
    "    \n",
    "    axes[0, 0].scatter(clean_samples[:, 0], clean_samples[:, 1], alpha=0.6, s=10)\n",
    "    axes[0, 0].scatter(mu[0], mu[1], color='red', s=100, marker='x', \n",
    "                      linewidth=3, label='真の平均')\n",
    "    axes[0, 0].set_title('HMCサンプル')\n",
    "    axes[0, 0].set_xlabel('q1')\n",
    "    axes[0, 0].set_ylabel('q2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_aspect('equal')\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 1].plot(samples[:500, 0], alpha=0.8, label='q1', linewidth=0.8)\n",
    "    axes[0, 1].plot(samples[:500, 1], alpha=0.8, label='q2', linewidth=0.8)\n",
    "    axes[0, 1].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[0, 1].set_title('トレースプロット')\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('Value')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ハミルトニアン誤差\n",
    "    errors = [info['delta_H'] for info in detailed_info]\n",
    "    axes[0, 2].plot(np.abs(errors[:500]), alpha=0.8, linewidth=0.8)\n",
    "    axes[0, 2].set_title('ハミルトニアン誤差 |ΔH|')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('|ΔH|')\n",
    "    axes[0, 2].set_yscale('log')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 受理確率の分布\n",
    "    accept_probs = [info['accept_prob'] for info in detailed_info]\n",
    "    axes[1, 0].hist(accept_probs, bins=30, alpha=0.7, density=True)\n",
    "    axes[1, 0].set_title('受理確率の分布')\n",
    "    axes[1, 0].set_xlabel('受理確率')\n",
    "    axes[1, 0].set_ylabel('密度')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 軌跡の例\n",
    "    sample_trajectory = detailed_info[50]['trajectory']  # 50番目のステップの軌跡\n",
    "    traj_q = np.array([traj[0] for traj in sample_trajectory])\n",
    "    \n",
    "    axes[1, 1].plot(traj_q[:, 0], traj_q[:, 1], 'bo-', markersize=4, \n",
    "                   linewidth=1.5, alpha=0.7)\n",
    "    axes[1, 1].plot(traj_q[0, 0], traj_q[0, 1], 'go', markersize=8, label='開始')\n",
    "    axes[1, 1].plot(traj_q[-1, 0], traj_q[-1, 1], 'ro', markersize=8, label='終了')\n",
    "    axes[1, 1].set_title('リープフロッグ軌跡の例')\n",
    "    axes[1, 1].set_xlabel('q1')\n",
    "    axes[1, 1].set_ylabel('q2')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_aspect('equal')\n",
    "    \n",
    "    # 統計比較\n",
    "    sample_mean = np.mean(clean_samples, axis=0)\n",
    "    sample_cov = np.cov(clean_samples.T)\n",
    "    \n",
    "    comparison_data = [\n",
    "        ['平均 q1', mu[0], sample_mean[0], abs(mu[0] - sample_mean[0])],\n",
    "        ['平均 q2', mu[1], sample_mean[1], abs(mu[1] - sample_mean[1])],\n",
    "        ['分散 q1', cov[0,0], sample_cov[0,0], abs(cov[0,0] - sample_cov[0,0])],\n",
    "        ['分散 q2', cov[1,1], sample_cov[1,1], abs(cov[1,1] - sample_cov[1,1])],\n",
    "        ['共分散', cov[0,1], sample_cov[0,1], abs(cov[0,1] - sample_cov[0,1])]\n",
    "    ]\n",
    "    \n",
    "    axes[1, 2].axis('off')\n",
    "    table_text = \"統計比較\\n\\n\"\n",
    "    table_text += f\"{'統計量':<8} {'真値':<8} {'推定値':<8} {'誤差':<8}\\n\"\n",
    "    table_text += \"-\" * 40 + \"\\n\"\n",
    "    for row in comparison_data:\n",
    "        table_text += f\"{row[0]:<8} {row[1]:<8.3f} {row[2]:<8.3f} {row[3]:<8.3f}\\n\"\n",
    "    \n",
    "    axes[1, 2].text(0.1, 0.8, table_text, transform=axes[1, 2].transAxes,\n",
    "                   fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可視化実行\n",
    "mu = np.array([1.0, -0.5])\n",
    "cov = np.array([[2.0, 1.2], [1.2, 1.5]])\n",
    "visualize_hmc_results(samples, detailed_info, mu, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 HMC vs 従来手法：性能比較\n",
    "\n",
    "ランダムウォーク・メトロポリス・ヘイスティングス法とHMCの性能を定量的に比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hmc_vs_rwmh():\n",
    "    \"\"\"HMC vs ランダムウォークMHの性能比較\"\"\"\n",
    "    \n",
    "    # ランダムウォークMHの実装\n",
    "    def random_walk_mh(log_prob_fn, initial_value, n_samples, step_size=0.5):\n",
    "        \"\"\"ランダムウォーク・メトロポリス・ヘイスティングス法\"\"\"\n",
    "        dim = len(initial_value)\n",
    "        samples = np.zeros((n_samples, dim))\n",
    "        current = initial_value.copy()\n",
    "        current_log_prob = log_prob_fn(current)\n",
    "        n_accepted = 0\n",
    "        \n",
    "        proposal_cov = step_size**2 * np.eye(dim)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # 提案\n",
    "            proposed = np.random.multivariate_normal(current, proposal_cov)\n",
    "            proposed_log_prob = log_prob_fn(proposed)\n",
    "            \n",
    "            # 受理確率\n",
    "            log_alpha = proposed_log_prob - current_log_prob\n",
    "            alpha = min(1.0, np.exp(log_alpha))\n",
    "            \n",
    "            # 受理/棄却\n",
    "            if np.random.rand() < alpha:\n",
    "                current = proposed\n",
    "                current_log_prob = proposed_log_prob\n",
    "                n_accepted += 1\n",
    "            \n",
    "            samples[i] = current\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"Iteration {i+1}/{n_samples}, Acceptance rate: {n_accepted/(i+1):.3f}\")\n",
    "        \n",
    "        acceptance_rate = n_accepted / n_samples\n",
    "        return samples, acceptance_rate\n",
    "    \n",
    "    # 効率指標の計算\n",
    "    def compute_efficiency_metrics(samples, burnin_frac=0.1):\n",
    "        \"\"\"効率指標の計算\"\"\"\n",
    "        burnin = int(len(samples) * burnin_frac)\n",
    "        clean_samples = samples[burnin:]\n",
    "        \n",
    "        # 各次元の自己相関時間を計算\n",
    "        autocorr_times = []\n",
    "        eff_sample_sizes = []\n",
    "        \n",
    "        for dim in range(clean_samples.shape[1]):\n",
    "            data = clean_samples[:, dim]\n",
    "            lags = min(200, len(data) // 4)\n",
    "            \n",
    "            # 自己相関の計算\n",
    "            data_centered = data - np.mean(data)\n",
    "            autocorr = np.correlate(data_centered, data_centered, mode='full')\n",
    "            autocorr = autocorr[len(autocorr)//2:]\n",
    "            autocorr = autocorr / autocorr[0]\n",
    "            \n",
    "            # 統合自己相関時間\n",
    "            tau_int = 1.0\n",
    "            for lag in range(1, min(len(autocorr), lags)):\n",
    "                if autocorr[lag] > 0.01:\n",
    "                    tau_int += 2 * autocorr[lag]\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            autocorr_times.append(tau_int)\n",
    "            eff_sample_sizes.append(len(data) / (2 * tau_int + 1))\n",
    "        \n",
    "        return autocorr_times, eff_sample_sizes\n",
    "    \n",
    "    # 目標分布の設定\n",
    "    mu_target = np.array([0.0, 0.0])\n",
    "    cov_target = np.array([[1.0, 0.8], [0.8, 1.0]])\n",
    "    cov_inv = np.linalg.inv(cov_target)\n",
    "    \n",
    "    def log_prob(x):\n",
    "        diff = x - mu_target\n",
    "        return -0.5 * diff.T @ cov_inv @ diff\n",
    "    \n",
    "    def grad_log_prob(x):\n",
    "        return -cov_inv @ (x - mu_target)\n",
    "    \n",
    "    # 比較実験の実行\n",
    "    print(\"ランダムウォークMHサンプリング実行中...\")\n",
    "    rwmh_samples, rwmh_acceptance_rate = random_walk_mh(\n",
    "        log_prob_fn=log_prob,\n",
    "        initial_value=np.array([0.0, 0.0]),\n",
    "        n_samples=5000,\n",
    "        step_size=0.8\n",
    "    )\n",
    "    \n",
    "    print(\"\\nHMCサンプリング実行中...\")\n",
    "    hmc = ComprehensiveHMC(log_prob, grad_log_prob)\n",
    "    hmc_samples, _ = hmc.sample(\n",
    "        initial_q=np.array([0.0, 0.0]),\n",
    "        n_samples=5000,\n",
    "        epsilon=0.25,\n",
    "        L=20\n",
    "    )\n",
    "    \n",
    "    hmc_stats = hmc.get_statistics()\n",
    "    \n",
    "    print(f\"\\nランダムウォークMH受理率: {rwmh_acceptance_rate:.3f}\")\n",
    "    print(f\"HMC受理率: {hmc_stats['acceptance_rate']:.3f}\")\n",
    "    \n",
    "    # 効率比較\n",
    "    hmc_autocorr, hmc_eff = compute_efficiency_metrics(hmc_samples)\n",
    "    rwmh_autocorr, rwmh_eff = compute_efficiency_metrics(rwmh_samples)\n",
    "    \n",
    "    print(f\"\\n=== 効率比較 ===\")\n",
    "    print(f\"{'Method':<12} {'Dim':<5} {'Acceptance':<12} {'Autocorr Time':<15} {'Eff Sample Size':<18} {'Efficiency':<12}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for dim in range(2):\n",
    "        print(f\"{'HMC':<12} {'X'+str(dim+1):<5} {hmc_stats['acceptance_rate']:<12.3f} \"\n",
    "              f\"{hmc_autocorr[dim]:<15.2f} {hmc_eff[dim]:<18.1f} {hmc_eff[dim]/len(hmc_samples[500:]):<12.3f}\")\n",
    "        print(f\"{'Random Walk':<12} {'X'+str(dim+1):<5} {rwmh_acceptance_rate:<12.3f} \"\n",
    "              f\"{rwmh_autocorr[dim]:<15.2f} {rwmh_eff[dim]:<18.1f} {rwmh_eff[dim]/len(rwmh_samples[500:]):<12.3f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"平均効率比（HMC/RWMH）: {np.mean(hmc_eff)/np.mean(rwmh_eff):.2f}\")\n",
    "    \n",
    "    return hmc_samples, rwmh_samples, hmc_eff, rwmh_eff\n",
    "\n",
    "# 比較実験実行\n",
    "hmc_samples, rwmh_samples, hmc_eff, rwmh_eff = compare_hmc_vs_rwmh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較結果の可視化\n",
    "def visualize_comparison(hmc_samples, rwmh_samples, hmc_eff, rwmh_eff):\n",
    "    \"\"\"HMC vs ランダムウォークMHの可視化比較\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 10))\n",
    "    \n",
    "    burnin = 500\n",
    "    hmc_clean = hmc_samples[burnin:]\n",
    "    rwmh_clean = rwmh_samples[burnin:]\n",
    "    \n",
    "    # トレースプロット比較\n",
    "    axes[0, 0].plot(hmc_samples[:2000, 0], alpha=0.8, label='HMC', linewidth=0.8, color='blue')\n",
    "    axes[0, 0].plot(rwmh_samples[:2000, 0], alpha=0.8, label='RWMH', linewidth=0.8, color='red')\n",
    "    axes[0, 0].axvline(burnin, color='gray', linestyle='--', alpha=0.7)\n",
    "    axes[0, 0].set_title('Trace Plot Comparison (X1)')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('X1')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 散布図比較\n",
    "    axes[0, 1].scatter(hmc_clean[::10, 0], hmc_clean[::10, 1], alpha=0.6, s=5, color='blue', label='HMC')\n",
    "    axes[0, 1].scatter(rwmh_clean[::10, 0], rwmh_clean[::10, 1], alpha=0.6, s=5, color='red', label='RWMH')\n",
    "    axes[0, 1].set_title('Sample Scatter Plot')\n",
    "    axes[0, 1].set_xlabel('X1')\n",
    "    axes[0, 1].set_ylabel('X2')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].set_aspect('equal')\n",
    "    \n",
    "    # 自己相関比較\n",
    "    lags = min(100, len(hmc_clean) // 10)\n",
    "    \n",
    "    # HMC自己相関\n",
    "    hmc_data = hmc_clean[:, 0] - np.mean(hmc_clean[:, 0])\n",
    "    hmc_autocorr = np.correlate(hmc_data, hmc_data, mode='full')\n",
    "    hmc_autocorr = hmc_autocorr[len(hmc_autocorr)//2:lags]\n",
    "    hmc_autocorr = hmc_autocorr / hmc_autocorr[0]\n",
    "    \n",
    "    # RWMH自己相関\n",
    "    rwmh_data = rwmh_clean[:, 0] - np.mean(rwmh_clean[:, 0])\n",
    "    rwmh_autocorr = np.correlate(rwmh_data, rwmh_data, mode='full')\n",
    "    rwmh_autocorr = rwmh_autocorr[len(rwmh_autocorr)//2:lags]\n",
    "    rwmh_autocorr = rwmh_autocorr / rwmh_autocorr[0]\n",
    "    \n",
    "    axes[0, 2].plot(hmc_autocorr, label='HMC', alpha=0.8, color='blue')\n",
    "    axes[0, 2].plot(rwmh_autocorr, label='RWMH', alpha=0.8, color='red')\n",
    "    axes[0, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].axhline(0.05, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].set_title('Autocorrelation Comparison (X1)')\n",
    "    axes[0, 2].set_xlabel('Lag')\n",
    "    axes[0, 2].set_ylabel('ACF')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 効率指標の比較\n",
    "    methods = ['HMC', 'RWMH']\n",
    "    x1_eff = [hmc_eff[0], rwmh_eff[0]]\n",
    "    x2_eff = [hmc_eff[1], rwmh_eff[1]]\n",
    "    \n",
    "    x_pos = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0, 3].bar(x_pos - width/2, x1_eff, width, label='X1', alpha=0.7, color='lightblue')\n",
    "    axes[0, 3].bar(x_pos + width/2, x2_eff, width, label='X2', alpha=0.7, color='lightcoral')\n",
    "    axes[0, 3].set_title('Effective Sample Size')\n",
    "    axes[0, 3].set_xlabel('Method')\n",
    "    axes[0, 3].set_ylabel('Effective Sample Size')\n",
    "    axes[0, 3].set_xticks(x_pos)\n",
    "    axes[0, 3].set_xticklabels(methods)\n",
    "    axes[0, 3].legend()\n",
    "    axes[0, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 軌跡の比較（最初の200ステップ）\n",
    "    hmc_traj = hmc_samples[:200]\n",
    "    rwmh_traj = rwmh_samples[:200]\n",
    "    \n",
    "    axes[1, 0].plot(hmc_traj[:, 0], hmc_traj[:, 1], 'b-', alpha=0.7, linewidth=1, label='HMC')\n",
    "    axes[1, 0].plot(hmc_traj[:, 0], hmc_traj[:, 1], 'b.', markersize=2, alpha=0.8)\n",
    "    axes[1, 0].set_title('HMC Trajectory (first 200)')\n",
    "    axes[1, 0].set_xlabel('X1')\n",
    "    axes[1, 0].set_ylabel('X2')\n",
    "    axes[1, 0].set_aspect('equal')\n",
    "    \n",
    "    axes[1, 1].plot(rwmh_traj[:, 0], rwmh_traj[:, 1], 'r-', alpha=0.7, linewidth=1, label='RWMH')\n",
    "    axes[1, 1].plot(rwmh_traj[:, 0], rwmh_traj[:, 1], 'r.', markersize=2, alpha=0.8)\n",
    "    axes[1, 1].set_title('RWMH Trajectory (first 200)')\n",
    "    axes[1, 1].set_xlabel('X1')\n",
    "    axes[1, 1].set_ylabel('X2')\n",
    "    axes[1, 1].set_aspect('equal')\n",
    "    \n",
    "    # ステップサイズの効果\n",
    "    step_distances_hmc = np.sqrt(np.sum(np.diff(hmc_samples[:1000], axis=0)**2, axis=1))\n",
    "    step_distances_rwmh = np.sqrt(np.sum(np.diff(rwmh_samples[:1000], axis=0)**2, axis=1))\n",
    "    \n",
    "    axes[1, 2].hist(step_distances_hmc, bins=30, alpha=0.7, density=True, color='blue', label='HMC')\n",
    "    axes[1, 2].hist(step_distances_rwmh, bins=30, alpha=0.7, density=True, color='red', label='RWMH')\n",
    "    axes[1, 2].set_title('Step Size Distribution')\n",
    "    axes[1, 2].set_xlabel('Step Distance')\n",
    "    axes[1, 2].set_ylabel('Density')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    # 探索効率（単位時間あたりの有効サンプル数）\n",
    "    # 注：実際の計算時間は測定していないため、理論的な比較\n",
    "    # HMCは1ステップあたりより多くの計算が必要だが、より効率的\n",
    "    axes[1, 3].bar(['HMC', 'RWMH'], \n",
    "                   [np.mean(hmc_eff)/20, np.mean(rwmh_eff)],  # HMCは20倍の計算コストと仮定\n",
    "                   alpha=0.7, color=['blue', 'red'])\n",
    "    axes[1, 3].set_title('Computational Efficiency\\n(ESS per unit computation)')\n",
    "    axes[1, 3].set_ylabel('Relative Efficiency')\n",
    "    axes[1, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 比較可視化実行\n",
    "visualize_comparison(hmc_samples, rwmh_samples, hmc_eff, rwmh_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 実践的パラメータチューニング\n",
    "\n",
    "HMCの性能は、ステップサイズ（ε）とリープフロッグステップ数（L）の設定に大きく依存します。最適なパラメータを見つけるための体系的手法を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmc_parameter_optimization():\n",
    "    \"\"\"HMCパラメータの体系的最適化\"\"\"\n",
    "    \n",
    "    # 目標分布の設定（病的な条件数を持つ分布）\n",
    "    dim = 3\n",
    "    mu = np.zeros(dim)\n",
    "    eigenvalues = np.array([10.0, 1.0, 0.1])  # 条件数100\n",
    "    eigenvectors = np.random.randn(dim, dim)\n",
    "    eigenvectors, _ = np.linalg.qr(eigenvectors)\n",
    "    cov = eigenvectors @ np.diag(eigenvalues) @ eigenvectors.T\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    \n",
    "    def log_prob(q):\n",
    "        diff = q - mu\n",
    "        return -0.5 * diff.T @ cov_inv @ diff\n",
    "    \n",
    "    def grad_log_prob(q):\n",
    "        return -cov_inv @ (q - mu)\n",
    "    \n",
    "    print(\"目標分布の条件数:\", np.linalg.cond(cov))\n",
    "    print(\"固有値:\", eigenvalues)\n",
    "    print()\n",
    "    \n",
    "    # パラメータグリッドの設定\n",
    "    epsilons = np.logspace(-2, -0.3, 6)  # 0.01 から 0.5\n",
    "    L_values = [5, 10, 20, 30]\n",
    "    \n",
    "    # 結果保存用\n",
    "    results_grid = np.zeros((len(epsilons), len(L_values), 4))  # accept_rate, autocorr_time, ess, mean_error\n",
    "    \n",
    "    print(\"パラメータ最適化実行中...\")\n",
    "    print(f\"グリッド サイズ: {len(epsilons)} × {len(L_values)} = {len(epsilons) * len(L_values)} 組み合わせ\")\n",
    "    print()\n",
    "    \n",
    "    total_combinations = len(epsilons) * len(L_values)\n",
    "    combination_count = 0\n",
    "    \n",
    "    for i, epsilon in enumerate(epsilons):\n",
    "        for j, L in enumerate(L_values):\n",
    "            combination_count += 1\n",
    "            \n",
    "            # HMCサンプリング\n",
    "            hmc = ComprehensiveHMC(log_prob, grad_log_prob)\n",
    "            samples, _ = hmc.sample(\n",
    "                initial_q=np.zeros(dim),\n",
    "                n_samples=1000,\n",
    "                epsilon=epsilon,\n",
    "                L=L\n",
    "            )\n",
    "            \n",
    "            stats = hmc.get_statistics()\n",
    "            \n",
    "            # 自己相関時間の計算\n",
    "            burnin = 200\n",
    "            clean_samples = samples[burnin:]\n",
    "            \n",
    "            autocorr_times = []\n",
    "            for d in range(dim):\n",
    "                data = clean_samples[:, d]\n",
    "                data = data - np.mean(data)\n",
    "                autocorr = np.correlate(data, data, mode='full')\n",
    "                autocorr = autocorr[len(autocorr)//2:]\n",
    "                autocorr = autocorr / autocorr[0]\n",
    "                \n",
    "                tau_int = 1.0\n",
    "                for lag in range(1, min(len(autocorr), 100)):\n",
    "                    if autocorr[lag] > 0.01:\n",
    "                        tau_int += 2 * autocorr[lag]\n",
    "                    else:\n",
    "                        break\n",
    "                autocorr_times.append(tau_int)\n",
    "            \n",
    "            mean_autocorr_time = np.mean(autocorr_times)\n",
    "            ess = len(clean_samples) / (2 * mean_autocorr_time + 1)\n",
    "            \n",
    "            # 結果の保存\n",
    "            results_grid[i, j, 0] = stats['acceptance_rate']\n",
    "            results_grid[i, j, 1] = mean_autocorr_time\n",
    "            results_grid[i, j, 2] = ess\n",
    "            results_grid[i, j, 3] = stats['mean_hamiltonian_error']\n",
    "            \n",
    "            if combination_count % 4 == 0:\n",
    "                print(f\"進捗: {combination_count}/{total_combinations} \"\n",
    "                      f\"({100*combination_count/total_combinations:.1f}%)\")\n",
    "    \n",
    "    # 最適解の特定\n",
    "    best_i, best_j = np.unravel_index(np.argmax(results_grid[:, :, 2]), \n",
    "                                      results_grid[:, :, 2].shape)\n",
    "    best_epsilon = epsilons[best_i]\n",
    "    best_L = L_values[best_j]\n",
    "    \n",
    "    print(f\"\\n最適パラメータ: ε = {best_epsilon:.3f}, L = {best_L}\")\n",
    "    print(f\"期待性能:\")\n",
    "    print(f\"  受理率: {results_grid[best_i, best_j, 0]:.3f}\")\n",
    "    print(f\"  ESS: {results_grid[best_i, best_j, 2]:.1f}\")\n",
    "    \n",
    "    return results_grid, epsilons, L_values, best_epsilon, best_L\n",
    "\n",
    "# パラメータ最適化の実行\n",
    "optimization_results = hmc_parameter_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化結果の可視化\n",
    "def visualize_optimization_results(results_grid, epsilons, L_values):\n",
    "    \"\"\"パラメータ最適化結果の可視化\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # ヒートマップ用のデータ準備\n",
    "    epsilon_labels = [f\"{eps:.3f}\" for eps in epsilons]\n",
    "    L_labels = [str(L) for L in L_values]\n",
    "    \n",
    "    # 1. 受理率\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    im1 = ax1.imshow(results_grid[:, :, 0], aspect='auto', cmap='viridis', \n",
    "                     vmin=0, vmax=1)\n",
    "    ax1.set_title('受理率')\n",
    "    ax1.set_xlabel('リープフロッグステップ数 L')\n",
    "    ax1.set_ylabel('ステップサイズ ε')\n",
    "    ax1.set_xticks(range(len(L_values)))\n",
    "    ax1.set_xticklabels(L_labels)\n",
    "    ax1.set_yticks(range(len(epsilons)))\n",
    "    ax1.set_yticklabels(epsilon_labels)\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # 2. 自己相関時間\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    im2 = ax2.imshow(np.log10(results_grid[:, :, 1]), aspect='auto', cmap='viridis_r')\n",
    "    ax2.set_title('自己相関時間 (log10)')\n",
    "    ax2.set_xlabel('リープフロッグステップ数 L')\n",
    "    ax2.set_ylabel('ステップサイズ ε')\n",
    "    ax2.set_xticks(range(len(L_values)))\n",
    "    ax2.set_xticklabels(L_labels)\n",
    "    ax2.set_yticks(range(len(epsilons)))\n",
    "    ax2.set_yticklabels(epsilon_labels)\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    # 3. 有効サンプルサイズ\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    im3 = ax3.imshow(results_grid[:, :, 2], aspect='auto', cmap='viridis')\n",
    "    ax3.set_title('有効サンプルサイズ')\n",
    "    ax3.set_xlabel('リープフロッグステップ数 L')\n",
    "    ax3.set_ylabel('ステップサイズ ε')\n",
    "    ax3.set_xticks(range(len(L_values)))\n",
    "    ax3.set_xticklabels(L_labels)\n",
    "    ax3.set_yticks(range(len(epsilons)))\n",
    "    ax3.set_yticklabels(epsilon_labels)\n",
    "    plt.colorbar(im3, ax=ax3)\n",
    "    \n",
    "    # 4. ハミルトニアン誤差\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    im4 = ax4.imshow(np.log10(results_grid[:, :, 3]), aspect='auto', cmap='viridis_r')\n",
    "    ax4.set_title('ハミルトニアン誤差 (log10)')\n",
    "    ax4.set_xlabel('リープフロッグステップ数 L')\n",
    "    ax4.set_ylabel('ステップサイズ ε')\n",
    "    ax4.set_xticks(range(len(L_values)))\n",
    "    ax4.set_xticklabels(L_labels)\n",
    "    ax4.set_yticks(range(len(epsilons)))\n",
    "    ax4.set_yticklabels(epsilon_labels)\n",
    "    plt.colorbar(im4, ax=ax4)\n",
    "    \n",
    "    # 5. パレート最適解の可視化\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    \n",
    "    # 全組み合わせをプロット\n",
    "    accept_rates_flat = results_grid[:, :, 0].flatten()\n",
    "    ess_flat = results_grid[:, :, 2].flatten()\n",
    "    \n",
    "    scatter = ax5.scatter(accept_rates_flat, ess_flat, c=results_grid[:, :, 1].flatten(), \n",
    "                         cmap='viridis_r', alpha=0.7, s=50)\n",
    "    \n",
    "    # 最適解をハイライト\n",
    "    best_i, best_j = np.unravel_index(np.argmax(results_grid[:, :, 2]), \n",
    "                                      results_grid[:, :, 2].shape)\n",
    "    ax5.scatter(results_grid[best_i, best_j, 0], results_grid[best_i, best_j, 2], \n",
    "               color='red', s=100, marker='*', \n",
    "               label=f'最適解 (ε={epsilons[best_i]:.3f}, L={L_values[best_j]})')\n",
    "    ax5.set_xlabel('受理率')\n",
    "    ax5.set_ylabel('有効サンプルサイズ')\n",
    "    ax5.set_title('パフォーマンス散布図')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax5, label='自己相関時間')\n",
    "    \n",
    "    # 6. 最適化サマリー\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # 上位5つの組み合わせ\n",
    "    ess_indices = np.unravel_index(np.argsort(results_grid[:, :, 2].flatten())[-5:],\n",
    "                                   results_grid[:, :, 2].shape)\n",
    "    \n",
    "    summary_text = \"最適パラメータ (ESS上位5位)\\n\\n\"\n",
    "    summary_text += f\"{'順位':<4} {'ε':<8} {'L':<4} {'受理率':<8} {'τ':<8} {'ESS':<8}\\n\"\n",
    "    summary_text += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    for rank, (i, j) in enumerate(zip(ess_indices[0][::-1], ess_indices[1][::-1])):\n",
    "        eps = epsilons[i]\n",
    "        L = L_values[j]\n",
    "        accept_rate = results_grid[i, j, 0]\n",
    "        autocorr_time = results_grid[i, j, 1]\n",
    "        ess = results_grid[i, j, 2]\n",
    "        \n",
    "        summary_text += f\"{rank+1:<4} {eps:<8.3f} {L:<4} {accept_rate:<8.3f} \"\n",
    "        summary_text += f\"{autocorr_time:<8.2f} {ess:<8.1f}\\n\"\n",
    "    \n",
    "    best_epsilon = epsilons[best_i]\n",
    "    best_L = L_values[best_j]\n",
    "    summary_text += f\"\\n推奨設定:\\n\"\n",
    "    summary_text += f\"ε = {best_epsilon:.3f}\\n\"\n",
    "    summary_text += f\"L = {best_L}\\n\"\n",
    "    summary_text += f\"期待性能:\\n\"\n",
    "    summary_text += f\"  受理率: {results_grid[best_i, best_j, 0]:.3f}\\n\"\n",
    "    summary_text += f\"  ESS: {results_grid[best_i, best_j, 2]:.1f}\\n\"\n",
    "    \n",
    "    ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes,\n",
    "            fontsize=9, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可視化実行\n",
    "results_grid, epsilons, L_values, best_epsilon, best_L = optimization_results\n",
    "visualize_optimization_results(results_grid, epsilons, L_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 階層ベイズモデルでのHMC応用\n",
    "\n",
    "実際の統計問題への応用例として、学校の成績分析を行う階層ベイズモデルをHMCで解いてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_bayes_hmc_example():\n",
    "    \"\"\"階層ベイズモデルでのHMC応用例\"\"\"\n",
    "    \n",
    "    print(\"=== 階層ベイズモデル例：学校の成績分析 ===\")\n",
    "    print()\n",
    "    \n",
    "    # データ生成（８つの学校の成績データ）\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 真のパラメータ\n",
    "    n_schools = 6\n",
    "    true_mu = 5.0  # 全体平均\n",
    "    true_tau = 2.0  # 学校間のばらつき\n",
    "    true_theta = np.random.normal(true_mu, true_tau, n_schools)  # 各学校の真の平均\n",
    "    school_sigmas = np.array([2.0, 1.5, 2.5, 1.8, 2.2, 1.6])  # 既知の学校内標準偏差\n",
    "    \n",
    "    # 観測データ\n",
    "    school_sizes = [20, 15, 25, 18, 22, 16]\n",
    "    observed_data = []\n",
    "    \n",
    "    for i in range(n_schools):\n",
    "        school_data = np.random.normal(true_theta[i], school_sigmas[i], school_sizes[i])\n",
    "        observed_data.append(school_data)\n",
    "    \n",
    "    # 観測統計量\n",
    "    school_means = [np.mean(data) for data in observed_data]\n",
    "    \n",
    "    print(\"観測データサマリー:\")\n",
    "    print(f\"{'学校':<4} {'サイズ':<6} {'観測平均':<10} {'真の平均':<10} {'標準偏差':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for i in range(n_schools):\n",
    "        print(f\"{i+1:<4} {school_sizes[i]:<6} {school_means[i]:<10.3f} {true_theta[i]:<10.3f} {school_sigmas[i]:<10.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # 階層ベイズモデルの定義\n",
    "    def hierarchical_log_prob(params):\n",
    "        \"\"\"\n",
    "        階層ベイズモデルの対数事後確率\n",
    "        params = [mu, log_tau, theta_1, ..., theta_n]\n",
    "        \"\"\"\n",
    "        mu = params[0]\n",
    "        log_tau = params[1] \n",
    "        tau = np.exp(log_tau)  # 正の制約のためlog変換\n",
    "        theta = params[2:2+n_schools]\n",
    "        \n",
    "        log_prob = 0.0\n",
    "        \n",
    "        # 事前分布\n",
    "        log_prob += -0.5 * (mu - 0)**2 / 100**2  # μ ~ N(0, 100)\n",
    "        log_prob += -0.5 * (log_tau - 0)**2 / 10**2  # log(τ) ~ N(0, 10)\n",
    "        \n",
    "        # 階層構造: θ_i | μ, τ ~ N(μ, τ)\n",
    "        for i in range(n_schools):\n",
    "            log_prob += -0.5 * (theta[i] - mu)**2 / tau**2\n",
    "        \n",
    "        # 尤度: y_ij | θ_i ~ N(θ_i, σ_i)\n",
    "        for i in range(n_schools):\n",
    "            n_i = school_sizes[i]\n",
    "            y_bar_i = school_means[i]\n",
    "            sigma_i = school_sigmas[i]\n",
    "            \n",
    "            # 十分統計量を使った尤度\n",
    "            log_prob += -0.5 * n_i * (y_bar_i - theta[i])**2 / sigma_i**2\n",
    "        \n",
    "        return log_prob\n",
    "    \n",
    "    def hierarchical_grad_log_prob(params):\n",
    "        \"\"\"階層ベイズモデルの勾配\"\"\"\n",
    "        mu = params[0]\n",
    "        log_tau = params[1]\n",
    "        tau = np.exp(log_tau)\n",
    "        theta = params[2:2+n_schools]\n",
    "        \n",
    "        grad = np.zeros_like(params)\n",
    "        \n",
    "        # ∂/∂μ\n",
    "        grad[0] = -mu / 100**2  # 事前分布\n",
    "        for i in range(n_schools):\n",
    "            grad[0] += (theta[i] - mu) / tau**2  # 階層構造\n",
    "        \n",
    "        # ∂/∂log_τ\n",
    "        grad[1] = -log_tau / 10**2  # 事前分布\n",
    "        grad[1] += n_schools  # |dτ/d(log τ)| = τ からのヤコビアン\n",
    "        for i in range(n_schools):\n",
    "            grad[1] += -(theta[i] - mu)**2 / tau**2  # 階層構造\n",
    "        \n",
    "        # ∂/∂θ_i\n",
    "        for i in range(n_schools):\n",
    "            grad[2+i] = -(theta[i] - mu) / tau**2  # 階層構造\n",
    "            \n",
    "            n_i = school_sizes[i]\n",
    "            y_bar_i = school_means[i]\n",
    "            sigma_i = school_sigmas[i]\n",
    "            grad[2+i] += n_i * (y_bar_i - theta[i]) / sigma_i**2  # 尤度\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    # HMCサンプリング\n",
    "    print(\"階層ベイズモデルのHMCサンプリング実行中...\")\n",
    "    \n",
    "    # 初期値\n",
    "    initial_params = np.concatenate([\n",
    "        [0.0],  # mu\n",
    "        [0.0],  # log_tau\n",
    "        school_means  # theta（観測平均で初期化）\n",
    "    ])\n",
    "    \n",
    "    hmc = ComprehensiveHMC(hierarchical_log_prob, hierarchical_grad_log_prob)\n",
    "    samples, detailed_info = hmc.sample(\n",
    "        initial_q=initial_params,\n",
    "        n_samples=2000,\n",
    "        epsilon=0.02,\n",
    "        L=30\n",
    "    )\n",
    "    \n",
    "    stats = hmc.get_statistics()\n",
    "    print(f\"HMC統計: 受理率={stats['acceptance_rate']:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    return samples, (true_mu, true_tau, true_theta), (school_means, school_sizes, school_sigmas)\n",
    "\n",
    "# 階層ベイズモデルの実行\n",
    "hierarchical_samples, true_params, observed_params = hierarchical_bayes_hmc_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階層ベイズモデル結果の分析と可視化\n",
    "def analyze_hierarchical_results(samples, true_params, observed_params):\n",
    "    \"\"\"階層ベイズモデル結果の分析\"\"\"\n",
    "    \n",
    "    true_mu, true_tau, true_theta = true_params\n",
    "    school_means, school_sizes, school_sigmas = observed_params\n",
    "    n_schools = len(school_means)\n",
    "    \n",
    "    # 結果の分析\n",
    "    burnin = 500\n",
    "    clean_samples = samples[burnin:]\n",
    "    \n",
    "    # パラメータの抽出\n",
    "    mu_samples = clean_samples[:, 0]\n",
    "    log_tau_samples = clean_samples[:, 1]\n",
    "    tau_samples = np.exp(log_tau_samples)\n",
    "    theta_samples = clean_samples[:, 2:2+n_schools]\n",
    "    \n",
    "    # 事後統計\n",
    "    print(\"事後統計サマリー:\")\n",
    "    print(f\"{'パラメータ':<12} {'真値':<10} {'事後平均':<12} {'95%信頼区間':<20}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # μ\n",
    "    mu_mean = np.mean(mu_samples)\n",
    "    mu_ci = np.percentile(mu_samples, [2.5, 97.5])\n",
    "    print(f\"{'μ (全体平均)':<12} {true_mu:<10.3f} {mu_mean:<12.3f} [{mu_ci[0]:.3f}, {mu_ci[1]:.3f}]\")\n",
    "    \n",
    "    # τ\n",
    "    tau_mean = np.mean(tau_samples)\n",
    "    tau_ci = np.percentile(tau_samples, [2.5, 97.5])\n",
    "    print(f\"{'τ (学校間SD)':<12} {true_tau:<10.3f} {tau_mean:<12.3f} [{tau_ci[0]:.3f}, {tau_ci[1]:.3f}]\")\n",
    "    \n",
    "    # θ\n",
    "    for i in range(n_schools):\n",
    "        theta_mean = np.mean(theta_samples[:, i])\n",
    "        theta_ci = np.percentile(theta_samples[:, i], [2.5, 97.5])\n",
    "        print(f\"{'θ_' + str(i+1):<12} {true_theta[i]:<10.3f} {theta_mean:<12.3f} [{theta_ci[0]:.3f}, {theta_ci[1]:.3f}]\")\n",
    "    \n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    \n",
    "    # μの事後分布\n",
    "    axes[0, 0].hist(mu_samples, bins=50, density=True, alpha=0.7, color='blue')\n",
    "    axes[0, 0].axvline(true_mu, color='red', linestyle='--', linewidth=2, label='真値')\n",
    "    axes[0, 0].axvline(mu_mean, color='green', linestyle='-', linewidth=2, label='事後平均')\n",
    "    axes[0, 0].set_title('μ (全体平均) の事後分布')\n",
    "    axes[0, 0].set_xlabel('μ')\n",
    "    axes[0, 0].set_ylabel('密度')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # τの事後分布\n",
    "    axes[0, 1].hist(tau_samples, bins=50, density=True, alpha=0.7, color='blue')\n",
    "    axes[0, 1].axvline(true_tau, color='red', linestyle='--', linewidth=2, label='真値')\n",
    "    axes[0, 1].axvline(tau_mean, color='green', linestyle='-', linewidth=2, label='事後平均')\n",
    "    axes[0, 1].set_title('τ (学校間標準偏差) の事後分布')\n",
    "    axes[0, 1].set_xlabel('τ')\n",
    "    axes[0, 1].set_ylabel('密度')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 2].plot(mu_samples[:1000], alpha=0.8, label='μ', linewidth=0.8)\n",
    "    axes[0, 2].plot(tau_samples[:1000], alpha=0.8, label='τ', linewidth=0.8)\n",
    "    axes[0, 2].set_title('μ, τ のトレースプロット')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Value')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 各学校のθの事後分布（最初の6校）\n",
    "    for i in range(6):\n",
    "        row, col = (i // 3) + 1, i % 3\n",
    "        axes[row, col].hist(theta_samples[:, i], bins=30, density=True, \n",
    "                           alpha=0.7, color='blue')\n",
    "        axes[row, col].axvline(true_theta[i], color='red', linestyle='--', \n",
    "                              linewidth=2, label='真値')\n",
    "        axes[row, col].axvline(school_means[i], color='orange', linestyle=':', \n",
    "                              linewidth=2, label='観測平均')\n",
    "        axes[row, col].axvline(np.mean(theta_samples[:, i]), color='green', \n",
    "                              linestyle='-', linewidth=2, label='事後平均')\n",
    "        axes[row, col].set_title(f'学校{i+1}: θ_{i+1} の事後分布')\n",
    "        axes[row, col].set_xlabel(f'θ_{i+1}')\n",
    "        axes[row, col].set_ylabel('密度')\n",
    "        if i == 0:\n",
    "            axes[row, col].legend()\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # shrinkage効果の分析\n",
    "    print(\"\\n=== Shrinkage効果の分析 ===\")\n",
    "    print(f\"{'学校':<4} {'観測平均':<10} {'事後平均':<10} {'Shrinkage':<12} {'真値との距離改善':<20}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for i in range(n_schools):\n",
    "        obs_mean = school_means[i]\n",
    "        post_mean = np.mean(theta_samples[:, i])\n",
    "        shrinkage = abs(post_mean - obs_mean)\n",
    "        \n",
    "        # 真値との距離の比較\n",
    "        obs_error = abs(obs_mean - true_theta[i])\n",
    "        post_error = abs(post_mean - true_theta[i])\n",
    "        improvement = obs_error - post_error\n",
    "        \n",
    "        print(f\"{i+1:<4} {obs_mean:<10.3f} {post_mean:<10.3f} {shrinkage:<12.3f} {improvement:<20.3f}\")\n",
    "    \n",
    "    # 予測分布の計算\n",
    "    print(\"\\n=== 新しい学校の予測 ===\")\n",
    "    \n",
    "    # 新しい学校の予測分布: N(μ, τ)\n",
    "    pred_samples = np.random.normal(mu_samples, tau_samples)\n",
    "    pred_mean = np.mean(pred_samples)\n",
    "    pred_ci = np.percentile(pred_samples, [2.5, 97.5])\n",
    "    \n",
    "    print(f\"新しい学校の成績予測:\")\n",
    "    print(f\"  予測平均: {pred_mean:.3f}\")\n",
    "    print(f\"  95%予測区間: [{pred_ci[0]:.3f}, {pred_ci[1]:.3f}]\")\n",
    "\n",
    "# 結果分析実行\n",
    "analyze_hierarchical_results(hierarchical_samples, true_params, observed_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 HMC実践のベストプラクティス\n",
    "\n",
    "実際にHMCを使用する際の重要なポイントをまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmc_best_practices_guide():\n",
    "    \"\"\"HMC実践のベストプラクティスガイド\"\"\"\n",
    "    \n",
    "    print(\"=== HMC実践のベストプラクティス ===\")\n",
    "    print()\n",
    "    \n",
    "    best_practices = {\n",
    "        \"1. パラメータ初期設定\": [\n",
    "            \"まず標準設定(ε=0.1, L=20)から開始\",\n",
    "            \"受理率を60-80%の範囲に調整\",\n",
    "            \"ハミルトニアン誤差をモニタリング\",\n",
    "            \"複数の初期値でテスト\"\n",
    "        ],\n",
    "        \n",
    "        \"2. 収束診断\": [\n",
    "            \"トレースプロットによる視覚的確認\",\n",
    "            \"Gelman-Rubin統計量 (R̂ < 1.1)\",\n",
    "            \"有効サンプルサイズの確認\",\n",
    "            \"複数チェーンによる検証\"\n",
    "        ],\n",
    "        \n",
    "        \"3. 数値安定性\": [\n",
    "            \"勾配の数値的検証を実施\",\n",
    "            \"パラメータのスケーリング正規化\",\n",
    "            \"制約の適切な処理（変数変換）\",\n",
    "            \"オーバーフローの防止\"\n",
    "        ],\n",
    "        \n",
    "        \"4. 効率向上\": [\n",
    "            \"前処理による分布の正規化\",\n",
    "            \"質量行列の適応的調整\",\n",
    "            \"再パラメータ化による相関軽減\",\n",
    "            \"適応的ステップサイズ調整\"\n",
    "        ],\n",
    "        \n",
    "        \"5. 実用的考慮事項\": [\n",
    "            \"勾配計算コストの評価\",\n",
    "            \"メモリ使用量の管理\",\n",
    "            \"並列化による高速化\",\n",
    "            \"専用ライブラリの活用\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, practices in best_practices.items():\n",
    "        print(f\"【{category}】\")\n",
    "        for practice in practices:\n",
    "            print(f\"  • {practice}\")\n",
    "        print()\n",
    "    \n",
    "    # よくある問題と対処法\n",
    "    print(\"=== よくある問題と対処法 ===\")\n",
    "    print()\n",
    "    \n",
    "    common_issues = {\n",
    "        \"低い受理率 (<50%)\": {\n",
    "            \"原因\": [\"ステップサイズが大きすぎる\", \"軌跡が長すぎる\", \"分布の勾配が急峻\"],\n",
    "            \"対策\": [\"εを小さくする\", \"Lを減らす\", \"質量行列による前処理\"]\n",
    "        },\n",
    "        \n",
    "        \"高い自己相関\": {\n",
    "            \"原因\": [\"ステップサイズが小さすぎる\", \"軌跡が短すぎる\", \"強い相関構造\"],\n",
    "            \"対策\": [\"εを大きくする\", \"Lを増やす\", \"再パラメータ化\"]\n",
    "        },\n",
    "        \n",
    "        \"数値不安定性\": {\n",
    "            \"原因\": [\"勾配計算誤差\", \"スケールの違い\", \"制約の不適切な処理\"],\n",
    "            \"対策\": [\"勾配検証\", \"変数変換\", \"ログ変換の活用\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for issue, details in common_issues.items():\n",
    "        print(f\"【{issue}】\")\n",
    "        print(\"原因:\")\n",
    "        for cause in details[\"原因\"]:\n",
    "            print(f\"  • {cause}\")\n",
    "        print(\"対策:\")\n",
    "        for solution in details[\"対策\"]:\n",
    "            print(f\"  • {solution}\")\n",
    "        print()\n",
    "    \n",
    "    # 推奨ライブラリとツール\n",
    "    print(\"=== 推奨ライブラリとツール ===\")\n",
    "    print()\n",
    "    \n",
    "    libraries = {\n",
    "        \"PyMC\": \"Pythonで最も人気。直感的なモデル記述、NUTS自動調整\",\n",
    "        \"Stan/PyStan\": \"高性能な専用言語。最先端のNUTS実装\",\n",
    "        \"TensorFlow Probability\": \"GPU加速、深層学習との統合\",\n",
    "        \"Pyro\": \"PyTorchベース、研究向けの柔軟性\",\n",
    "        \"ArviZ\": \"ベイズ統計の可視化と診断専用ライブラリ\"\n",
    "    }\n",
    "    \n",
    "    for lib, description in libraries.items():\n",
    "        print(f\"• **{lib}**: {description}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=== 学習から実用への移行指針 ===\")\n",
    "    print()\n",
    "    print(\"1. **理論理解段階**: 本ノートブックのような教育実装で原理を学ぶ\")\n",
    "    print(\"2. **実験段階**: 簡単なモデルで専用ライブラリに慣れる\")\n",
    "    print(\"3. **応用段階**: 実際の問題にNUTSを適用\")\n",
    "    print(\"4. **最適化段階**: カスタム質量行列や並列化を活用\")\n",
    "    print(\"5. **プロダクション段階**: 監視・診断を自動化\")\n",
    "\n",
    "hmc_best_practices_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章のまとめ\n",
    "\n",
    "### 🎯 主要な学習成果\n",
    "\n",
    "1. **物理学的直感の獲得**\n",
    "   - HMCの本質は「確率の山を転がるボール」\n",
    "   - エネルギー保存により効率的な長距離移動が可能\n",
    "   - 勾配情報を活用した賢いサンプリング\n",
    "\n",
    "2. **アルゴリズムの完全理解**\n",
    "   - リープフロッグ積分の重要性\n",
    "   - メトロポリス受理による誤差補正\n",
    "   - パラメータ調整の体系的手法\n",
    "\n",
    "3. **実践的スキルの習得**\n",
    "   - 階層ベイズモデルへの応用\n",
    "   - 収束診断とデバッグ手法\n",
    "   - 専用ライブラリへの移行指針\n",
    "\n",
    "### 🚀 HMCの革新性\n",
    "\n",
    "- **効率性**: 従来手法の10-100倍の効率改善\n",
    "- **スケーラビリティ**: 高次元問題への対応\n",
    "- **汎用性**: 勾配が利用可能な任意の分布\n",
    "- **理論的保証**: 正確なサンプリングの数学的保証\n",
    "\n",
    "### ⚡ 次のステップ\n",
    "\n",
    "1. **No-U-Turn Sampler (NUTS)**: HMCの自動調整版\n",
    "2. **変分推論**: 近似的だが高速なベイズ推論\n",
    "3. **GPU並列化**: 大規模データへの対応\n",
    "4. **ベイズ深層学習**: ニューラルネットワークとの統合\n",
    "\n",
    "HMCは現代ベイズ統計学の中核技術として、研究から実務まで幅広く活用されています。本章で学んだ知識を基に、より高度なモデリングと推論に挑戦してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 Chapter 7: ハミルトニアンモンテカルロ法 完了！\")\n",
    "print(\"\\n次は実際のプロジェクトでHMCを活用してみましょう。\")\n",
    "print(\"PyMCやStanなどの専用ライブラリも試してみてください。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}