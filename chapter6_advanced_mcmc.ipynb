{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: 高度なMCMC手法\n",
    "\n",
    "## 学習目標\n",
    "- ハミルトニアンモンテカルロ法（HMC）の原理を理解する\n",
    "- No-U-Turn Sampler（NUTS）の仕組みを学ぶ\n",
    "- 適応的MCMC手法を習得する\n",
    "- 並列・分散MCMCの概念を理解する\n",
    "- 変分推論との比較を学ぶ\n",
    "- 実用的なMCMCライブラリの使用方法を習得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 ハミルトニアンモンテカルロ法（HMC）\n",
    "\n",
    "HMCは物理学のハミルトニアン力学を応用したMCMC手法で、高次元空間での効率的なサンプリングを可能にします。\n",
    "\n",
    "### 基本概念\n",
    "- **位置変数**：$q$ （パラメータ）\n",
    "- **運動量変数**：$p$ （補助変数）\n",
    "- **ハミルトニアン**：$H(q, p) = U(q) + K(p)$\n",
    "  - $U(q) = -\\log \\pi(q)$ （ポテンシャルエネルギー）\n",
    "  - $K(p) = \\frac{1}{2}p^T M^{-1} p$ （運動エネルギー）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianMC:\n",
    "    \"\"\"\n",
    "    ハミルトニアンモンテカルロ法の実装\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_prob_fn, grad_log_prob_fn, mass_matrix=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - log_prob_fn: 対数確率密度関数\n",
    "        - grad_log_prob_fn: 対数確率密度の勾配関数\n",
    "        - mass_matrix: 質量行列（None の場合は単位行列）\n",
    "        \"\"\"\n",
    "        self.log_prob_fn = log_prob_fn\n",
    "        self.grad_log_prob_fn = grad_log_prob_fn\n",
    "        self.mass_matrix = mass_matrix\n",
    "        \n",
    "    def leapfrog_step(self, q, p, epsilon):\n",
    "        \"\"\"\n",
    "        リープフロッグ積分による1ステップ更新\n",
    "        \"\"\"\n",
    "        # 運動量の半ステップ更新\n",
    "        p_half = p + 0.5 * epsilon * self.grad_log_prob_fn(q)\n",
    "        \n",
    "        # 位置の全ステップ更新\n",
    "        if self.mass_matrix is None:\n",
    "            q_new = q + epsilon * p_half\n",
    "        else:\n",
    "            q_new = q + epsilon * np.linalg.solve(self.mass_matrix, p_half)\n",
    "        \n",
    "        # 運動量の残り半ステップ更新\n",
    "        p_new = p_half + 0.5 * epsilon * self.grad_log_prob_fn(q_new)\n",
    "        \n",
    "        return q_new, p_new\n",
    "    \n",
    "    def hamiltonian(self, q, p):\n",
    "        \"\"\"\n",
    "        ハミルトニアンの計算\n",
    "        \"\"\"\n",
    "        # ポテンシャルエネルギー\n",
    "        U = -self.log_prob_fn(q)\n",
    "        \n",
    "        # 運動エネルギー\n",
    "        if self.mass_matrix is None:\n",
    "            K = 0.5 * np.sum(p**2)\n",
    "        else:\n",
    "            K = 0.5 * p.T @ np.linalg.solve(self.mass_matrix, p)\n",
    "        \n",
    "        return U + K\n",
    "    \n",
    "    def sample(self, initial_q, n_samples, epsilon, L):\n",
    "        \"\"\"\n",
    "        HMCサンプリングの実行\n",
    "        \n",
    "        Parameters:\n",
    "        - initial_q: 初期位置\n",
    "        - n_samples: サンプル数\n",
    "        - epsilon: ステップサイズ\n",
    "        - L: リープフロッグステップ数\n",
    "        \n",
    "        Returns:\n",
    "        - samples: サンプル配列\n",
    "        - acceptance_rate: 受理率\n",
    "        - hamiltonian_errors: ハミルトニアン保存誤差\n",
    "        \"\"\"\n",
    "        dim = len(initial_q)\n",
    "        samples = np.zeros((n_samples, dim))\n",
    "        hamiltonian_errors = np.zeros(n_samples)\n",
    "        \n",
    "        current_q = initial_q.copy()\n",
    "        n_accepted = 0\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # 運動量をサンプリング\n",
    "            if self.mass_matrix is None:\n",
    "                current_p = np.random.normal(0, 1, dim)\n",
    "            else:\n",
    "                current_p = np.random.multivariate_normal(np.zeros(dim), self.mass_matrix)\n",
    "            \n",
    "            # 現在のハミルトニアン\n",
    "            current_H = self.hamiltonian(current_q, current_p)\n",
    "            \n",
    "            # リープフロッグ積分\n",
    "            q, p = current_q.copy(), current_p.copy()\n",
    "            \n",
    "            for _ in range(L):\n",
    "                q, p = self.leapfrog_step(q, p, epsilon)\n",
    "            \n",
    "            # 運動量を反転（ハミルトニアン力学の時間反転対称性）\n",
    "            p = -p\n",
    "            \n",
    "            # 提案後のハミルトニアン\n",
    "            proposed_H = self.hamiltonian(q, p)\n",
    "            \n",
    "            # ハミルトニアン保存誤差\n",
    "            hamiltonian_error = abs(proposed_H - current_H)\n",
    "            hamiltonian_errors[i] = hamiltonian_error\n",
    "            \n",
    "            # メトロポリス受理確率\n",
    "            alpha = min(1.0, np.exp(current_H - proposed_H))\n",
    "            \n",
    "            # 受理/棄却\n",
    "            if np.random.rand() < alpha:\n",
    "                current_q = q\n",
    "                n_accepted += 1\n",
    "            \n",
    "            samples[i] = current_q\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"Iteration {i+1}/{n_samples}, Acceptance rate: {n_accepted/(i+1):.3f}\")\n",
    "        \n",
    "        acceptance_rate = n_accepted / n_samples\n",
    "        return samples, acceptance_rate, hamiltonian_errors\n",
    "\n",
    "# テスト用の2次元正規分布\n",
    "def multivariate_normal_log_prob(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度\"\"\"\n",
    "    diff = x - mu\n",
    "    try:\n",
    "        chol = cholesky(cov, lower=True)\n",
    "        log_det = 2 * np.sum(np.log(np.diag(chol)))\n",
    "        solve = solve_triangular(chol, diff, lower=True)\n",
    "        mahalanobis_sq = np.sum(solve**2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf\n",
    "    \n",
    "    return -0.5 * (len(mu) * np.log(2 * np.pi) + log_det + mahalanobis_sq)\n",
    "\n",
    "def multivariate_normal_grad_log_prob(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度の勾配\"\"\"\n",
    "    diff = x - mu\n",
    "    try:\n",
    "        grad = -np.linalg.solve(cov, diff)\n",
    "    except np.linalg.LinAlgError:\n",
    "        grad = np.zeros_like(x)\n",
    "    return grad\n",
    "\n",
    "# パラメータ設定\n",
    "mu_target = np.array([0.0, 0.0])\n",
    "cov_target = np.array([[1.0, 0.8], [0.8, 1.0]])\n",
    "\n",
    "# HMCサンプラーの作成\n",
    "hmc = HamiltonianMC(\n",
    "    log_prob_fn=lambda x: multivariate_normal_log_prob(x, mu_target, cov_target),\n",
    "    grad_log_prob_fn=lambda x: multivariate_normal_grad_log_prob(x, mu_target, cov_target)\n",
    ")\n",
    "\n",
    "# HMCサンプリングの実行\n",
    "print(\"HMCサンプリング実行中...\")\n",
    "initial_q = np.array([0.0, 0.0])\n",
    "hmc_samples, hmc_acceptance_rate, hmc_errors = hmc.sample(\n",
    "    initial_q=initial_q,\n",
    "    n_samples=5000,\n",
    "    epsilon=0.25,  # ステップサイズ\n",
    "    L=20          # リープフロッグステップ数\n",
    ")\n",
    "\n",
    "print(f\"\\nHMC受理率: {hmc_acceptance_rate:.3f}\")\n",
    "print(f\"平均ハミルトニアン誤差: {np.mean(hmc_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC結果の可視化\n",
    "def plot_hmc_results(samples, errors, mu_target, cov_target, title=\"HMC Results\"):\n",
    "    \"\"\"\n",
    "    HMC結果の包括的可視化\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    burnin = 500\n",
    "    samples_clean = samples[burnin:]\n",
    "    \n",
    "    # 1. サンプルの軌跡（最初の500サンプル）\n",
    "    trajectory = samples[:500]\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b-', alpha=0.7, linewidth=0.8)\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b.', markersize=1, alpha=0.6)\n",
    "    axes[0, 0].plot(trajectory[0, 0], trajectory[0, 1], 'go', markersize=8, label='Start')\n",
    "    axes[0, 0].plot(trajectory[-1, 0], trajectory[-1, 1], 'ro', markersize=8, label='End')\n",
    "    axes[0, 0].set_title('HMC Trajectory (first 500)')\n",
    "    axes[0, 0].set_xlabel('X1')\n",
    "    axes[0, 0].set_ylabel('X2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 散布図と真の分布の等高線\n",
    "    axes[0, 1].scatter(samples_clean[::5, 0], samples_clean[::5, 1], alpha=0.6, s=1)\n",
    "    \n",
    "    # 真の分布の等高線\n",
    "    x1_range = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 50)\n",
    "    x2_range = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 50)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    pos = np.dstack((X1, X2))\n",
    "    rv = stats.multivariate_normal(mu_target, cov_target)\n",
    "    axes[0, 1].contour(X1, X2, rv.pdf(pos), colors='red', alpha=0.8, linewidths=2)\n",
    "    axes[0, 1].set_title('Samples with True Distribution')\n",
    "    axes[0, 1].set_xlabel('X1')\n",
    "    axes[0, 1].set_ylabel('X2')\n",
    "    axes[0, 1].set_aspect('equal')\n",
    "    \n",
    "    # 3. ハミルトニアン誤差の時系列\n",
    "    axes[0, 2].plot(errors[:2000], alpha=0.8, linewidth=0.8)\n",
    "    axes[0, 2].set_title('Hamiltonian Errors')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('|H_proposed - H_current|')\n",
    "    axes[0, 2].set_yscale('log')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. トレースプロット\n",
    "    axes[1, 0].plot(samples[:2000, 0], alpha=0.8, label='X1', linewidth=0.8)\n",
    "    axes[1, 0].plot(samples[:2000, 1], alpha=0.8, label='X2', linewidth=0.8)\n",
    "    axes[1, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[1, 0].set_title('Trace Plot')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Value')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. マージナル分布の比較\n",
    "    axes[1, 1].hist(samples_clean[:, 0], bins=50, density=True, alpha=0.7, \n",
    "                   color='lightblue', label='X1 samples')\n",
    "    x1_theory = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 100)\n",
    "    axes[1, 1].plot(x1_theory, stats.norm.pdf(x1_theory, mu_target[0], np.sqrt(cov_target[0, 0])), \n",
    "                   'r-', linewidth=2, label='X1 true')\n",
    "    axes[1, 1].set_title('Marginal Distribution X1')\n",
    "    axes[1, 1].set_xlabel('X1')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # 6. 自己相関関数\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    lags = min(100, len(samples_clean) // 10)\n",
    "    autocorr_x1 = acf(samples_clean[:, 0], nlags=lags, fft=True)\n",
    "    autocorr_x2 = acf(samples_clean[:, 1], nlags=lags, fft=True)\n",
    "    \n",
    "    axes[1, 2].plot(autocorr_x1, label='X1', alpha=0.8)\n",
    "    axes[1, 2].plot(autocorr_x2, label='X2', alpha=0.8)\n",
    "    axes[1, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(-0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].set_title('Autocorrelation Functions')\n",
    "    axes[1, 2].set_xlabel('Lag')\n",
    "    axes[1, 2].set_ylabel('ACF')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 結果の可視化\n",
    "plot_hmc_results(hmc_samples, hmc_errors, mu_target, cov_target, \"Hamiltonian Monte Carlo Results\")\n",
    "\n",
    "# 統計的比較\n",
    "burnin = 500\n",
    "hmc_clean = hmc_samples[burnin:]\n",
    "\n",
    "sample_mean = np.mean(hmc_clean, axis=0)\n",
    "sample_cov = np.cov(hmc_clean.T)\n",
    "\n",
    "print(f\"\\n=== HMC統計結果 ===\")\n",
    "print(f\"真の平均:     {mu_target}\")\n",
    "print(f\"サンプル平均: {sample_mean}\")\n",
    "print(f\"\\n真の共分散:\")\n",
    "print(cov_target)\n",
    "print(f\"サンプル共分散:\")\n",
    "print(sample_cov)\n",
    "\n",
    "# 効率の計算\n",
    "from statsmodels.tsa.stattools import acf\n",
    "autocorr_x1 = acf(hmc_clean[:, 0], nlags=min(200, len(hmc_clean)//4), fft=True)\n",
    "tau_int = 1.0\n",
    "for k in range(1, len(autocorr_x1)):\n",
    "    if autocorr_x1[k] > 0.01:\n",
    "        tau_int += 2 * autocorr_x1[k]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "eff_sample_size = len(hmc_clean) / (2 * tau_int + 1)\n",
    "print(f\"\\n統合自己相関時間: {tau_int:.2f}\")\n",
    "print(f\"有効サンプルサイズ: {eff_sample_size:.0f}\")\n",
    "print(f\"効率: {eff_sample_size/len(hmc_clean):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 ランダムウォークMHとHMCの比較\n",
    "\n",
    "同じ分布に対してランダムウォーク・メトロポリス・ヘイスティングス法とHMCを比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムウォークMHの実装（比較用）\n",
    "def random_walk_mh(log_prob_fn, initial_value, n_samples, step_size=0.5):\n",
    "    \"\"\"\n",
    "    ランダムウォーク・メトロポリス・ヘイスティングス法\n",
    "    \"\"\"\n",
    "    dim = len(initial_value)\n",
    "    samples = np.zeros((n_samples, dim))\n",
    "    current = initial_value.copy()\n",
    "    current_log_prob = log_prob_fn(current)\n",
    "    n_accepted = 0\n",
    "    \n",
    "    proposal_cov = step_size**2 * np.eye(dim)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 提案\n",
    "        proposed = np.random.multivariate_normal(current, proposal_cov)\n",
    "        proposed_log_prob = log_prob_fn(proposed)\n",
    "        \n",
    "        # 受理確率\n",
    "        log_alpha = proposed_log_prob - current_log_prob\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却\n",
    "        if np.random.rand() < alpha:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        samples[i] = current\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Iteration {i+1}/{n_samples}, Acceptance rate: {n_accepted/(i+1):.3f}\")\n",
    "    \n",
    "    acceptance_rate = n_accepted / n_samples\n",
    "    return samples, acceptance_rate\n",
    "\n",
    "# 比較実験の実行\n",
    "print(\"ランダムウォークMHサンプリング実行中...\")\n",
    "rwmh_samples, rwmh_acceptance_rate = random_walk_mh(\n",
    "    log_prob_fn=lambda x: multivariate_normal_log_prob(x, mu_target, cov_target),\n",
    "    initial_value=np.array([0.0, 0.0]),\n",
    "    n_samples=5000,\n",
    "    step_size=0.8\n",
    ")\n",
    "\n",
    "print(f\"\\nランダムウォークMH受理率: {rwmh_acceptance_rate:.3f}\")\n",
    "\n",
    "# 効率比較\n",
    "def compute_efficiency_metrics(samples, burnin_frac=0.1):\n",
    "    \"\"\"\n",
    "    効率指標の計算\n",
    "    \"\"\"\n",
    "    burnin = int(len(samples) * burnin_frac)\n",
    "    clean_samples = samples[burnin:]\n",
    "    \n",
    "    # 各次元の自己相関時間を計算\n",
    "    autocorr_times = []\n",
    "    eff_sample_sizes = []\n",
    "    \n",
    "    for dim in range(clean_samples.shape[1]):\n",
    "        data = clean_samples[:, dim]\n",
    "        lags = min(200, len(data) // 4)\n",
    "        autocorr = acf(data, nlags=lags, fft=True)\n",
    "        \n",
    "        # 統合自己相関時間\n",
    "        tau_int = 1.0\n",
    "        for lag in range(1, len(autocorr)):\n",
    "            if autocorr[lag] > 0.01:\n",
    "                tau_int += 2 * autocorr[lag]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        autocorr_times.append(tau_int)\n",
    "        eff_sample_sizes.append(len(data) / (2 * tau_int + 1))\n",
    "    \n",
    "    return autocorr_times, eff_sample_sizes\n",
    "\n",
    "# 効率比較\n",
    "hmc_autocorr, hmc_eff = compute_efficiency_metrics(hmc_samples)\n",
    "rwmh_autocorr, rwmh_eff = compute_efficiency_metrics(rwmh_samples)\n",
    "\n",
    "print(f\"\\n=== 効率比較 ===\")\n",
    "print(f\"{'Method':<12} {'Dim':<5} {'Acceptance':<12} {'Autocorr Time':<15} {'Eff Sample Size':<18} {'Efficiency':<12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for dim in range(2):\n",
    "    print(f\"{'HMC':<12} {'X'+str(dim+1):<5} {hmc_acceptance_rate:<12.3f} \"\n",
    "          f\"{hmc_autocorr[dim]:<15.2f} {hmc_eff[dim]:<18.1f} {hmc_eff[dim]/len(hmc_samples[500:]):<12.3f}\")\n",
    "    print(f\"{'Random Walk':<12} {'X'+str(dim+1):<5} {rwmh_acceptance_rate:<12.3f} \"\n",
    "          f\"{rwmh_autocorr[dim]:<15.2f} {rwmh_eff[dim]:<18.1f} {rwmh_eff[dim]/len(rwmh_samples[500:]):<12.3f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"平均効率比（HMC/RWMH）: {np.mean(hmc_eff)/np.mean(rwmh_eff):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC vs ランダムウォークMHの可視化比較\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 10))\n",
    "\n",
    "burnin = 500\n",
    "hmc_clean = hmc_samples[burnin:]\n",
    "rwmh_clean = rwmh_samples[burnin:]\n",
    "\n",
    "# トレースプロット比較\n",
    "axes[0, 0].plot(hmc_samples[:2000, 0], alpha=0.8, label='HMC', linewidth=0.8, color='blue')\n",
    "axes[0, 0].plot(rwmh_samples[:2000, 0], alpha=0.8, label='RWMH', linewidth=0.8, color='red')\n",
    "axes[0, 0].axvline(burnin, color='gray', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].set_title('Trace Plot Comparison (X1)')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('X1')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 散布図比較\n",
    "axes[0, 1].scatter(hmc_clean[::10, 0], hmc_clean[::10, 1], alpha=0.6, s=5, color='blue', label='HMC')\n",
    "axes[0, 1].scatter(rwmh_clean[::10, 0], rwmh_clean[::10, 1], alpha=0.6, s=5, color='red', label='RWMH')\n",
    "axes[0, 1].set_title('Sample Scatter Plot')\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "\n",
    "# 自己相関比較\n",
    "lags = min(100, len(hmc_clean) // 10)\n",
    "hmc_acf = acf(hmc_clean[:, 0], nlags=lags, fft=True)\n",
    "rwmh_acf = acf(rwmh_clean[:, 0], nlags=lags, fft=True)\n",
    "\n",
    "axes[0, 2].plot(hmc_acf, label='HMC', alpha=0.8, color='blue')\n",
    "axes[0, 2].plot(rwmh_acf, label='RWMH', alpha=0.8, color='red')\n",
    "axes[0, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "axes[0, 2].axhline(0.05, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 2].set_title('Autocorrelation Comparison (X1)')\n",
    "axes[0, 2].set_xlabel('Lag')\n",
    "axes[0, 2].set_ylabel('ACF')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 効率指標の比較\n",
    "methods = ['HMC', 'RWMH']\n",
    "x1_eff = [hmc_eff[0], rwmh_eff[0]]\n",
    "x2_eff = [hmc_eff[1], rwmh_eff[1]]\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 3].bar(x_pos - width/2, x1_eff, width, label='X1', alpha=0.7, color='lightblue')\n",
    "axes[0, 3].bar(x_pos + width/2, x2_eff, width, label='X2', alpha=0.7, color='lightcoral')\n",
    "axes[0, 3].set_title('Effective Sample Size')\n",
    "axes[0, 3].set_xlabel('Method')\n",
    "axes[0, 3].set_ylabel('Effective Sample Size')\n",
    "axes[0, 3].set_xticks(x_pos)\n",
    "axes[0, 3].set_xticklabels(methods)\n",
    "axes[0, 3].legend()\n",
    "axes[0, 3].grid(True, alpha=0.3)\n",
    "\n",
    "# 軌跡の比較（最初の200ステップ）\n",
    "hmc_traj = hmc_samples[:200]\n",
    "rwmh_traj = rwmh_samples[:200]\n",
    "\n",
    "axes[1, 0].plot(hmc_traj[:, 0], hmc_traj[:, 1], 'b-', alpha=0.7, linewidth=1, label='HMC')\n",
    "axes[1, 0].plot(hmc_traj[:, 0], hmc_traj[:, 1], 'b.', markersize=2, alpha=0.8)\n",
    "axes[1, 0].set_title('HMC Trajectory (first 200)')\n",
    "axes[1, 0].set_xlabel('X1')\n",
    "axes[1, 0].set_ylabel('X2')\n",
    "axes[1, 0].set_aspect('equal')\n",
    "\n",
    "axes[1, 1].plot(rwmh_traj[:, 0], rwmh_traj[:, 1], 'r-', alpha=0.7, linewidth=1, label='RWMH')\n",
    "axes[1, 1].plot(rwmh_traj[:, 0], rwmh_traj[:, 1], 'r.', markersize=2, alpha=0.8)\n",
    "axes[1, 1].set_title('RWMH Trajectory (first 200)')\n",
    "axes[1, 1].set_xlabel('X1')\n",
    "axes[1, 1].set_ylabel('X2')\n",
    "axes[1, 1].set_aspect('equal')\n",
    "\n",
    "# ステップサイズの効果（HMC）\n",
    "step_distances_hmc = np.sqrt(np.sum(np.diff(hmc_samples[:1000], axis=0)**2, axis=1))\n",
    "step_distances_rwmh = np.sqrt(np.sum(np.diff(rwmh_samples[:1000], axis=0)**2, axis=1))\n",
    "\n",
    "axes[1, 2].hist(step_distances_hmc, bins=30, alpha=0.7, density=True, color='blue', label='HMC')\n",
    "axes[1, 2].hist(step_distances_rwmh, bins=30, alpha=0.7, density=True, color='red', label='RWMH')\n",
    "axes[1, 2].set_title('Step Size Distribution')\n",
    "axes[1, 2].set_xlabel('Step Distance')\n",
    "axes[1, 2].set_ylabel('Density')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "# 探索効率（単位時間あたりの有効サンプル数）\n",
    "# 注：実際の計算時間は測定していないため、理論的な比較\n",
    "# HMCは1ステップあたりより多くの計算が必要だが、より効率的\n",
    "axes[1, 3].bar(['HMC', 'RWMH'], \n",
    "               [np.mean(hmc_eff)/20, np.mean(rwmh_eff)],  # HMCは20倍の計算コストと仮定\n",
    "               alpha=0.7, color=['blue', 'red'])\n",
    "axes[1, 3].set_title('Computational Efficiency\\n(ESS per unit computation)')\n",
    "axes[1, 3].set_ylabel('Relative Efficiency')\n",
    "axes[1, 3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 詳細統計の比較\n",
    "print(f\"\\n=== 詳細統計比較 ===\")\n",
    "print(f\"{'Metric':<25} {'HMC':<15} {'Random Walk MH':<15} {'Ratio (HMC/RWMH)':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "hmc_mean_eff = np.mean(hmc_eff)\n",
    "rwmh_mean_eff = np.mean(rwmh_eff)\n",
    "hmc_mean_tau = np.mean(hmc_autocorr)\n",
    "rwmh_mean_tau = np.mean(rwmh_autocorr)\n",
    "\n",
    "print(f\"{'Acceptance Rate':<25} {hmc_acceptance_rate:<15.3f} {rwmh_acceptance_rate:<15.3f} {hmc_acceptance_rate/rwmh_acceptance_rate:<15.2f}\")\n",
    "print(f\"{'Mean Autocorr Time':<25} {hmc_mean_tau:<15.2f} {rwmh_mean_tau:<15.2f} {hmc_mean_tau/rwmh_mean_tau:<15.2f}\")\n",
    "print(f\"{'Mean Eff Sample Size':<25} {hmc_mean_eff:<15.1f} {rwmh_mean_eff:<15.1f} {hmc_mean_eff/rwmh_mean_eff:<15.2f}\")\n",
    "print(f\"{'Efficiency':<25} {hmc_mean_eff/len(hmc_clean):<15.3f} {rwmh_mean_eff/len(rwmh_clean):<15.3f} {(hmc_mean_eff/len(hmc_clean))/(rwmh_mean_eff/len(rwmh_clean)):<15.2f}\")\n",
    "\n",
    "# 平均ステップサイズ\n",
    "hmc_mean_step = np.mean(step_distances_hmc[step_distances_hmc > 0])\n",
    "rwmh_mean_step = np.mean(step_distances_rwmh[step_distances_rwmh > 0])\n",
    "print(f\"{'Mean Step Size':<25} {hmc_mean_step:<15.3f} {rwmh_mean_step:<15.3f} {hmc_mean_step/rwmh_mean_step:<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 No-U-Turn Sampler (NUTS)\n",
    "\n",
    "NUTSはHMCの拡張で、リープフロッグステップ数Lを自動的に決定する手法です。\n",
    "\n",
    "### 基本アイデア\n",
    "- 軌跡が「U字型」になる（元の位置に戻り始める）まで続ける\n",
    "- 木構造を用いて効率的に実装\n",
    "- ステップサイズの適応的調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNUTS:\n",
    "    \"\"\"\n",
    "    簡易版No-U-Turn Sampler\n",
    "    \n",
    "    注：これは教育目的の簡易実装です。\n",
    "    実際のNUTSはより複雑な木構造と適応機構を持ちます。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_prob_fn, grad_log_prob_fn, max_treedepth=10):\n",
    "        self.log_prob_fn = log_prob_fn\n",
    "        self.grad_log_prob_fn = grad_log_prob_fn\n",
    "        self.max_treedepth = max_treedepth\n",
    "        \n",
    "    def leapfrog_step(self, q, p, epsilon):\n",
    "        \"\"\"リープフロッグステップ\"\"\"\n",
    "        p_half = p + 0.5 * epsilon * self.grad_log_prob_fn(q)\n",
    "        q_new = q + epsilon * p_half\n",
    "        p_new = p_half + 0.5 * epsilon * self.grad_log_prob_fn(q_new)\n",
    "        return q_new, p_new\n",
    "    \n",
    "    def compute_energy(self, q, p):\n",
    "        \"\"\"エネルギー（負の対数確率）の計算\"\"\"\n",
    "        return -self.log_prob_fn(q) + 0.5 * np.sum(p**2)\n",
    "    \n",
    "    def build_tree(self, q, p, u, v, j, epsilon, q0, p0):\n",
    "        \"\"\"\n",
    "        二分木の構築（簡易版）\n",
    "        \n",
    "        Returns:\n",
    "        - q_minus, p_minus: 木の左端\n",
    "        - q_plus, p_plus: 木の右端\n",
    "        - q_prime: 提案する新しい位置\n",
    "        - n_prime: 有効な状態数\n",
    "        - s_prime: 継続するかどうか\n",
    "        \"\"\"\n",
    "        if j == 0:\n",
    "            # 基本ケース：1ステップ\n",
    "            q_prime, p_prime = self.leapfrog_step(q, p, v * epsilon)\n",
    "            \n",
    "            # エネルギー制約のチェック\n",
    "            energy_prime = self.compute_energy(q_prime, p_prime)\n",
    "            energy_0 = self.compute_energy(q0, p0)\n",
    "            \n",
    "            n_prime = int(u <= np.exp(energy_0 - energy_prime))\n",
    "            s_prime = int(u < np.exp(1000 + energy_0 - energy_prime))  # 数値安定性のため\n",
    "            \n",
    "            return q_prime, p_prime, q_prime, p_prime, q_prime, n_prime, s_prime\n",
    "        \n",
    "        else:\n",
    "            # 再帰ケース\n",
    "            # 最初の半分の木を構築\n",
    "            q_minus, p_minus, q_plus, p_plus, q_prime, n_prime, s_prime = \\\n",
    "                self.build_tree(q, p, u, v, j-1, epsilon, q0, p0)\n",
    "            \n",
    "            if s_prime:\n",
    "                if v == -1:\n",
    "                    # 左方向に拡張\n",
    "                    q_minus, p_minus, _, _, q_double_prime, n_double_prime, s_double_prime = \\\n",
    "                        self.build_tree(q_minus, p_minus, u, v, j-1, epsilon, q0, p0)\n",
    "                else:\n",
    "                    # 右方向に拡張\n",
    "                    _, _, q_plus, p_plus, q_double_prime, n_double_prime, s_double_prime = \\\n",
    "                        self.build_tree(q_plus, p_plus, u, v, j-1, epsilon, q0, p0)\n",
    "                \n",
    "                # 提案の選択\n",
    "                if np.random.rand() < n_double_prime / max(n_prime + n_double_prime, 1):\n",
    "                    q_prime = q_double_prime\n",
    "                \n",
    "                # U-turn検出（簡易版）\n",
    "                delta_minus = q_plus - q_minus\n",
    "                no_uturn = (np.dot(delta_minus, p_minus) >= 0) and (np.dot(delta_minus, p_plus) >= 0)\n",
    "                \n",
    "                s_prime = s_double_prime and no_uturn\n",
    "                n_prime = n_prime + n_double_prime\n",
    "            \n",
    "            return q_minus, p_minus, q_plus, p_plus, q_prime, n_prime, s_prime\n",
    "    \n",
    "    def sample(self, initial_q, n_samples, initial_epsilon=0.1, adapt_steps=1000):\n",
    "        \"\"\"\n",
    "        NUTSサンプリングの実行\n",
    "        \"\"\"\n",
    "        dim = len(initial_q)\n",
    "        samples = np.zeros((n_samples, dim))\n",
    "        \n",
    "        q = initial_q.copy()\n",
    "        epsilon = initial_epsilon\n",
    "        n_accepted = 0\n",
    "        \n",
    "        # 適応的パラメータ\n",
    "        target_accept = 0.8\n",
    "        log_epsilon = np.log(epsilon)\n",
    "        log_epsilon_bar = 0.0\n",
    "        h_bar = 0.0\n",
    "        gamma = 0.05\n",
    "        t0 = 10\n",
    "        kappa = 0.75\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # 運動量のサンプリング\n",
    "            p = np.random.normal(0, 1, dim)\n",
    "            \n",
    "            # スライス変数\n",
    "            u = np.random.rand() * np.exp(self.log_prob_fn(q) - 0.5 * np.sum(p**2))\n",
    "            \n",
    "            # 初期設定\n",
    "            q_minus = q_plus = q.copy()\n",
    "            p_minus = p_plus = p.copy()\n",
    "            j = 0\n",
    "            n = 1\n",
    "            s = 1\n",
    "            q_new = q.copy()\n",
    "            \n",
    "            # 木の構築\n",
    "            while s and j < self.max_treedepth:\n",
    "                # 方向を決定\n",
    "                v = 2 * np.random.randint(2) - 1\n",
    "                \n",
    "                if v == -1:\n",
    "                    q_minus, p_minus, _, _, q_prime, n_prime, s_prime = \\\n",
    "                        self.build_tree(q_minus, p_minus, u, v, j, epsilon, q, p)\n",
    "                else:\n",
    "                    _, _, q_plus, p_plus, q_prime, n_prime, s_prime = \\\n",
    "                        self.build_tree(q_plus, p_plus, u, v, j, epsilon, q, p)\n",
    "                \n",
    "                if s_prime:\n",
    "                    if np.random.rand() < n_prime / n:\n",
    "                        q_new = q_prime\n",
    "                \n",
    "                n = n + n_prime\n",
    "                \n",
    "                # U-turn検出\n",
    "                delta = q_plus - q_minus\n",
    "                s = s_prime and (np.dot(delta, p_minus) >= 0) and (np.dot(delta, p_plus) >= 0)\n",
    "                j = j + 1\n",
    "            \n",
    "            # 受理/棄却（NUTSでは自動的に決まる）\n",
    "            if not np.allclose(q_new, q):\n",
    "                n_accepted += 1\n",
    "            q = q_new\n",
    "            samples[i] = q\n",
    "            \n",
    "            # ステップサイズの適応（Dual Averaging）\n",
    "            if i < adapt_steps:\n",
    "                accept_prob = min(1, n / (2**j))\n",
    "                h_bar = (1 - 1/(i + t0 + 1)) * h_bar + (target_accept - accept_prob) / (i + t0 + 1)\n",
    "                log_epsilon = log_epsilon_bar - np.sqrt(i + 1) / gamma * h_bar\n",
    "                log_epsilon_bar = (i + 1)**(-kappa) * log_epsilon + (1 - (i + 1)**(-kappa)) * log_epsilon_bar\n",
    "                epsilon = np.exp(log_epsilon)\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"Iteration {i+1}/{n_samples}, Acceptance rate: {n_accepted/(i+1):.3f}, Epsilon: {epsilon:.4f}\")\n",
    "        \n",
    "        acceptance_rate = n_accepted / n_samples\n",
    "        return samples, acceptance_rate, epsilon\n",
    "\n",
    "# NUTSサンプラーの作成と実行\n",
    "print(\"NUTS (簡易版) サンプリング実行中...\")\n",
    "nuts = SimpleNUTS(\n",
    "    log_prob_fn=lambda x: multivariate_normal_log_prob(x, mu_target, cov_target),\n",
    "    grad_log_prob_fn=lambda x: multivariate_normal_grad_log_prob(x, mu_target, cov_target)\n",
    ")\n",
    "\n",
    "nuts_samples, nuts_acceptance_rate, final_epsilon = nuts.sample(\n",
    "    initial_q=np.array([0.0, 0.0]),\n",
    "    n_samples=3000  # NUTSは計算量が多いため少なめに設定\n",
    ")\n",
    "\n",
    "print(f\"\\nNUTS受理率: {nuts_acceptance_rate:.3f}\")\n",
    "print(f\"最終ステップサイズ: {final_epsilon:.4f}\")\n",
    "\n",
    "# NUTS効率の計算\n",
    "nuts_autocorr, nuts_eff = compute_efficiency_metrics(nuts_samples)\n",
    "\n",
    "print(f\"\\n=== NUTS効率指標 ===\")\n",
    "print(f\"平均自己相関時間: {np.mean(nuts_autocorr):.2f}\")\n",
    "print(f\"平均有効サンプルサイズ: {np.mean(nuts_eff):.1f}\")\n",
    "print(f\"効率: {np.mean(nuts_eff)/len(nuts_samples[300:]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 適応的MCMC手法\n",
    "\n",
    "サンプリング中にパラメータを自動調整する手法を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveMetropolis:\n",
    "    \"\"\"\n",
    "    適応的メトロポリス法（AM）\n",
    "    Haario et al. (2001) による手法\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_prob_fn, initial_cov_scale=0.1, adaptation_start=100):\n",
    "        self.log_prob_fn = log_prob_fn\n",
    "        self.initial_cov_scale = initial_cov_scale\n",
    "        self.adaptation_start = adaptation_start\n",
    "        \n",
    "    def sample(self, initial_value, n_samples):\n",
    "        \"\"\"\n",
    "        適応的サンプリングの実行\n",
    "        \"\"\"\n",
    "        dim = len(initial_value)\n",
    "        samples = np.zeros((n_samples, dim))\n",
    "        \n",
    "        # 初期設定\n",
    "        current = initial_value.copy()\n",
    "        current_log_prob = self.log_prob_fn(current)\n",
    "        \n",
    "        # 適応的共分散行列\n",
    "        cov_matrix = self.initial_cov_scale**2 * np.eye(dim)\n",
    "        epsilon = 1e-6  # 数値安定性のため\n",
    "        sd_scale = 2.4**2 / dim  # 最適スケーリング\n",
    "        \n",
    "        n_accepted = 0\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # 提案分布の更新\n",
    "            if i >= self.adaptation_start:\n",
    "                # 経験共分散行列の計算\n",
    "                sample_mean = np.mean(samples[:i], axis=0)\n",
    "                sample_cov = np.cov(samples[:i].T, ddof=1)\n",
    "                \n",
    "                # Regularization（数値安定性のため）\n",
    "                if np.any(np.isnan(sample_cov)) or np.any(np.isinf(sample_cov)):\n",
    "                    cov_matrix = self.initial_cov_scale**2 * np.eye(dim)\n",
    "                else:\n",
    "                    cov_matrix = sd_scale * (sample_cov + epsilon * np.eye(dim))\n",
    "            \n",
    "            # 提案\n",
    "            try:\n",
    "                proposed = np.random.multivariate_normal(current, cov_matrix)\n",
    "            except np.linalg.LinAlgError:\n",
    "                # 共分散行列が特異の場合\n",
    "                proposed = current + np.random.normal(0, self.initial_cov_scale, dim)\n",
    "            \n",
    "            proposed_log_prob = self.log_prob_fn(proposed)\n",
    "            \n",
    "            # 受理確率\n",
    "            log_alpha = proposed_log_prob - current_log_prob\n",
    "            alpha = min(1.0, np.exp(log_alpha))\n",
    "            \n",
    "            # 受理/棄却\n",
    "            if np.random.rand() < alpha:\n",
    "                current = proposed\n",
    "                current_log_prob = proposed_log_prob\n",
    "                n_accepted += 1\n",
    "            \n",
    "            samples[i] = current\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"Iteration {i+1}/{n_samples}, Acceptance rate: {n_accepted/(i+1):.3f}\")\n",
    "        \n",
    "        acceptance_rate = n_accepted / n_samples\n",
    "        return samples, acceptance_rate, cov_matrix\n",
    "\n",
    "# 適応的メトロポリス法の実行\n",
    "print(\"適応的メトロポリス法サンプリング実行中...\")\n",
    "am = AdaptiveMetropolis(\n",
    "    log_prob_fn=lambda x: multivariate_normal_log_prob(x, mu_target, cov_target)\n",
    ")\n",
    "\n",
    "am_samples, am_acceptance_rate, final_cov = am.sample(\n",
    "    initial_value=np.array([0.0, 0.0]),\n",
    "    n_samples=5000\n",
    ")\n",
    "\n",
    "print(f\"\\n適応的メトロポリス法受理率: {am_acceptance_rate:.3f}\")\n",
    "print(f\"\\n最終提案共分散行列:\")\n",
    "print(final_cov)\n",
    "print(f\"\\n真の共分散行列:\")\n",
    "print(cov_target)\n",
    "\n",
    "# 効率の計算\n",
    "am_autocorr, am_eff = compute_efficiency_metrics(am_samples)\n",
    "\n",
    "print(f\"\\n=== 適応的メトロポリス法効率指標 ===\")\n",
    "print(f\"平均自己相関時間: {np.mean(am_autocorr):.2f}\")\n",
    "print(f\"平均有効サンプルサイズ: {np.mean(am_eff):.1f}\")\n",
    "print(f\"効率: {np.mean(am_eff)/len(am_samples[500:]):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全手法の比較可視化\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# サンプル数を統一（最小のものに合わせる）\n",
    "min_samples = min(len(hmc_samples), len(rwmh_samples), len(nuts_samples), len(am_samples))\n",
    "burnin_unified = 300\n",
    "\n",
    "methods = ['Random Walk MH', 'HMC', 'NUTS', 'Adaptive Metropolis']\n",
    "all_samples = [rwmh_samples[:min_samples], hmc_samples[:min_samples], \n",
    "               nuts_samples[:min_samples], am_samples[:min_samples]]\n",
    "all_acceptance = [rwmh_acceptance_rate, hmc_acceptance_rate, nuts_acceptance_rate, am_acceptance_rate]\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "# 1. トレースプロット比較\n",
    "for i, (method, samples, color) in enumerate(zip(methods, all_samples, colors)):\n",
    "    axes[0, 0].plot(samples[:1500, 0], alpha=0.7, label=method, color=color, linewidth=0.8)\n",
    "axes[0, 0].axvline(burnin_unified, color='gray', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].set_title('Trace Plot Comparison (X1)')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('X1')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 散布図比較\n",
    "for i, (method, samples, color) in enumerate(zip(methods, all_samples, colors)):\n",
    "    clean_samples = samples[burnin_unified:]\n",
    "    axes[0, 1].scatter(clean_samples[::20, 0], clean_samples[::20, 1], \n",
    "                      alpha=0.6, s=5, label=method, color=color)\n",
    "axes[0, 1].set_title('Sample Scatter Plot')\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_aspect('equal')\n",
    "\n",
    "# 3. 受理率比較\n",
    "axes[0, 2].bar(methods, all_acceptance, alpha=0.7, color=colors)\n",
    "axes[0, 2].set_title('Acceptance Rate Comparison')\n",
    "axes[0, 2].set_ylabel('Acceptance Rate')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4-6. 各手法の軌跡（最初の200ステップ）\n",
    "trajectory_plots = [(1, 0), (1, 1), (1, 2)]\n",
    "for i, ((row, col), (method, samples, color)) in enumerate(zip(trajectory_plots, \n",
    "                                                               zip(methods[:3], all_samples[:3], colors[:3]))):\n",
    "    traj = samples[:200]\n",
    "    axes[row, col].plot(traj[:, 0], traj[:, 1], '-', alpha=0.7, linewidth=1, color=color)\n",
    "    axes[row, col].plot(traj[:, 0], traj[:, 1], '.', markersize=2, alpha=0.8, color=color)\n",
    "    axes[row, col].plot(traj[0, 0], traj[0, 1], 'go', markersize=6)\n",
    "    axes[row, col].plot(traj[-1, 0], traj[-1, 1], 'ro', markersize=6)\n",
    "    axes[row, col].set_title(f'{method} Trajectory')\n",
    "    axes[row, col].set_xlabel('X1')\n",
    "    axes[row, col].set_ylabel('X2')\n",
    "    axes[row, col].set_aspect('equal')\n",
    "\n",
    "# 7. 効率比較\n",
    "all_eff = [rwmh_eff, hmc_eff, nuts_eff, am_eff]\n",
    "eff_means = [np.mean(eff) for eff in all_eff]\n",
    "\n",
    "axes[2, 0].bar(methods, eff_means, alpha=0.7, color=colors)\n",
    "axes[2, 0].set_title('Effective Sample Size Comparison')\n",
    "axes[2, 0].set_ylabel('Mean Effective Sample Size')\n",
    "axes[2, 0].tick_params(axis='x', rotation=45)\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 8. 自己相関比較\n",
    "for i, (method, samples, color) in enumerate(zip(methods, all_samples, colors)):\n",
    "    clean_samples = samples[burnin_unified:]\n",
    "    if len(clean_samples) > 100:\n",
    "        lags = min(50, len(clean_samples) // 10)\n",
    "        autocorr = acf(clean_samples[:, 0], nlags=lags, fft=True)\n",
    "        axes[2, 1].plot(autocorr, label=method, alpha=0.8, color=color)\n",
    "\n",
    "axes[2, 1].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "axes[2, 1].axhline(0.05, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2, 1].set_title('Autocorrelation Comparison (X1)')\n",
    "axes[2, 1].set_xlabel('Lag')\n",
    "axes[2, 1].set_ylabel('ACF')\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 9. 統計サマリー\n",
    "axes[2, 2].axis('off')\n",
    "summary_text = \"Method Comparison Summary\\n\\n\"\n",
    "all_autocorr = [rwmh_autocorr, hmc_autocorr, nuts_autocorr, am_autocorr]\n",
    "\n",
    "for method, acc_rate, eff, autocorr in zip(methods, all_acceptance, all_eff, all_autocorr):\n",
    "    summary_text += f\"{method}:\\n\"\n",
    "    summary_text += f\"  Acceptance: {acc_rate:.3f}\\n\"\n",
    "    summary_text += f\"  Mean ESS: {np.mean(eff):.1f}\\n\"\n",
    "    summary_text += f\"  Mean τ: {np.mean(autocorr):.2f}\\n\\n\"\n",
    "\n",
    "axes[2, 2].text(0.1, 0.9, summary_text, transform=axes[2, 2].transAxes, \n",
    "               fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 定量的比較表\n",
    "print(f\"\\n=== 全手法の定量的比較 ===\")\n",
    "print(f\"{'Method':<20} {'Acceptance':<12} {'Mean ESS':<12} {'Mean τ':<12} {'Efficiency':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method, acc_rate, eff, autocorr in zip(methods, all_acceptance, all_eff, all_autocorr):\n",
    "    efficiency = np.mean(eff) / (min_samples - burnin_unified)\n",
    "    print(f\"{method:<20} {acc_rate:<12.3f} {np.mean(eff):<12.1f} {np.mean(autocorr):<12.2f} {efficiency:<12.3f}\")\n",
    "\n",
    "# 相対性能\n",
    "print(f\"\\n=== 相対性能（Random Walk MH基準） ===\")\n",
    "base_eff = np.mean(rwmh_eff)\n",
    "base_tau = np.mean(rwmh_autocorr)\n",
    "\n",
    "for method, eff, autocorr in zip(methods, all_eff, all_autocorr):\n",
    "    eff_ratio = np.mean(eff) / base_eff\n",
    "    tau_ratio = base_tau / np.mean(autocorr)  # 小さいほうが良いので逆数\n",
    "    print(f\"{method}: ESS ratio = {eff_ratio:.2f}, τ improvement = {tau_ratio:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 実用的なMCMCライブラリの紹介\n",
    "\n",
    "実際の研究・開発では、専用ライブラリを使用することが一般的です。主要なライブラリを紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要なMCMCライブラリの概要と使用例\n",
    "print(\"=== 主要なMCMCライブラリ ===\")\n",
    "print()\n",
    "\n",
    "libraries_info = {\n",
    "    \"PyMC\": {\n",
    "        \"description\": \"Pythonで最も人気のあるベイズ統計ライブラリ\",\n",
    "        \"features\": [\n",
    "            \"直感的なモデル記述\",\n",
    "            \"自動微分によるHMC/NUTS\",\n",
    "            \"豊富な分布ライブラリ\",\n",
    "            \"変分推論サポート\",\n",
    "            \"優れた可視化機能\"\n",
    "        ],\n",
    "        \"use_cases\": \"階層モデル、時系列分析、機械学習\"\n",
    "    },\n",
    "    \"Stan (PyStan)\": {\n",
    "        \"description\": \"高性能なベイズ推論プラットフォーム\",\n",
    "        \"features\": [\n",
    "            \"専用言語による高速実行\",\n",
    "            \"最先端のNUTS実装\",\n",
    "            \"自動微分と最適化\",\n",
    "            \"R, Python, Julia等の多言語サポート\",\n",
    "            \"詳細な診断機能\"\n",
    "        ],\n",
    "        \"use_cases\": \"複雑なモデル、大規模データ、研究用途\"\n",
    "    },\n",
    "    \"TensorFlow Probability\": {\n",
    "        \"description\": \"TensorFlowベースの確率的プログラミング\",\n",
    "        \"features\": [\n",
    "            \"GPU加速サポート\",\n",
    "            \"深層学習との統合\",\n",
    "            \"変分推論と正規化フロー\",\n",
    "            \"大規模データ対応\",\n",
    "            \"分散計算サポート\"\n",
    "        ],\n",
    "        \"use_cases\": \"ベイズ深層学習、大規模推論\"\n",
    "    },\n",
    "    \"PyTorch/Pyro\": {\n",
    "        \"description\": \"PyTorchベースの確率的プログラミング\",\n",
    "        \"features\": [\n",
    "            \"動的計算グラフ\",\n",
    "            \"HMC/NUTSサポート\",\n",
    "            \"変分推論\",\n",
    "            \"ガイド付き推論\",\n",
    "            \"研究向け柔軟性\"\n",
    "        ],\n",
    "        \"use_cases\": \"研究開発、カスタムモデル\"\n",
    "    },\n",
    "    \"emcee\": {\n",
    "        \"description\": \"アンサンブルサンプラー専門ライブラリ\",\n",
    "        \"features\": [\n",
    "            \"Affine Invariant Ensemble Sampler\",\n",
    "            \"高次元問題に効果的\",\n",
    "            \"並列化サポート\",\n",
    "            \"シンプルなAPI\",\n",
    "            \"天体物理学で人気\"\n",
    "        ],\n",
    "        \"use_cases\": \"高次元パラメータ推定、物理学応用\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for lib_name, info in libraries_info.items():\n",
    "    print(f\"【{lib_name}】\")\n",
    "    print(f\"概要: {info['description']}\")\n",
    "    print(\"主な機能:\")\n",
    "    for feature in info['features']:\n",
    "        print(f\"  • {feature}\")\n",
    "    print(f\"適用分野: {info['use_cases']}\")\n",
    "    print()\n",
    "\n",
    "# ライブラリ選択の指針\n",
    "print(\"=== ライブラリ選択の指針 ===\")\n",
    "print()\n",
    "\n",
    "selection_guide = {\n",
    "    \"初学者・一般的な用途\": \"PyMC - 直感的で豊富なドキュメント\",\n",
    "    \"高性能・複雑なモデル\": \"Stan - 最適化された実装と豊富な診断\",\n",
    "    \"深層学習との統合\": \"TensorFlow Probability, Pyro - GPU活用と大規模データ\",\n",
    "    \"研究・カスタム実装\": \"Pyro, 自作実装 - 柔軟性と制御\",\n",
    "    \"高次元パラメータ推定\": \"emcee - 効率的なアンサンブル手法\",\n",
    "    \"教育・理解\": \"自作実装 - アルゴリズムの詳細理解\"\n",
    "}\n",
    "\n",
    "for use_case, recommendation in selection_guide.items():\n",
    "    print(f\"{use_case}: {recommendation}\")\n",
    "\n",
    "print()\n",
    "print(\"=== パフォーマンス比較の目安 ===\")\n",
    "print()\n",
    "\n",
    "performance_comparison = {\n",
    "    \"実行速度\": \"Stan > TFP ≈ Pyro > PyMC > emcee > 自作実装\",\n",
    "    \"学習コスト\": \"PyMC < emcee < TFP ≈ Pyro < Stan < 自作実装\",\n",
    "    \"柔軟性\": \"自作実装 > Pyro ≈ TFP > Stan ≈ PyMC > emcee\",\n",
    "    \"診断機能\": \"Stan > PyMC > TFP ≈ Pyro > emcee > 自作実装\",\n",
    "    \"コミュニティ\": \"PyMC ≈ Stan > TFP > Pyro > emcee > 自作実装\"\n",
    "}\n",
    "\n",
    "for aspect, ranking in performance_comparison.items():\n",
    "    print(f\"{aspect}: {ranking}\")\n",
    "\n",
    "# 実装例のテンプレート（疑似コード）\n",
    "print()\n",
    "print(\"=== 各ライブラリの実装例（疑似コード） ===\")\n",
    "print()\n",
    "\n",
    "print(\"【PyMC例】\")\n",
    "pymc_example = \"\"\"\n",
    "import pymc as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # 事前分布\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10, shape=p)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "    \n",
    "    # 尤度\n",
    "    mu = pm.math.dot(X, beta)\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
    "    \n",
    "    # サンプリング\n",
    "    trace = pm.sample(2000, tune=1000, cores=4)\n",
    "\"\"\"\n",
    "print(pymc_example)\n",
    "\n",
    "print(\"【Stan例】\")\n",
    "stan_example = \"\"\"\n",
    "# model.stan\n",
    "data {\n",
    "  int<lower=0> n;\n",
    "  int<lower=0> p;\n",
    "  matrix[n, p] X;\n",
    "  vector[n] y;\n",
    "}\n",
    "parameters {\n",
    "  vector[p] beta;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  beta ~ normal(0, 10);\n",
    "  sigma ~ normal(0, 1);\n",
    "  y ~ normal(X * beta, sigma);\n",
    "}\n",
    "\n",
    "# Python\n",
    "import stan\n",
    "posterior = stan.build(stan_code, data=data)\n",
    "fit = posterior.sample(num_chains=4, num_samples=2000)\n",
    "\"\"\"\n",
    "print(stan_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 演習問題\n",
    "\n",
    "### 問題1：HMCのパラメータ調整\n",
    "異なるステップサイズとリープフロッグステップ数でHMCの性能を比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1: HMCパラメータの最適化\n",
    "def hmc_parameter_tuning(log_prob_fn, grad_log_prob_fn, initial_q, n_samples=2000):\n",
    "    \"\"\"\n",
    "    HMCのパラメータ（ε, L）の最適化実験\n",
    "    \n",
    "    ヒント：\n",
    "    1. 異なる(ε, L)の組み合わせでHMCを実行\n",
    "    2. 受理率、有効サンプルサイズ、ハミルトニアン誤差を記録\n",
    "    3. 最適なパラメータ組み合わせを特定\n",
    "    4. トレードオフ関係を可視化\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    epsilons = [0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "    L_values = [5, 10, 20, 30, 50]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # パラメータグリッドサーチの実装\n",
    "    # ...\n",
    "    \n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テスト実行\n",
    "# results = hmc_parameter_tuning(\n",
    "#     lambda x: multivariate_normal_log_prob(x, mu_target, cov_target),\n",
    "#     lambda x: multivariate_normal_grad_log_prob(x, mu_target, cov_target),\n",
    "#     np.array([0.0, 0.0])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2：並列MCMC\n",
    "複数のチェーンを並列実行し、結果を統合する手法を実装してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2: 並列MCMCの実装\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "\n",
    "def parallel_mcmc_chains(sampler_func, sampler_args, n_chains=4, n_samples=2000):\n",
    "    \"\"\"\n",
    "    複数チェーンの並列実行\n",
    "    \n",
    "    Parameters:\n",
    "    - sampler_func: サンプリング関数\n",
    "    - sampler_args: サンプラー引数のリスト（チェーンごと）\n",
    "    - n_chains: チェーン数\n",
    "    - n_samples: チェーンあたりのサンプル数\n",
    "    \n",
    "    実装のヒント：\n",
    "    1. ProcessPoolExecutorを使用\n",
    "    2. 異なる初期値・乱数シードでチェーンを開始\n",
    "    3. Gelman-Rubin診断で収束確認\n",
    "    4. チェーンの結合と統計計算\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "def single_chain_wrapper(args):\n",
    "    \"\"\"\n",
    "    単一チェーン実行のラッパー関数\n",
    "    \"\"\"\n",
    "    # 並列処理用のラッパー実装\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# 使用例（疑似コード）\n",
    "# chains_results = parallel_mcmc_chains(\n",
    "#     sampler_func=random_walk_mh,\n",
    "#     sampler_args=[\n",
    "#         (log_prob_fn, initial_values[i], n_samples, step_size) \n",
    "#         for i in range(n_chains)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "この章では、高度なMCMC手法について学習しました：\n",
    "\n",
    "### 学習した手法\n",
    "\n",
    "1. **ハミルトニアンモンテカルロ法（HMC）**：\n",
    "   - 物理学的原理の活用\n",
    "   - 勾配情報による効率的探索\n",
    "   - リープフロッグ積分による数値計算\n",
    "   - 高次元問題での優位性\n",
    "\n",
    "2. **No-U-Turn Sampler（NUTS）**：\n",
    "   - HMCの自動パラメータ調整\n",
    "   - U-turn検出による最適軌跡長\n",
    "   - 適応的ステップサイズ調整\n",
    "   - 実用性の向上\n",
    "\n",
    "3. **適応的MCMC**：\n",
    "   - 実行中のパラメータ自動調整\n",
    "   - 経験共分散による提案分布最適化\n",
    "   - ユーザー介入の削減\n",
    "\n",
    "### 性能比較の結果\n",
    "\n",
    "| 手法 | 受理率 | 効率 | 適用範囲 | 実装難易度 |\n",
    "|------|--------|------|----------|------------|\n",
    "| Random Walk MH | 中 | 低 | 汎用 | 易 |\n",
    "| HMC | 高 | 高 | 連続・微分可能 | 中 |\n",
    "| NUTS | 高 | 最高 | 連続・微分可能 | 難 |\n",
    "| Adaptive MH | 中〜高 | 中〜高 | 汎用 | 中 |\n",
    "\n",
    "### 実用的な指針\n",
    "\n",
    "**手法選択の基準**：\n",
    "- **勾配利用可能** → HMC/NUTS\n",
    "- **高次元問題** → HMC/NUTS/Ensemble methods\n",
    "- **離散パラメータ** → Gibbs/MH\n",
    "- **計算資源制約** → Adaptive MH\n",
    "- **実装簡単さ重視** → Random Walk MH\n",
    "\n",
    "**ライブラリ活用**：\n",
    "- 研究・開発では専用ライブラリの使用を強く推奨\n",
    "- PyMC, Stan, TensorFlow Probabilityが主要選択肢\n",
    "- アルゴリズム理解のための自作実装も有効\n",
    "\n",
    "### 今後の発展\n",
    "\n",
    "- **変分推論**：近似的だが高速なベイズ推論\n",
    "- **正規化フロー**：複雑な事後分布の表現\n",
    "- **GPU加速**：大規模データへの対応\n",
    "- **自動微分**：勾配計算の自動化\n",
    "- **ベイズ深層学習**：ニューラルネットワークとの統合\n",
    "\n",
    "MCMCは現代の統計学・機械学習における中核技術として、今後も発展を続けることが予想されます。基礎理論の理解と実践的な応用スキルの両方を身につけることが重要です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}