了解しました。工学部の学生向けに、MCMCの基本理論をわかりやすく解説し、Pythonで網羅的なシミュレーション例を含んだ教材を構成します。

教材には、メトロポリス法、メトロポリス–ヘイスティングス法、ギブスサンプリングなど代表的なMCMC手法の理論と、それぞれを使ったPythonコード付きのシミュレーション例を含めます。準備が整い次第ご案内します。


# マルコフ連鎖モンテカルロ法（MCMC）入門

## 1. MCMCとは何か – 背景と概要

マルコフ連鎖モンテカルロ法（**M**arkov **C**hain **M**onte **C**arlo, 略して **MCMC**）は、**「複雑な確率分布からサンプル（乱数）を生成することで、その分布を近似する手法」**です。統計分析や機械学習の分野では、直接サンプリングが難しい分布（例えばベイズ推定で登場する事後分布など）からランダムサンプルを得たい場面が頻繁にあります。しかし高次元であったり正規化定数（分布の積分値）が不明な場合、そのままサンプルを得るのは困難です。MCMC法では**マルコフ連鎖**の仕組みを利用し、目的の**確率分布（目標分布）に従うマルコフ連鎖を構築**します。そして、その連鎖を十分に実行することで連鎖の状態が目標分布に従うと期待し、得られたサンプル列から分布の性質（例えば期待値や分散、確率密度の形状）を近似的に計算します。このように、MCMC法は乱数を用いて確率分布の積分計算（期待値計算など）を近似する強力な方法であり、現在ではベイズ統計や機械学習を中心に多くの場面で利用されています。

**Monte Carlo（モンテカルロ）法の基本発想:** MCMCを理解するため、まず「モンテカルロ法」とは何かを直感的に説明します。モンテカルロ法とは\*\*「乱数（無作為抽出）を使って何らかの値を近似計算する手法」**のことです。有名な例として、モンテカルロ法で円周率πを近似計算する方法があります。例えば、辺の長さ2の正方形に内接する半径1の円を考え、正方形内に無作為に点を打つことを想像してください。十分多数の点を打つと、**円の中に入った点の割合**は**円の面積/正方形の面積 = π/4\*\* に近づいていきます。この性質を利用し、総打点数に対する円内の点数の比率からπを推定するのです。実際に点を増やしていくと、その割合は徐々に\*\*3.14…**に収束していきます（大数の法則による）。この例から分かるように、モンテカルロ法では**偶然性（乱数）\*\*を利用して数値計算を行います。

**Markov Chain（マルコフ連鎖）の基本発想:** 次に「マルコフ連鎖」とは何でしょうか。マルコフ連鎖とは\*\*「未来の状態が直前の現在の状態のみに依存し、過去の状態には依存しない」という性質を持つ確率過程**のことです。言い換えると、状態の推移が**「直前の状態のみ記憶する\*\*（メモリーレス）」\*\*仕組みになっている連鎖です。例えば、ある日の天気が前日だけで決まりそれ以前の影響は無視する、というようなモデルがマルコフ連鎖的な発想です。数式で表現すると、時刻\$t\$での状態を\$X\_t\$とし、

* \$P(X\_{t+1}=j \mid X\_t=i,;X\_{t-1}=i\_{t-1},\dots) = P(X\_{t+1}=j \mid X\_t=i)\$

となる関係を満たします。この関係性がマルコフ性であり、現在状態\$i\$から次状態\$j\$への遷移確率を\$p\_{ij}\$で表します。マルコフ連鎖では長い時間実行すると一定の確率分布（**定常分布**と呼ばれる）に状態が従う場合があり、さらに**エルゴード性**（初期状態に関係なく同じ定常分布に収束する性質）を満たすとき、十分後の状態は初期値の影響を忘れて定常分布に従います。MCMCではこの**定常分布**を自分が欲しい目標分布に設定したマルコフ連鎖を設計し、その連鎖を動かすことで目標分布のサンプルを得ようというわけです。

**MCMCの基本原理:** 以上より、**MCMC = 「マルコフ連鎖」 + 「モンテカルロ法」**と言えます。すなわち、「直前の状態だけに基づいて次の状態を確率的に生成していく連鎖（マルコフ連鎖）を利用し、乱数を使って近似計算を行う（モンテカルロ法）」手法です。MCMCでは**目標とする確率分布\$\pi(x)\$を定常分布にもつような状態遷移ルール**を工夫してマルコフ連鎖を作ります。そしてその連鎖を長時間シミュレーションし、十分「焼き慣らし（burn-in）」を経た後の状態系列をサンプルとして集めます。うまく設計されたマルコフ連鎖であれば、集めたサンプルは互いに依存はあるものの最終的には**目標分布に従うサンプル列**となります。これによって、直接その分布から乱数を生成できなくても、間接的に**マルコフ連鎖のシミュレーションで目的の乱数サンプルを手に入れる**ことが可能になるのです。特に重要なのは、多くの場合**目標分布\$\pi(x)\$の「形（比例式）」さえ分かれば良く、正規化定数は不要**という点です。たとえばベイズ推定で事後分布\$p(\theta \mid D)\$を得たい場合、分母となる周辺尤度（証拠）が不明でも、Metropolis-Hastings法では事後分布に比例した値\$\tilde{\pi}(\theta) = p(D|\theta)p(\theta)\$の比だけで受容確率が計算できるため正規化定数はキャンセルされます。この性質こそ、複雑な分布からサンプリングするMCMC法の威力と言えるでしょう。

---

## 2. 基本的なMCMCアルゴリズム概要

MCMC法にはさまざまなアルゴリズムがありますが、まずは代表的な基本手法である**メトロポリス法**、その拡張である**メトロポリス–ヘイスティングス法**、そして多次元分布に便利な**ギブスサンプリング**という3つのアルゴリズムに注目します。以下では、それぞれの**アルゴリズムの原理、特徴、使いどころ**について直感的に解説します。いずれもMCMCの一種であり、適切に使い分けることで様々な問題に対応できます。

### 2.1 メトロポリス法 (Metropolis法)

**原理:** メトロポリス法は、MCMCアルゴリズムの中でも最も基本的な手法の一つで、**対称な提案分布**を用いたサンプリング法です。目標とする確率密度（例えば事後分布に比例する関数）を\$f(x)\$とすると、以下のような手順でマルコフ連鎖を構築します。

1. **初期値** \$x^{(0)}\$ を適当に定めます。
2. **提案**: 現在の状態\$x^{(t)}\$から**対称な提案分布** \$q(y|x)\$ （例えば平均\$x^{(t)}\$、一定分散の正規乱数など）に従って**候補点** \$y\$ をランダムに生成します。対称な分布とは、\$q(y|x)=q(x|y)\$が成り立つ分布のことで、具体例として「現在位置を平均とするガウス分布に従って乱数を生成する」といった方法がよく用いられます。
3. **受容/棄却判定**: 提案された候補点\$y\$の確率密度\$f(y)\$と現在点の確率密度\$f(x^{(t)})\$を比較します。\$f(y)\$が大きければ（つまりより高確率の領域に移動したなら）**常に受容**し、次の状態\$x^{(t+1)}=y\$とします。一方、\$f(y)\$が小さければ（低確率な方向への移動なら）、**確率**

$$
r = \frac{f(y)}{\,f(x^{(t)})\,}
$$

で受容し、受容されれば\$x^{(t+1)}=y\$、拒否された場合は**現在の状態を維持**して\$x^{(t+1)}=x^{(t)}\$とします。この受容確率\$r\$は0〜1の値になるので、0から1の一様乱数を発生させて\$r\$と比較することで確率的な受容/棄却を実現できます。
4\. **次イテレーションへ**: 上記の提案と受容判定を繰り返します。十分多く反復すれば、状態\$x^{(t)}\$は目標の確率密度\$f(x)\$に従ったサンプル列になります。

このアルゴリズムでは、**「高い確率の領域へは貪欲に進み、低い確率の領域へは時折チャレンジする」**ような動きをします。例えば、確率密度関数\$f(x)\$の形を「山」にたとえると、**登山者が山頂を目指して登り、山頂付近ではあまり降りないように留まる**動きに相当します。こうすることで、結果的に**山（確率密度の高い部分）に長く留まる**ことになり、高い確率の領域を重点的にサンプリングできるわけです。この直感的説明から、メトロポリス法は「**確率山登り法**」のようにイメージすると分かりやすいでしょう。

**特徴と使いどころ:** メトロポリス法では提案分布に対称な分布を用いるため、受容確率の計算が単純で**目標密度の比**をとるだけで済みます。実装も比較的容易であり、**乱数による積分計算の入門**としてもしばしば紹介されます。しかし提案分布が対称である必要があるため、複雑な分布に対して移動の工夫をしたい場合には制約があります。また後述するメトロポリス–ヘイスティングス法の特殊ケースとみなせるため、現在では理論上はMH法に統一されることも多いです。ただし\*\*「現在の状態にランダムな摂動を加える」\*\*というアイデア自体は非常にシンプルで、多くの場合に有効です。使いどころとしては、**とりあえずシンプルなMCMCサンプラーを実装したい場合**や、提案分布に特にこだわりが無い場合にまず試してみる価値があります。また後述のギブスサンプリングのように各次元ごとにサンプルできない場合（条件付き分布が取り出せない場合）にも、このランダムウォーク型のメトロポリス法が活躍します。

### 2.2 メトロポリス–ヘイスティングス法 (MH法)

**原理:** メトロポリス–ヘイスティングス法（**MH法**）は、メトロポリス法を一般化し**非対称な提案分布**にも対応できるようにしたアルゴリズムです。基本的な流れはメトロポリス法と同じですが、受容確率の計算に**提案分布\$q\$の遷移確率**を考慮します。現在の状態を\$x\$、提案された次状態の候補を\$y\$とすると、MH法での**受容確率**\$\alpha\$は次の式で与えられます。

$$
\alpha(y|x) = \min\!\Biggl(1,\;\frac{\,f(y)\,q(x|y)\,}{\,f(x)\,q(y|x)\,}\Biggr)\,,
$$

ここで\$f(\cdot)\$は目標分布の確率密度（比例関数でも可）、\$q(y|x)\$は提案分布で「現在\$x\$から\$y\$を提案する確率密度」を表します。この\$\alpha\$に従って受容・棄却を決め、受容なら\$x^{(t+1)}=y\$、棄却なら\$x^{(t+1)}=x^{(t)}\$とします（他の部分はメトロポリス法と同様です）。もし提案分布が対称（\$q(y|x)=q(x|y)\$）ならこの式は\$f(y)/f(x)\$に簡略化され、**メトロポリス法**の規則に一致します。

**特徴:** MH法の長所は、**提案分布\$q\$を自由に設計できる柔軟性**にあります。問題に応じて「こう動いてほしい」という形の提案を導入でき、例えば**非対称な飛び方**（過去の履歴に応じてステップサイズを変える、ターゲット分布の一部を近似する分布からサンプルする等）も可能です。理論上、どんな提案分布であっても上記の受容確率でバイアスのないサンプルが得られることが保証されています。一方で、提案の自由度が高い分、**効率よくサンプリングするには提案分布の調整（チューニング）が重要**になります。提案が大き過ぎると受容率が極端に低くなり多くが棄却されて進まなくなりますし、逆に小さ過ぎると受容はされるものの少しずつしか動けずサンプル間の相関が強くなります。適切な受容率（一般に20〜50%程度が目安）の範囲になるよう、提案分布の分散や形状を調節する必要があります。この調整は実務上しばしば**難関**になりますが、上手くいけば高次元空間でも柔軟かつ効率的にサンプリングできる強力な手法です。

**使いどころ:** MH法は**現在最も汎用的に使われているMCMCアルゴリズム**です。目標分布\$f(x)\$さえ計算できれば（正規化定数は不要）、任意の提案メカニズムを組み込んでサンプリングが可能なので、**ベイズ推定の事後分布**の計算など広範な用途に適用されています。例えば、「複雑な事後分布から乱数を得たいが、その事後分布はベイズの分母（周辺尤度）が不明なので直接サンプリングできない」という場合でも、MH法なら**事後分布に比例する値（尤度×事前）**さえ計算できればサンプリングできます。これは前述のとおり受容確率で**比\$\frac{f(y)}{f(x)}\$**（またはその拡張の比）を取るため、未知の正規化定数が約分されてしまうからです。この利点により、MH法はモンテカルロ積分によるベイズ推定の主要手段となっています。総じて、**「柔軟に設計可能なMCMC」が欲しいときはMH法**を選ぶことになります。

---

## 3. Pythonによるシミュレーション例 – MH法とギブスサンプリング

ここからは、実際にPythonを使って基本的なMCMCアルゴリズムのシミュレーションを行い、その挙動を確認してみましょう。扱う例として、**2次元正規分布**（平均\$\boldsymbol{\mu}=\mathbf{0}\$、分散共分散行列\$\Sigma=\begin{pmatrix}1 & 0.8\0.8 & 1\end{pmatrix}\$、すなわち**相関0.8**の2変量正規分布）を目標分布とします。この分布は\$x\_1\$と\$x\_2\$に強い相関があるため、一様乱数から直接サンプルするのは難しいですが、MCMC法を使えばサンプル列を生成しその分布を再現できることを確認します。

### 3.1 Metropolis-Hastings法の実装例

まずは**メトロポリス–ヘイスティングス法（対称な提案分布を使用しているので本質的にはメトロポリス法）**を実装し、サンプルを生成してみます。提案分布には**現在の点を平均とする等方的ガウス分布**（標準偏差`scale=0.5`）を用い、アルゴリズムは上で述べた通りの手順で進めます。以下のコードでは、目標密度関数`target_pdf(x)`を定義し、MH法によるサンプリング関数`metropolis_hastings`を実装しています（受容確率の計算では提案分布が対称なので単に\$p\_{\text{proposal}}/p\_{\text{current}}\$の比になっている点に注目してください）。

```python
import numpy as np
import matplotlib.pyplot as plt

# 目標の2次元正規分布のパラメータ（平均ベクトルと分散共分散行列）
mu = np.array([0.0, 0.0])
Sigma = np.array([[1.0, 0.8],
                  [0.8, 1.0]])
inv_Sigma = np.linalg.inv(Sigma)                      # 分散共分散行列の逆行列
det_Sigma = np.linalg.det(Sigma)                      # 分散共分散行列の行列式

def target_pdf(x):
    """目標分布（2次元ガウス）の確率密度を計算"""
    diff = x - mu
    exponent = -0.5 * diff @ inv_Sigma @ diff         # x^T Sigma^{-1} x の計算
    coeff = 1.0 / (2.0 * np.pi * np.sqrt(det_Sigma))  # 正規化定数（2π√|Sigma|）の逆数
    return coeff * np.exp(exponent)

def metropolis_hastings(n_samples=10000, scale=0.5):
    """メトロポリス–ヘイスティング法で2次元正規分布からサンプルを取得"""
    samples = []
    x_current = np.array([0.0, 0.0])  # 初期値（ここでは目標分布の平均に設定）
    for t in range(n_samples):
        # 対称な提案分布: 現在位置を平均としたガウス乱数を生成
        x_proposal = x_current + scale * np.random.randn(2)
        # 目標密度の比（対称な提案ゆえ提案分布の比は不要）
        p_current = target_pdf(x_current)
        p_proposal = target_pdf(x_proposal)
        ratio = p_proposal / p_current
        # 受容判定: ratioと一様乱数を比較
        if np.random.rand() < min(1.0, ratio):
            x_current = x_proposal  # 受容：状態を更新
        # 棄却の場合はx_currentをそのまま次ステップへ（状態据え置き）
        samples.append(x_current.copy())
    return np.array(samples)

# サンプル生成の実行
samples = metropolis_hastings(n_samples=10000, scale=0.5)

# 前半のバーンイン期間は除去し、残りのサンプルを可視化
burn_in = 1000
samples_after_burnin = samples[burn_in:]

plt.figure(figsize=(6,6))
plt.scatter(samples_after_burnin[:, 0], samples_after_burnin[:, 1], 
            s=5, alpha=0.3)
plt.xlabel("x1")
plt.ylabel("x2")
plt.title("Metropolis-Hastings: samples from target distribution")
plt.axis("equal")
plt.show()
```

上記コードを実行すると、メトロポリス–ヘイスティング法により生成されたサンプルが得られます。可視化の散布図では、サンプルが元の目標分布（相関0.8の2次元正規分布）に概ね従っていることが確認できます。バーンイン期間として初期の1000サンプルは捨て、以降のサンプルをプロットしています。また、`scale=0.5`という提案分布の幅は経験的に適度な受容率をもたらす値として選びました（受容率が極端でないことがサンプル効率に重要です）。

&#x20;*メトロポリス–ヘイスティング法で得られたサンプル（焼き慣らし後）。相関0.8の2次元正規分布に従う点が生成されており、楕円形の分布を再現している。プロット上の点の濃い部分は高密度領域（分布の中心付近）にサンプルが多く集まっていることを示す。*

加えて、メトロポリス–ヘイスティング法の**チェーン（状態遷移）の動き**を少し覗いてみましょう。次の図は、初期値を離れた点（例えば(-3, -3)）に設定した場合に、最初の数十ステップでサンプルがどのように移動するかを示したものです。左図はMH法のチェーン、右図は後述のギブスサンプリングのチェーンの比較です。それぞれ緑の点がスタート位置、赤の点が終了位置を表しています。

&#x20;\*図: MCMCチェーンの初期挙動の比較（左: MH法、右: ギブスサンプリング）。MH法では現在地付近を中心に**ランダムウォーク**的に移動し、確率の高い方向へは受容されやすく徐々に高密度領域へ近づいている。一方ギブスサンプリングでは座標を1つずつ交互に更新するため、\*\*碁盤の目状（軸に沿った直角方向）\**にステップが進んでいる様子が分かる。このようにアルゴリズムによってチェーンの動き方に特徴が現れる。最終的にはどちらも高密度領域（中心付近）へ収束していく。*

メトロポリス–ヘイスティング法のチェーン（左図）では、低確率領域では提案が棄却され留まることもありますが、確率が高くなる方向には次第に受容されて**山を登っていく**挙動が見てとれます。一方、ギブスサンプリングのチェーン（右図）は後述しますが、一度に1変数ずつしか更新しないため**縦横の軸方向へジグザグ**に進むのが特徴的です。それでも長期的には同じ高密度領域にサンプルが集まる点に注目してください。

### 3.2 ギブスサンプリングの実装例

続いて、**ギブスサンプリング**によって同じ目標の2次元正規分布からサンプルを生成してみます。ギブスサンプリングでは各変数を交互に条件付き分布からサンプリングします。今回の例では、2次元正規分布の**各成分の条件付き分布も正規分布**になります。その性質（**多変量正規分布の周辺・条件付きも正規**）を利用し、\$X\_1\$を\$X\_2\$の値に条件付けた正規分布から、次に\$X\_2\$を新しい\$X\_1\$に条件付けた正規分布から、というように交互にサンプルします。具体的には、\$X\_1|X\_2=y \sim \mathcal{N}(\rho y,;1-\rho^2)\$、\$X\_2|X\_1=x \sim \mathcal{N}(\rho x,;1-\rho^2)\$となります（\$\rho\$は2次元正規分布の相関係数。今回\$\rho=0.8\$）[^1]。このアルゴリズムでは\*\*各ステップで必ず新しい値が採用される（受容拒否がない）\*\*点がMH法との大きな違いです。

以下のコードはギブスサンプリングを実装し、サンプルを得る例です。

```python
import numpy as np
import matplotlib.pyplot as plt

rho = 0.8  # 目標分布の相関係数（2次元正規分布）
def gibbs_sampling(n_samples=10000):
    samples = []
    x1, x2 = 0.0, 0.0  # 初期値（ここでは0,0に設定）
    for t in range(n_samples):
        # Step1: X1 を X2 に条件付けた分布からサンプリング
        mean_x1 = rho * x2
        var_x1 = 1 - rho**2
        x1 = np.random.normal(loc=mean_x1, scale=np.sqrt(var_x1))
        # Step2: X2 を 更新後のX1 に条件付けた分布からサンプリング
        mean_x2 = rho * x1
        var_x2 = 1 - rho**2
        x2 = np.random.normal(loc=mean_x2, scale=np.sqrt(var_x2))
        samples.append([x1, x2])
    return np.array(samples)

# ギブスサンプリングでサンプルを生成
samples = gibbs_sampling(n_samples=10000)

# 前半の1000サンプルをバーンインとして破棄
samples_after_burnin = samples[1000:]

plt.figure(figsize=(6,6))
plt.scatter(samples_after_burnin[:,0], samples_after_burnin[:,1], 
            s=5, alpha=0.3, color="green")
plt.xlabel("x1")
plt.ylabel("x2")
plt.title("Gibbs Sampling: samples from target distribution")
plt.axis("equal")
plt.show()
```

ギブスサンプリングのコードでは、各ステップで\$x\_1, x\_2\$を交互に更新しています。2次元正規分布の場合、条件付き分布が計算しやすいため、このように直接サンプリングできます。得られたサンプルを可視化すると、やはり元の分布とよく一致する点が確認できます。特にMH法の場合と比べて、**一度のステップで確率の高い方向に必ず進める**（必ずどちらかの座標を動かす）ため、受容拒否による足踏みがない点に注目してください。 *ギブスサンプリングで得られたサンプル（焼き慣らし後）。MH法の場合と同様、目標の2次元正規分布に従う点群が得られている。緑色の点はギブスサンプル、オレンジ色の点（前掲【22】図）はMH法のサンプルであるが、両者に大きな違いはなく、どちらも正しく目標分布を再現できていることが分かる。*

**特徴:** ギブスサンプリングは「各変数の条件付き分布からサンプルできる」場合には**実装が簡単**で\*\*受容率100%（毎回更新が起こる）\*\*という利点があります。特に高次元の場合でも各次元ずつ順番に更新すれば良いため、次元が増えても提案の調整などをあまり気にせず適用しやすいです。また条件付き分布に従う抽出なので、一歩一歩が目標分布に「沿った」動きであり無駄が少ない場合が多いです。例えば今回のように多変量正規分布で相関がある場合でも、条件付き分布は比較的強く平均が引っ張られるため、**割と大きくステップできる**傾向があります（初期値が遠くても数ステップで高密度領域に入ることが期待できます）。

**欠点:** 一方でギブスサンプリングは**適用できる条件が限られる**点に注意が必要です。条件付き分布を解析的に書けても、それが容易にサンプリング可能とは限りません（分布の形が複雑で乱数生成が難しい場合があります）。そのような場合には無理にギブスサンプリングを適用できず、MH法など他のMCMCに頼る必要があります。また、変数間の相関が非常に強い場合、ギブスサンプリングは一度に一方向にしか動けないため、**チェーンの収束が遅くなる**可能性があります（ジグザグと細かく刻む動きになって効率が悪化することがあります）。今回の例でも\$\rho=0.99\$のように極端に相関が高いと、MH法で対角方向に大きく提案した方が早く動ける場合もあります。従って、**各変数ごとには簡単にサンプリングできるが同時分布は複雑**という状況で威力を発揮する一方、すべての問題に万能ではない点は押さえておきましょう。

---

## 4. アルゴリズムのまとめと実用上の注意

最後に、取り上げた3つのアルゴリズムのポイントをまとめ、実際にMCMC法を適用する上での注意点に触れます。

* **メトロポリス法:** 対称提案によるシンプルなMCMC。実装が容易で直感的な乱歩サンプラーとして有用。提案分布の調整が比較的単純だが、高次元では効率が落ちることも。基本的にはMH法の特別ケースなので、特殊な理由がなければMH法で代替可能。
* **メトロポリス–ヘイスティングス法:** 最も汎用的なMCMC。提案分布を自由に設計でき、あらゆる状況に対応可能。適切な提案の選択・調整が肝要で、経験的チューニングが必要になる。高度なバリエーションとして**アダプティブMH法**（逐次的に提案を調整）や**独立MH法**（現在と無関係に提案）などもある。困ったらまずMH法を試すのが基本。
* **ギブスサンプリング:** 条件付き分布に従ったサンプルが取り出せる場合には極めて有効。収束が速く実装も簡単だが、条件付き分布が容易にサンプリング可能というモデルに限る。ベイズ統計で**共役事前分布**を用いたモデルでは事後分布の条件付きが分かりやすいのでしばしば適用される。そうでない場合はMH法とのハイブリッド（例：一部の変数はギブス、それ以外はMHで提案）など工夫する。

**MCMC全般の実用上の注意:** MCMCで得られるサンプル列は**一様独立な乱数ではなく、相関のある系列**です。したがって推定量の分散は独立サンプルの場合より大きくなります。実務では、**十分なイテレーションを回して収束したと判断できるか**を確認する必要があります。一般的に、チェーンが定常分布に近づくまでの**バーンイン（焼き慣らし）期間**のサンプルは捨て、それ以降のサンプルを解析に用います。またサンプル間の相関を低減するため、例えば\*\*10ステップに1個だけ採用する（サブサンプリングやシンニング）\*\*といった手法もとられます。複数の独立したチェーンを走らせて収束を診断すること（**Gelman-Rubin診断**など）も推奨されます。さらに、高次元・複雑な分布では基本的なMHやギブスでは非効率な場合もあり、**ハミルトニアンモンテカルロ法（HMC）**や**差分進化MCMC**などの高度な手法が有効なこともあります。目的に応じてアルゴリズムを使い分け、十分な試行錯誤と診断を行うことが、MCMCによる信頼性の高い推定には不可欠です。

以上、MCMCの基本概念と代表的なアルゴリズムについて、工学部の学生でも理解できるレベルで概説しました。MCMC法は、一見魔法のように感じられるかもしれませんが、その基礎は「乱数による近似計算」と「現在にだけ基づく遷移ルール」の組み合わせに過ぎません。一度原理を理解すれば応用範囲は広く、ベイズ推定から機械学習の最先端まで様々な場面で役立つ強力な道具となります。ぜひ実際に手を動かしてコードを実行し、MCMCサンプルが目標分布に近づいていく様子を体感してみてください。

[^1]: 条件付き分布の平均と分散の導出には多変量正規分布の性質を利用しています。より一般には、\$d\$次元正規分布 \$\mathcal{N}(\mu,\Sigma)\$ において、成分を\$X=(X\_i, X\_{-i})\$（\$X\_{-i}\$は\$X\_i\$以外すべて）と分けると、\$X\_i \mid X\_{-i} \sim \mathcal{N}!\Big(\mu\_i + \Sigma\_{i,-i}\Sigma\_{-i,-i}^{-1}(X\_{-i}-\mu\_{-i}),;\Sigma\_{i,i} - \Sigma\_{i,-i}\Sigma\_{-i,-i}^{-1}\Sigma\_{-i,i}\Big)\$ となります。今回の場合は対称性により簡略化され、上記のようになります。
