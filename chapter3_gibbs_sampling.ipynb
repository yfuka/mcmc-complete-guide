{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: ギブスサンプリング\n",
    "\n",
    "## 学習目標\n",
    "- ギブスサンプリングの基本原理を理解する\n",
    "- 条件付き分布の導出方法を学ぶ\n",
    "- 多変量正規分布での実装を習得する\n",
    "- 混合モデルや階層モデルへの応用を理解する\n",
    "- ブロックギブスサンプリングの概念を学ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.1 ギブスサンプリング：「棄却のないMCMC」の威力\n\nギブスサンプリングは、多変量分布 $p(x_1, x_2, ..., x_k)$ からサンプリングを行う、極めてエレガントなMCMC手法です。その最大の特徴は「**受理率100%**」という驚異的な効率性にあります。\n\n### 基本アイデア：複雑な問題の分解\n\n高次元の複雑な同時確率分布からのサンプリングを、一連のより単純な**1次元サンプリング**に分解するのが核心的アイデアです。\n\n### アルゴリズム（k変数の場合）\n1. **初期値設定**: $(x_1^{(0)}, x_2^{(0)}, ..., x_k^{(0)})$ を適当に設定\n2. **各イテレーション** $t$ で以下を順次実行：\n   - $x_1^{(t+1)} \\sim p(x_1 | x_2^{(t)}, x_3^{(t)}, ..., x_k^{(t)})$\n   - $x_2^{(t+1)} \\sim p(x_2 | x_1^{(t+1)}, x_3^{(t)}, ..., x_k^{(t)})$\n   - $\\vdots$\n   - $x_k^{(t+1)} \\sim p(x_k | x_1^{(t+1)}, x_2^{(t+1)}, ..., x_{k-1}^{(t+1)})$\n\nこのジグザグとしたサンプリングを繰り返すことで、サンプル列は目標とする同時分布に収束します。\n\n### MH法との根本的な関係\n\nギブスサンプリングは、実は**メトロポリス・ヘイスティングス法の特殊で効率的なケース**です：\n\n- **提案分布**: 完全条件付き分布 $p(x_i'|x_{-i}^{(t)})$ そのものを使用\n- **採択確率**: $\\alpha = \\min(1, \\frac{p(x_i'|x_{-i}^{(t)}) \\cdot p(x_i'|x_{-i}^{(t)})}{p(x_i^{(t)}|x_{-i}^{(t)}) \\cdot p(x_i^{(t)}|x_{-i}^{(t)})}) = \\min(1, 1) = 1$\n\nつまり、**すべての提案が必ず採択される「棄却のないMH法」**なのです。\n\n### 長所と制約\n\n**長所:**\n- ✅ **受理率100%**: 提案分布のチューニング不要\n- ✅ **計算効率**: 複雑な受理確率計算が不要\n- ✅ **自動的な詳細釣り合い**: 条件付き分布の性質により自然に満たされる\n\n**制約:**\n- ❌ **適用範囲の限定**: すべての完全条件付き分布が「既知の」確率分布である必要\n- ❌ **数学的配慮**: 共役事前分布などの慎重な設計が必要\n\nギブスサンプリングは「適用できる場合には非常に効率的」な、条件付きの強力な手法です。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 例1：2変量正規分布からのサンプリング\n",
    "\n",
    "まず、解析的に条件付き分布を導出できる2変量正規分布でギブスサンプリングを実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling_bivariate_normal(mu, cov, n_samples, initial_value=None):\n",
    "    \"\"\"\n",
    "    2変量正規分布からのギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - mu: 平均ベクトル [mu_x, mu_y]\n",
    "    - cov: 共分散行列 [[var_x, cov_xy], [cov_xy, var_y]]\n",
    "    - n_samples: サンプル数\n",
    "    - initial_value: 初期値 [x0, y0]\n",
    "    \n",
    "    Returns:\n",
    "    - samples: shape (n_samples, 2) のサンプル配列\n",
    "    \"\"\"\n",
    "    samples = np.zeros((n_samples, 2))\n",
    "    \n",
    "    # 条件付き分布のパラメータを事前計算\n",
    "    mu_x, mu_y = mu[0], mu[1]\n",
    "    var_x, var_y = cov[0, 0], cov[1, 1]\n",
    "    cov_xy = cov[0, 1]\n",
    "    \n",
    "    # 相関係数\n",
    "    rho = cov_xy / np.sqrt(var_x * var_y)\n",
    "    \n",
    "    # 条件付き分布の標準偏差\n",
    "    sigma_x_given_y = np.sqrt(var_x * (1 - rho**2))\n",
    "    sigma_y_given_x = np.sqrt(var_y * (1 - rho**2))\n",
    "    \n",
    "    # 初期値の設定\n",
    "    if initial_value is None:\n",
    "        x, y = mu_x, mu_y\n",
    "    else:\n",
    "        x, y = initial_value[0], initial_value[1]\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # x | y からサンプリング\n",
    "        # p(x|y) ~ N(mu_x + rho*(sigma_x/sigma_y)*(y - mu_y), sigma_x^2*(1-rho^2))\n",
    "        mu_x_given_y = mu_x + rho * np.sqrt(var_x / var_y) * (y - mu_y)\n",
    "        x = np.random.normal(mu_x_given_y, sigma_x_given_y)\n",
    "        \n",
    "        # y | x からサンプリング\n",
    "        # p(y|x) ~ N(mu_y + rho*(sigma_y/sigma_x)*(x - mu_x), sigma_y^2*(1-rho^2))\n",
    "        mu_y_given_x = mu_y + rho * np.sqrt(var_y / var_x) * (x - mu_x)\n",
    "        y = np.random.normal(mu_y_given_x, sigma_y_given_x)\n",
    "        \n",
    "        samples[i] = [x, y]\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# パラメータ設定\n",
    "mu = np.array([1.0, 2.0])\n",
    "cov = np.array([[2.0, 1.5], [1.5, 3.0]])\n",
    "\n",
    "print(f\"目標分布の平均: {mu}\")\n",
    "print(f\"目標分布の共分散:\\n{cov}\")\n",
    "print(f\"相関係数: {cov[0,1]/np.sqrt(cov[0,0]*cov[1,1]):.3f}\")\n",
    "\n",
    "# ギブスサンプリング実行\n",
    "samples_gibbs = gibbs_sampling_bivariate_normal(mu, cov, 10000)\n",
    "\n",
    "# 結果の統計\n",
    "burnin = 1000\n",
    "sample_mean = np.mean(samples_gibbs[burnin:], axis=0)\n",
    "sample_cov = np.cov(samples_gibbs[burnin:].T)\n",
    "\n",
    "print(f\"\\nサンプル平均: {sample_mean}\")\n",
    "print(f\"サンプル共分散:\\n{sample_cov}\")\n",
    "print(f\"サンプル相関係数: {sample_cov[0,1]/np.sqrt(sample_cov[0,0]*sample_cov[1,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ギブスサンプリング結果の可視化\n",
    "def plot_gibbs_results(samples, mu, cov, title=\"Gibbs Sampling Results\"):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    burnin = len(samples) // 10\n",
    "    samples_clean = samples[burnin:]\n",
    "    \n",
    "    # サンプルの軌跡（最初の500サンプル）\n",
    "    trajectory = samples[:500]\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b-', alpha=0.7, linewidth=0.8)\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b.', markersize=2, alpha=0.8)\n",
    "    axes[0, 0].plot(trajectory[0, 0], trajectory[0, 1], 'go', markersize=8, label='Start')\n",
    "    axes[0, 0].plot(trajectory[-1, 0], trajectory[-1, 1], 'ro', markersize=8, label='End')\n",
    "    axes[0, 0].set_title('Gibbs Sampling Trajectory (first 500)')\n",
    "    axes[0, 0].set_xlabel('X1')\n",
    "    axes[0, 0].set_ylabel('X2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 散布図と真の分布の等高線\n",
    "    axes[0, 1].scatter(samples_clean[::5, 0], samples_clean[::5, 1], alpha=0.6, s=1)\n",
    "    \n",
    "    # 真の分布の等高線\n",
    "    x1_range = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 50)\n",
    "    x2_range = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 50)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    pos = np.dstack((X1, X2))\n",
    "    rv = stats.multivariate_normal(mu, cov)\n",
    "    axes[0, 1].contour(X1, X2, rv.pdf(pos), colors='red', alpha=0.8, linewidths=2)\n",
    "    axes[0, 1].set_title('Samples with True Distribution')\n",
    "    axes[0, 1].set_xlabel('X1')\n",
    "    axes[0, 1].set_ylabel('X2')\n",
    "    axes[0, 1].set_aspect('equal')\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 2].plot(samples[:2000, 0], alpha=0.7, label='X1', linewidth=0.8)\n",
    "    axes[0, 2].plot(samples[:2000, 1], alpha=0.7, label='X2', linewidth=0.8)\n",
    "    axes[0, 2].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[0, 2].set_title('Trace Plot')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Value')\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # X1のマージナル分布\n",
    "    axes[1, 0].hist(samples_clean[:, 0], bins=50, density=True, alpha=0.7, \n",
    "                    color='lightblue', label='X1 samples')\n",
    "    x1_theory = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 100)\n",
    "    axes[1, 0].plot(x1_theory, stats.norm.pdf(x1_theory, mu[0], np.sqrt(cov[0, 0])), \n",
    "                    'r-', linewidth=2, label='X1 true')\n",
    "    axes[1, 0].set_title('Marginal Distribution X1')\n",
    "    axes[1, 0].set_xlabel('X1')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # X2のマージナル分布\n",
    "    axes[1, 1].hist(samples_clean[:, 1], bins=50, density=True, alpha=0.7, \n",
    "                    color='lightgreen', label='X2 samples')\n",
    "    x2_theory = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 100)\n",
    "    axes[1, 1].plot(x2_theory, stats.norm.pdf(x2_theory, mu[1], np.sqrt(cov[1, 1])), \n",
    "                    'r-', linewidth=2, label='X2 true')\n",
    "    axes[1, 1].set_title('Marginal Distribution X2')\n",
    "    axes[1, 1].set_xlabel('X2')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # 自己相関（X1について）\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    lags = min(100, len(samples_clean) // 10)\n",
    "    autocorr_x1 = acf(samples_clean[:, 0], nlags=lags, fft=True)\n",
    "    autocorr_x2 = acf(samples_clean[:, 1], nlags=lags, fft=True)\n",
    "    \n",
    "    axes[1, 2].plot(autocorr_x1, label='X1', alpha=0.8)\n",
    "    axes[1, 2].plot(autocorr_x2, label='X2', alpha=0.8)\n",
    "    axes[1, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(-0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].set_title('Autocorrelation Functions')\n",
    "    axes[1, 2].set_xlabel('Lag')\n",
    "    axes[1, 2].set_ylabel('ACF')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gibbs_results(samples_gibbs, mu, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 メトロポリス・ヘイスティングス法との比較\n",
    "\n",
    "同じ分布に対してメトロポリス・ヘイスティングス法も適用し、性能を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メトロポリス・ヘイスティングス法の実装（前章から）\n",
    "def multivariate_normal_log_pdf(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度\"\"\"\n",
    "    k = len(mu)\n",
    "    diff = x - mu\n",
    "    \n",
    "    try:\n",
    "        chol = np.linalg.cholesky(cov)\n",
    "        log_det = 2 * np.sum(np.log(np.diag(chol)))\n",
    "        solve = np.linalg.solve(chol, diff)\n",
    "        mahalanobis_sq = np.sum(solve**2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf\n",
    "    \n",
    "    return -0.5 * (k * np.log(2 * np.pi) + log_det + mahalanobis_sq)\n",
    "\n",
    "def mh_multivariate_normal(mu, cov, n_samples, step_size=0.5):\n",
    "    \"\"\"多変量正規分布からのMHサンプリング\"\"\"\n",
    "    samples = np.zeros((n_samples, len(mu)))\n",
    "    current = np.copy(mu)  # 平均から開始\n",
    "    current_log_prob = multivariate_normal_log_pdf(current, mu, cov)\n",
    "    n_accepted = 0\n",
    "    \n",
    "    cov_proposal = step_size * np.eye(len(mu))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 提案\n",
    "        proposed = np.random.multivariate_normal(current, cov_proposal)\n",
    "        proposed_log_prob = multivariate_normal_log_pdf(proposed, mu, cov)\n",
    "        \n",
    "        # 受理確率（対称提案なので簡単）\n",
    "        log_alpha = proposed_log_prob - current_log_prob\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却\n",
    "        if np.random.rand() < alpha:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        samples[i] = current\n",
    "    \n",
    "    return samples, n_accepted / n_samples\n",
    "\n",
    "# MHサンプリング実行\n",
    "print(\"メトロポリス・ヘイスティングス法でサンプリング中...\")\n",
    "samples_mh, acceptance_rate = mh_multivariate_normal(mu, cov, 10000, step_size=0.8)\n",
    "\n",
    "print(f\"MH法受理率: {acceptance_rate:.3f}\")\n",
    "\n",
    "# 統計の比較\n",
    "burnin = 1000\n",
    "\n",
    "# ギブス統計\n",
    "gibbs_mean = np.mean(samples_gibbs[burnin:], axis=0)\n",
    "gibbs_cov = np.cov(samples_gibbs[burnin:].T)\n",
    "\n",
    "# MH統計\n",
    "mh_mean = np.mean(samples_mh[burnin:], axis=0)\n",
    "mh_cov = np.cov(samples_mh[burnin:].T)\n",
    "\n",
    "print(f\"\\n=== 統計比較 ===\")\n",
    "print(f\"真の平均:     {mu}\")\n",
    "print(f\"ギブス平均:   {gibbs_mean}\")\n",
    "print(f\"MH平均:       {mh_mean}\")\n",
    "print(f\"\\n真の共分散:\")\n",
    "print(cov)\n",
    "print(f\"ギブス共分散:\")\n",
    "print(gibbs_cov)\n",
    "print(f\"MH共分散:\")\n",
    "print(mh_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 効率の比較\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def compute_efficiency_metrics(samples, burnin_frac=0.1):\n",
    "    \"\"\"効率指標の計算\"\"\"\n",
    "    burnin = int(len(samples) * burnin_frac)\n",
    "    clean_samples = samples[burnin:]\n",
    "    \n",
    "    # 各次元の自己相関時間を計算\n",
    "    autocorr_times = []\n",
    "    eff_sample_sizes = []\n",
    "    \n",
    "    for dim in range(clean_samples.shape[1]):\n",
    "        data = clean_samples[:, dim]\n",
    "        lags = min(200, len(data) // 4)\n",
    "        autocorr = acf(data, nlags=lags, fft=True)\n",
    "        \n",
    "        # 最初に閾値を下回るラグを見つける\n",
    "        tau_int = 1\n",
    "        for lag in range(1, len(autocorr)):\n",
    "            if autocorr[lag] < 0.05:\n",
    "                tau_int = lag\n",
    "                break\n",
    "        \n",
    "        autocorr_times.append(tau_int)\n",
    "        eff_sample_sizes.append(len(data) / (2 * tau_int + 1))\n",
    "    \n",
    "    return autocorr_times, eff_sample_sizes\n",
    "\n",
    "# 効率比較\n",
    "gibbs_autocorr, gibbs_eff = compute_efficiency_metrics(samples_gibbs)\n",
    "mh_autocorr, mh_eff = compute_efficiency_metrics(samples_mh)\n",
    "\n",
    "print(\"=== 効率比較 ===\")\n",
    "print(f\"{'Method':<10} {'Dim':<5} {'Autocorr Time':<15} {'Eff Sample Size':<18}\")\n",
    "print(\"-\" * 50)\n",
    "for dim in range(2):\n",
    "    print(f\"{'Gibbs':<10} {'X'+str(dim+1):<5} {gibbs_autocorr[dim]:<15d} {gibbs_eff[dim]:<18.1f}\")\n",
    "    print(f\"{'MH':<10} {'X'+str(dim+1):<5} {mh_autocorr[dim]:<15d} {mh_eff[dim]:<18.1f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"平均効率サンプルサイズ:\")\n",
    "print(f\"  ギブス: {np.mean(gibbs_eff):.1f}\")\n",
    "print(f\"  MH:     {np.mean(mh_eff):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 例2：混合正規分布の推定\n",
    "\n",
    "より実践的な例として、潜在変数を持つ混合正規分布のパラメータ推定をギブスサンプリングで行ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "def generate_mixture_data(n_samples, weights, means, variances):\n",
    "    \"\"\"\n",
    "    混合正規分布からデータを生成\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: サンプル数\n",
    "    - weights: 混合重み\n",
    "    - means: 各成分の平均\n",
    "    - variances: 各成分の分散\n",
    "    \"\"\"\n",
    "    n_components = len(weights)\n",
    "    \n",
    "    # 成分の割り当て\n",
    "    components = np.random.choice(n_components, size=n_samples, p=weights)\n",
    "    \n",
    "    # データ生成\n",
    "    data = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        comp = components[i]\n",
    "        data[i] = np.random.normal(means[comp], np.sqrt(variances[comp]))\n",
    "    \n",
    "    return data, components\n",
    "\n",
    "# 真のパラメータ\n",
    "true_weights = np.array([0.3, 0.7])\n",
    "true_means = np.array([-2.0, 2.0])\n",
    "true_variances = np.array([0.5, 1.0])\n",
    "\n",
    "# データ生成\n",
    "n_obs = 200\n",
    "data, true_components = generate_mixture_data(n_obs, true_weights, true_means, true_variances)\n",
    "\n",
    "print(f\"真のパラメータ:\")\n",
    "print(f\"  重み: {true_weights}\")\n",
    "print(f\"  平均: {true_means}\")\n",
    "print(f\"  分散: {true_variances}\")\n",
    "\n",
    "# データの可視化\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, density=True, alpha=0.7, color='lightblue')\n",
    "x_range = np.linspace(data.min(), data.max(), 1000)\n",
    "true_density = (true_weights[0] * stats.norm.pdf(x_range, true_means[0], np.sqrt(true_variances[0])) +\n",
    "                true_weights[1] * stats.norm.pdf(x_range, true_means[1], np.sqrt(true_variances[1])))\n",
    "plt.plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "plt.title('Generated Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = ['red', 'blue']\n",
    "for k in range(2):\n",
    "    mask = true_components == k\n",
    "    plt.hist(data[mask], bins=15, alpha=0.7, color=colors[k], \n",
    "             label=f'Component {k+1}', density=True)\n",
    "plt.title('Data by True Components')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_mixture_gaussian(data, n_components, n_iterations, \n",
    "                          prior_alpha=1.0, prior_mu_var=10.0, \n",
    "                          prior_sigma_shape=1.0, prior_sigma_scale=1.0):\n",
    "    \"\"\"\n",
    "    混合正規分布のギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - data: 観測データ\n",
    "    - n_components: 混合成分数\n",
    "    - n_iterations: イテレーション数\n",
    "    - prior_*: 事前分布のパラメータ\n",
    "    \"\"\"\n",
    "    n_obs = len(data)\n",
    "    \n",
    "    # パラメータ保存用配列\n",
    "    weights_samples = np.zeros((n_iterations, n_components))\n",
    "    means_samples = np.zeros((n_iterations, n_components))\n",
    "    variances_samples = np.zeros((n_iterations, n_components))\n",
    "    components_samples = np.zeros((n_iterations, n_obs), dtype=int)\n",
    "    \n",
    "    # 初期値\n",
    "    weights = np.ones(n_components) / n_components\n",
    "    means = np.random.normal(0, 2, n_components)\n",
    "    variances = np.ones(n_components)\n",
    "    components = np.random.choice(n_components, n_obs)\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        # 1. 潜在変数（成分割り当て）の更新\n",
    "        for i in range(n_obs):\n",
    "            # 各成分への所属確率を計算\n",
    "            log_probs = np.zeros(n_components)\n",
    "            for k in range(n_components):\n",
    "                log_probs[k] = (np.log(weights[k]) + \n",
    "                               stats.norm.logpdf(data[i], means[k], np.sqrt(variances[k])))\n",
    "            \n",
    "            # 安定な確率計算\n",
    "            log_probs -= logsumexp(log_probs)\n",
    "            probs = np.exp(log_probs)\n",
    "            \n",
    "            # サンプリング\n",
    "            components[i] = np.random.choice(n_components, p=probs)\n",
    "        \n",
    "        # 2. 混合重みの更新（ディリクレ分布から）\n",
    "        counts = np.bincount(components, minlength=n_components)\n",
    "        weights = np.random.dirichlet(prior_alpha + counts)\n",
    "        \n",
    "        # 3. 平均の更新（正規分布から）\n",
    "        for k in range(n_components):\n",
    "            mask = components == k\n",
    "            n_k = np.sum(mask)\n",
    "            \n",
    "            if n_k > 0:\n",
    "                data_k = data[mask]\n",
    "                sample_mean = np.mean(data_k)\n",
    "                \n",
    "                # 事後分布のパラメータ\n",
    "                posterior_var = 1 / (1/prior_mu_var + n_k/variances[k])\n",
    "                posterior_mean = posterior_var * (n_k * sample_mean / variances[k])\n",
    "                \n",
    "                means[k] = np.random.normal(posterior_mean, np.sqrt(posterior_var))\n",
    "            else:\n",
    "                # データが割り当てられていない場合は事前分布から\n",
    "                means[k] = np.random.normal(0, np.sqrt(prior_mu_var))\n",
    "        \n",
    "        # 4. 分散の更新（逆ガンマ分布から）\n",
    "        for k in range(n_components):\n",
    "            mask = components == k\n",
    "            n_k = np.sum(mask)\n",
    "            \n",
    "            if n_k > 0:\n",
    "                data_k = data[mask]\n",
    "                ss = np.sum((data_k - means[k])**2)\n",
    "                \n",
    "                # 事後分布のパラメータ\n",
    "                posterior_shape = prior_sigma_shape + n_k / 2\n",
    "                posterior_scale = prior_sigma_scale + ss / 2\n",
    "                \n",
    "                # 逆ガンマからサンプリング（ガンマの逆数）\n",
    "                variances[k] = 1 / np.random.gamma(posterior_shape, 1/posterior_scale)\n",
    "            else:\n",
    "                # データが割り当てられていない場合は事前分布から\n",
    "                variances[k] = 1 / np.random.gamma(prior_sigma_shape, 1/prior_sigma_scale)\n",
    "        \n",
    "        # サンプル保存\n",
    "        weights_samples[iteration] = weights\n",
    "        means_samples[iteration] = means\n",
    "        variances_samples[iteration] = variances\n",
    "        components_samples[iteration] = components\n",
    "        \n",
    "        if iteration % 200 == 0:\n",
    "            print(f\"Iteration {iteration}: weights={weights:.3f}, \"\n",
    "                  f\"means=[{means[0]:.2f}, {means[1]:.2f}], \"\n",
    "                  f\"vars=[{variances[0]:.2f}, {variances[1]:.2f}]\")\n",
    "    \n",
    "    return {\n",
    "        'weights': weights_samples,\n",
    "        'means': means_samples,\n",
    "        'variances': variances_samples,\n",
    "        'components': components_samples\n",
    "    }\n",
    "\n",
    "# ギブスサンプリング実行\n",
    "print(\"混合正規分布のパラメータ推定中...\")\n",
    "results = gibbs_mixture_gaussian(data, n_components=2, n_iterations=2000)\n",
    "\n",
    "# 結果の統計\n",
    "burnin = 500\n",
    "weights_post = results['weights'][burnin:]\n",
    "means_post = results['means'][burnin:]\n",
    "variances_post = results['variances'][burnin:]\n",
    "\n",
    "print(f\"\\n=== 推定結果 ===\")\n",
    "print(f\"重み:\")\n",
    "print(f\"  真値:   {true_weights}\")\n",
    "print(f\"  推定値: {np.mean(weights_post, axis=0)}\")\n",
    "print(f\"平均:\")\n",
    "print(f\"  真値:   {true_means}\")\n",
    "print(f\"  推定値: {np.mean(means_post, axis=0)}\")\n",
    "print(f\"分散:\")\n",
    "print(f\"  真値:   {true_variances}\")\n",
    "print(f\"  推定値: {np.mean(variances_post, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合モデル結果の可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# パラメータのトレースプロット\n",
    "iterations = np.arange(len(results['weights']))\n",
    "\n",
    "# 重み\n",
    "axes[0, 0].plot(iterations, results['weights'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 0].plot(iterations, results['weights'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 0].axhline(true_weights[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].axhline(true_weights[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 0].set_title('Mixture Weights')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Weight')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 平均\n",
    "axes[0, 1].plot(iterations, results['means'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 1].plot(iterations, results['means'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 1].axhline(true_means[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].axhline(true_means[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 1].set_title('Component Means')\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Mean')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 分散\n",
    "axes[0, 2].plot(iterations, results['variances'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 2].plot(iterations, results['variances'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 2].axhline(true_variances[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 2].axhline(true_variances[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 2].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 2].set_title('Component Variances')\n",
    "axes[0, 2].set_xlabel('Iteration')\n",
    "axes[0, 2].set_ylabel('Variance')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 事後分布のヒストグラム\n",
    "axes[1, 0].hist(weights_post[:, 0], bins=30, alpha=0.7, density=True, label='Component 1')\n",
    "axes[1, 0].hist(weights_post[:, 1], bins=30, alpha=0.7, density=True, label='Component 2')\n",
    "axes[1, 0].axvline(true_weights[0], color='red', linestyle='--', label='True values')\n",
    "axes[1, 0].axvline(true_weights[1], color='blue', linestyle='--')\n",
    "axes[1, 0].set_title('Posterior Distribution of Weights')\n",
    "axes[1, 0].set_xlabel('Weight')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].hist(means_post[:, 0], bins=30, alpha=0.7, density=True, label='Component 1')\n",
    "axes[1, 1].hist(means_post[:, 1], bins=30, alpha=0.7, density=True, label='Component 2')\n",
    "axes[1, 1].axvline(true_means[0], color='red', linestyle='--', label='True values')\n",
    "axes[1, 1].axvline(true_means[1], color='blue', linestyle='--')\n",
    "axes[1, 1].set_title('Posterior Distribution of Means')\n",
    "axes[1, 1].set_xlabel('Mean')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 推定分布 vs 真の分布\n",
    "x_range = np.linspace(data.min(), data.max(), 1000)\n",
    "\n",
    "# 事後平均を使った推定分布\n",
    "est_weights = np.mean(weights_post, axis=0)\n",
    "est_means = np.mean(means_post, axis=0)\n",
    "est_variances = np.mean(variances_post, axis=0)\n",
    "\n",
    "est_density = (est_weights[0] * stats.norm.pdf(x_range, est_means[0], np.sqrt(est_variances[0])) +\n",
    "               est_weights[1] * stats.norm.pdf(x_range, est_means[1], np.sqrt(est_variances[1])))\n",
    "\n",
    "true_density = (true_weights[0] * stats.norm.pdf(x_range, true_means[0], np.sqrt(true_variances[0])) +\n",
    "                true_weights[1] * stats.norm.pdf(x_range, true_means[1], np.sqrt(true_variances[1])))\n",
    "\n",
    "axes[1, 2].hist(data, bins=30, density=True, alpha=0.7, color='lightgray', label='Data')\n",
    "axes[1, 2].plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "axes[1, 2].plot(x_range, est_density, 'b--', linewidth=2, label='Estimated distribution')\n",
    "axes[1, 2].set_title('Distribution Comparison')\n",
    "axes[1, 2].set_xlabel('Value')\n",
    "axes[1, 2].set_ylabel('Density')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 ブロックギブスサンプリング\n",
    "\n",
    "変数を個別に更新する代わりに、変数のブロック（グループ）を同時に更新する手法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_gibbs_bivariate_normal(mu, cov, n_samples, block_prob=0.5):\n",
    "    \"\"\"\n",
    "    ブロックギブスサンプリング（2変量正規分布）\n",
    "    \n",
    "    Parameters:\n",
    "    - mu, cov: 分布パラメータ\n",
    "    - n_samples: サンプル数\n",
    "    - block_prob: ブロック更新を行う確率\n",
    "    \"\"\"\n",
    "    samples = np.zeros((n_samples, 2))\n",
    "    \n",
    "    # 条件付き分布のパラメータ（通常のギブスサンプリング用）\n",
    "    mu_x, mu_y = mu[0], mu[1]\n",
    "    var_x, var_y = cov[0, 0], cov[1, 1]\n",
    "    cov_xy = cov[0, 1]\n",
    "    rho = cov_xy / np.sqrt(var_x * var_y)\n",
    "    sigma_x_given_y = np.sqrt(var_x * (1 - rho**2))\n",
    "    sigma_y_given_x = np.sqrt(var_y * (1 - rho**2))\n",
    "    \n",
    "    # 初期値\n",
    "    x, y = mu_x, mu_y\n",
    "    \n",
    "    block_updates = 0\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        if np.random.rand() < block_prob:\n",
    "            # ブロック更新：両変数を同時に更新\n",
    "            new_sample = np.random.multivariate_normal(mu, cov)\n",
    "            x, y = new_sample[0], new_sample[1]\n",
    "            block_updates += 1\n",
    "        else:\n",
    "            # 通常のギブス更新\n",
    "            # x | y\n",
    "            mu_x_given_y = mu_x + rho * np.sqrt(var_x / var_y) * (y - mu_y)\n",
    "            x = np.random.normal(mu_x_given_y, sigma_x_given_y)\n",
    "            \n",
    "            # y | x\n",
    "            mu_y_given_x = mu_y + rho * np.sqrt(var_y / var_x) * (x - mu_x)\n",
    "            y = np.random.normal(mu_y_given_x, sigma_y_given_x)\n",
    "        \n",
    "        samples[i] = [x, y]\n",
    "    \n",
    "    print(f\"ブロック更新の割合: {block_updates / n_samples:.2%}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 高い相関を持つ分布でテスト\n",
    "high_corr_cov = np.array([[1.0, 0.95], [0.95, 1.0]])\n",
    "\n",
    "print(\"高相関分布での比較...\")\n",
    "print(f\"相関係数: {high_corr_cov[0,1]/np.sqrt(high_corr_cov[0,0]*high_corr_cov[1,1]):.3f}\")\n",
    "\n",
    "# 通常のギブス\n",
    "samples_gibbs_high = gibbs_sampling_bivariate_normal(mu, high_corr_cov, 5000)\n",
    "\n",
    "# ブロックギブス（50%の確率でブロック更新）\n",
    "samples_block_gibbs = block_gibbs_bivariate_normal(mu, high_corr_cov, 5000, block_prob=0.5)\n",
    "\n",
    "# 効率比較\n",
    "gibbs_high_autocorr, gibbs_high_eff = compute_efficiency_metrics(samples_gibbs_high)\n",
    "block_autocorr, block_eff = compute_efficiency_metrics(samples_block_gibbs)\n",
    "\n",
    "print(f\"\\n=== 高相関での効率比較 ===\")\n",
    "print(f\"{'Method':<15} {'Dim':<5} {'Autocorr Time':<15} {'Eff Sample Size':<18}\")\n",
    "print(\"-\" * 55)\n",
    "for dim in range(2):\n",
    "    print(f\"{'Regular Gibbs':<15} {'X'+str(dim+1):<5} {gibbs_high_autocorr[dim]:<15d} {gibbs_high_eff[dim]:<18.1f}\")\n",
    "    print(f\"{'Block Gibbs':<15} {'X'+str(dim+1):<5} {block_autocorr[dim]:<15d} {block_eff[dim]:<18.1f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"平均効率サンプルサイズ:\")\n",
    "print(f\"  通常ギブス:   {np.mean(gibbs_high_eff):.1f}\")\n",
    "print(f\"  ブロックギブス: {np.mean(block_eff):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 演習問題\n",
    "\n",
    "### 問題1：3変量正規分布のギブスサンプリング\n",
    "3変量正規分布に対してギブスサンプリングを実装しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1の解答欄\n",
    "def gibbs_sampling_trivariate_normal(mu, cov, n_samples):\n",
    "    \"\"\"\n",
    "    3変量正規分布からのギブスサンプリング\n",
    "    \n",
    "    ヒント：\n",
    "    3変量正規分布 N(μ, Σ) において、\n",
    "    X1 | X2, X3 ~ N(μ1 + Σ12 Σ22^-1 (X23 - μ23), Σ11 - Σ12 Σ22^-1 Σ21)\n",
    "    ここで X23 = [X2, X3]^T, μ23 = [μ2, μ3]^T\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テスト用パラメータ\n",
    "mu_3d = np.array([1.0, 2.0, 3.0])\n",
    "cov_3d = np.array([\n",
    "    [2.0, 0.8, 0.3],\n",
    "    [0.8, 1.5, 0.6],\n",
    "    [0.3, 0.6, 1.0]\n",
    "])\n",
    "\n",
    "# samples_3d = gibbs_sampling_trivariate_normal(mu_3d, cov_3d, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 問題2：ベイズ線形回帰の完全実装\n\n新しいドキュメントで詳しく解説されていたベイズ線形回帰を完全実装してみましょう。\n\n#### モデル設定\n- **尤度**: $y = X\\beta + \\epsilon$, $\\epsilon \\sim N(0, \\sigma^2 I)$\n- **回帰係数の事前分布**: $\\beta \\sim N(0, \\tau_0^{-1} I)$  \n- **精度の事前分布**: $\\tau = 1/\\sigma^2 \\sim \\text{Gamma}(\\alpha, \\beta)$\n\n#### 完全条件付き分布\nギブスサンプリングの核心は、各パラメータの完全条件付き事後分布を導出することです：\n\n1. **$p(\\beta|\\tau, y, X)$**: 多変量正規分布\n2. **$p(\\tau|\\beta, y, X)$**: ガンマ分布\n\nこれらの分布のパラメータは、データと他のパラメータの現在値から計算できます。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gibbs_bayesian_regression(X, y, n_iterations, \n                             prior_beta_precision=0.0001, \n                             prior_tau_shape=2.0, prior_tau_rate=1.0):\n    \"\"\"\n    線形回帰のベイズ推定（ギブスサンプリング）\n    \n    モデル: y = X β + ε, ε ~ N(0, τ^{-1})\n    事前分布: \n    - β ~ N(0, prior_beta_precision^{-1} * I)\n    - τ ~ Gamma(prior_tau_shape, prior_tau_rate)\n    \n    Parameters:\n    - X: 計画行列 (n × p)\n    - y: 観測値 (n × 1)\n    - n_iterations: 反復回数\n    - prior_*: 事前分布のパラメータ\n    \n    Returns:\n    - samples: {'beta': beta_samples, 'tau': tau_samples, 'sigma': sigma_samples}\n    \"\"\"\n    n, p = X.shape\n    \n    # サンプル保存用\n    beta_samples = np.zeros((n_iterations, p))\n    tau_samples = np.zeros(n_iterations)\n    sigma_samples = np.zeros(n_iterations)\n    \n    # 初期値\n    beta_current = np.zeros(p)\n    tau_current = 1.0\n    \n    # 事前計算（計算効率のため）\n    XtX = X.T @ X\n    Xty = X.T @ y\n    \n    for i in range(n_iterations):\n        # 1. β | τ, y の更新（多変量正規分布から）\n        # 事後精度行列と平均\n        posterior_precision = prior_beta_precision * np.eye(p) + tau_current * XtX\n        try:\n            posterior_cov = np.linalg.inv(posterior_precision)\n            posterior_mean = posterior_cov @ (tau_current * Xty)\n            \n            # サンプリング\n            beta_current = np.random.multivariate_normal(posterior_mean, posterior_cov)\n        except np.linalg.LinAlgError:\n            # 数値的に不安定な場合はCholeskyを使用\n            try:\n                L = np.linalg.cholesky(posterior_precision)\n                z = np.random.randn(p)\n                v = np.linalg.solve(L, tau_current * Xty)\n                w = np.linalg.solve(L, z)\n                beta_current = np.linalg.solve(L.T, v) + np.linalg.solve(L.T, w)\n            except:\n                # それでも失敗した場合は前の値を保持\n                pass\n        \n        # 2. τ | β, y の更新（ガンマ分布から）\n        # 残差の計算\n        residuals = y - X @ beta_current\n        sum_squared_residuals = np.sum(residuals**2)\n        \n        # 事後パラメータ\n        posterior_shape = prior_tau_shape + n / 2.0\n        posterior_rate = prior_tau_rate + sum_squared_residuals / 2.0\n        \n        # サンプリング\n        tau_current = np.random.gamma(posterior_shape, 1.0 / posterior_rate)\n        \n        # 結果の保存\n        beta_samples[i] = beta_current\n        tau_samples[i] = tau_current\n        sigma_samples[i] = 1.0 / np.sqrt(tau_current)\n        \n        if i > 0 and i % 500 == 0:\n            print(f\"Iteration {i}: β̂ = {beta_current[:3]}, σ̂ = {1/np.sqrt(tau_current):.3f}\")\n    \n    return {\n        'beta': beta_samples,\n        'tau': tau_samples,\n        'sigma': sigma_samples\n    }\n\n# 合成データの生成\nnp.random.seed(42)\nn_obs = 100\nn_predictors = 3\n\n# 設計行列（切片項を含む）\nX_reg = np.column_stack([\n    np.ones(n_obs),  # 切片\n    np.random.randn(n_obs),  # 予測子1\n    np.random.randn(n_obs)   # 予測子2\n])\n\n# 真のパラメータ\ntrue_beta = np.array([2.5, 1.8, -1.2])  # [切片, 傾き1, 傾き2]\ntrue_sigma = 1.5\n\n# 観測値の生成\ny_reg = X_reg @ true_beta + np.random.normal(0, true_sigma, n_obs)\n\nprint(f\"=== データ生成 ===\")\nprint(f\"サンプル数: {n_obs}\")\nprint(f\"真の回帰係数: {true_beta}\")\nprint(f\"真の誤差標準偏差: {true_sigma}\")\n\n# ギブスサンプリング実行\nprint(f\"\\n=== ギブスサンプリング実行 ===\")\nresults_reg = gibbs_bayesian_regression(X_reg, y_reg, 5000)\n\n# 結果の分析\nburnin = 1000\nbeta_post = results_reg['beta'][burnin:]\nsigma_post = results_reg['sigma'][burnin:]\n\nprint(f\"\\n=== 推定結果 ===\")\nprint(f\"事後平均（回帰係数）:\")\nfor i, (true_val, est_val) in enumerate(zip(true_beta, np.mean(beta_post, axis=0))):\n    param_name = \"切片\" if i == 0 else f\"傾き{i}\"\n    print(f\"  {param_name:>4}: 真値={true_val:6.2f}, 推定値={est_val:6.2f}\")\n\nprint(f\"\\n誤差標準偏差:\")\nprint(f\"  真値={true_sigma:6.2f}, 推定値={np.mean(sigma_post):6.2f}\")\n\n# 信頼区間\nprint(f\"\\n=== 95%信頼区間 ===\")\nfor i, true_val in enumerate(true_beta):\n    param_name = \"切片\" if i == 0 else f\"傾き{i}\"\n    ci_lower = np.percentile(beta_post[:, i], 2.5)\n    ci_upper = np.percentile(beta_post[:, i], 97.5)\n    in_ci = ci_lower <= true_val <= ci_upper\n    print(f\"  {param_name:>4}: [{ci_lower:6.2f}, {ci_upper:6.2f}] {'✓' if in_ci else '✗'}\")\n\nsigma_ci_lower = np.percentile(sigma_post, 2.5)\nsigma_ci_upper = np.percentile(sigma_post, 97.5)\nsigma_in_ci = sigma_ci_lower <= true_sigma <= sigma_ci_upper\nprint(f\"  {'σ':>4}: [{sigma_ci_lower:6.2f}, {sigma_ci_upper:6.2f}] {'✓' if sigma_in_ci else '✗'}\")"
  },
  {
   "cell_type": "code",
   "source": "# ベイズ線形回帰結果の可視化\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# トレースプロット\nparam_names = ['切片', '傾き1', '傾き2']\nfor i in range(3):\n    axes[0, i].plot(results_reg['beta'][:, i], alpha=0.8, linewidth=0.8)\n    axes[0, i].axhline(true_beta[i], color='red', linestyle='--', linewidth=2, \n                       label=f'真値 = {true_beta[i]:.2f}')\n    axes[0, i].axvline(burnin, color='gray', linestyle=':', alpha=0.7, label='Burn-in')\n    axes[0, i].set_title(f'{param_names[i]}のトレースプロット')\n    axes[0, i].set_xlabel('Iteration')\n    axes[0, i].set_ylabel(f'{param_names[i]}')\n    axes[0, i].legend()\n    axes[0, i].grid(True, alpha=0.3)\n\n# 事後分布のヒストグラム\nfor i in range(3):\n    axes[1, i].hist(beta_post[:, i], bins=50, density=True, alpha=0.7, \n                    color=f'C{i}', label=f'{param_names[i]} 事後分布')\n    axes[1, i].axvline(true_beta[i], color='red', linestyle='--', linewidth=2,\n                       label=f'真値 = {true_beta[i]:.2f}')\n    axes[1, i].axvline(np.mean(beta_post[:, i]), color='blue', linestyle='-', linewidth=2,\n                       label=f'事後平均 = {np.mean(beta_post[:, i]):.2f}')\n    axes[1, i].set_title(f'{param_names[i]}の事後分布')\n    axes[1, i].set_xlabel(f'{param_names[i]}')\n    axes[1, i].set_ylabel('密度')\n    axes[1, i].legend()\n    axes[1, i].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 予測と残差の分析\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 観測値 vs 予測値\ny_pred_mean = X_reg @ np.mean(beta_post, axis=0)\naxes[0].scatter(y_reg, y_pred_mean, alpha=0.7)\nmin_val = min(y_reg.min(), y_pred_mean.min())\nmax_val = max(y_reg.max(), y_pred_mean.max())\naxes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='y=x')\naxes[0].set_xlabel('観測値')\naxes[0].set_ylabel('予測値（事後平均）')\naxes[0].set_title('観測値 vs 予測値')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# 残差プロット\nresiduals_mean = y_reg - y_pred_mean\naxes[1].scatter(y_pred_mean, residuals_mean, alpha=0.7)\naxes[1].axhline(0, color='red', linestyle='--', linewidth=2)\naxes[1].set_xlabel('予測値')\naxes[1].set_ylabel('残差')\naxes[1].set_title('残差プロット')\naxes[1].grid(True, alpha=0.3)\n\n# σの事後分布\naxes[2].hist(sigma_post, bins=50, density=True, alpha=0.7, color='orange')\naxes[2].axvline(true_sigma, color='red', linestyle='--', linewidth=2,\n                label=f'真値 = {true_sigma:.2f}')\naxes[2].axvline(np.mean(sigma_post), color='blue', linestyle='-', linewidth=2,\n                label=f'事後平均 = {np.mean(sigma_post):.2f}')\naxes[2].set_title('σの事後分布')\naxes[2].set_xlabel('σ')\naxes[2].set_ylabel('密度')\naxes[2].legend()\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 予測区間の可視化（1次元の場合の例）\nif X_reg.shape[1] == 3:  # 切片 + 2つの予測子の場合\n    # 第1予測子を固定して第2予測子との関係を可視化\n    x1_fixed = 0  # 第1予測子を0に固定\n    x2_range = np.linspace(-3, 3, 50)\n    X_pred = np.column_stack([np.ones(len(x2_range)), \n                             np.full(len(x2_range), x1_fixed), \n                             x2_range])\n    \n    # 事後サンプルから予測分布を計算\n    n_pred_samples = 100\n    pred_samples = np.zeros((n_pred_samples, len(x2_range)))\n    \n    for i in range(n_pred_samples):\n        idx = np.random.randint(len(beta_post))\n        beta_sample = beta_post[idx]\n        sigma_sample = sigma_post[idx]\n        \n        mean_pred = X_pred @ beta_sample\n        pred_samples[i] = np.random.normal(mean_pred, sigma_sample)\n    \n    # 予測区間の計算\n    pred_mean = np.mean(pred_samples, axis=0)\n    pred_lower = np.percentile(pred_samples, 2.5, axis=0)\n    pred_upper = np.percentile(pred_samples, 97.5, axis=0)\n    \n    plt.figure(figsize=(10, 6))\n    plt.fill_between(x2_range, pred_lower, pred_upper, alpha=0.3, color='lightblue', \n                     label='95%予測区間')\n    plt.plot(x2_range, pred_mean, 'b-', linewidth=2, label='予測平均')\n    \n    # データ点をプロット（第1予測子が0に近いもの）\n    mask = np.abs(X_reg[:, 1] - x1_fixed) < 0.5\n    if np.any(mask):\n        plt.scatter(X_reg[mask, 2], y_reg[mask], color='red', alpha=0.7, \n                   label='観測データ', s=50)\n    \n    plt.xlabel('予測子2')\n    plt.ylabel('応答変数')\n    plt.title(f'予測区間（予測子1 = {x1_fixed}で固定）')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## まとめ：ギブスサンプリング完全理解\n\nこの章では、ギブスサンプリングについて包括的に学習しました：\n\n### 🧠 核心的理解\n\n1. **基本原理**：複雑な同時分布を条件付き分布の連鎖に分解\n2. **数学的美しさ**：「受理率100%」の驚異的効率性\n3. **MH法との関係**：詳細釣り合い条件を満たす特殊なMH法\n\n### 🔧 実践的スキル\n\n4. **実装技術**：\n   - 多変量正規分布での解析的導出\n   - 混合モデルでの潜在変数の扱い\n   - ブロックギブスによる効率化\n   - ベイズ線形回帰での完全な事後分布推定\n\n### 📊 重要な応用パターン\n\n5. **適用場面**：\n   - **多変量正規分布**: 解析解が利用できる理想的ケース\n   - **混合モデル**: 潜在変数と観測変数の交互更新\n   - **階層ベイズモデル**: パラメータ層の効率的サンプリング\n   - **回帰分析**: 共役事前分布による高速推定\n\n## 🎯 実践的MCMCアルゴリズム選択ガイド\n\n### 決定フローチャート\n\n```\n問題設定\n    ↓\nすべての完全条件付き分布が既知？\n    ↓           ↓\n   Yes         No\n    ↓           ↓\nギブスサンプリング   変数間の相関は？\n    ↓           ↓        ↓\n性能は満足？    高い      低い\n    ↓           ↓        ↓\n   Yes   ブロックギブス   MH法\n    ↓           ↓        ↓\n  完了      効果あり？    ハイブリッド\n              ↓        検討\n             Yes\n              ↓\n            完了\n```\n\n### 📋 アルゴリズム選択マトリックス\n\n| 状況 | 推奨手法 | 理由 | 注意点 |\n|------|----------|------|--------|\n| **すべて共役** | ギブス | 受理率100% | 高相関時は要注意 |\n| **一部非共役** | ハイブリッド | 効率とロバスト性 | 実装複雑度up |\n| **高次元・高相関** | ブロックギブス | 相関構造を考慮 | ブロック設計が重要 |\n| **複雑尤度** | MH法 | 汎用性が高い | チューニング必要 |\n| **階層構造** | ギブス | 自然な分解可能 | レベル間の設計 |\n| **混合モデル** | ギブス | 潜在変数が自然 | ラベルスイッチング |\n\n### 🚀 性能最適化の戦略\n\n#### Phase 1: 基本実装\n1. **純粋ギブス**: 条件付き分布がすべて既知なら最初に試す\n2. **診断**: 収束と混合の確認\n3. **問題特定**: ボトルネックの発見\n\n#### Phase 2: 高度化\n1. **ブロック化**: 相関のある変数をグループ化\n2. **適応的更新**: パフォーマンスに応じた動的調整\n3. **並列化**: 独立な部分の同時処理\n\n#### Phase 3: ハイブリッド\n1. **部分MH**: 困難な変数のみMH法に\n2. **階層最適化**: レベル別の手法選択\n3. **動的切り替え**: 条件に応じた手法変更\n\n### ⚡ 効率性のベンチマーク指標\n\n| 指標 | 計算式 | 目標値 | \n|------|--------|--------|\n| **有効サンプルサイズ** | N / (2τ + 1) | > 400 |\n| **混合効率** | ESS / 計算時間 | 問題依存 |\n| **収束速度** | R-hat < 1.01 達成時間 | 早いほど良い |\n\n### 🎨 実装品質のチェックリスト\n\n#### 数値安定性\n- [ ] 対数スケール計算で数値オーバーフロー回避\n- [ ] 条件付き分散の正定値性確保\n- [ ] 例外処理とフォールバック機構\n\n#### コード品質\n- [ ] モジュラー設計：各更新ステップの独立化\n- [ ] パフォーマンス監視：実行時診断機能\n- [ ] 拡張性：新しい変数の容易な追加\n\n#### 診断機能\n- [ ] リアルタイム収束監視\n- [ ] 自動ボトルネック検出\n- [ ] 詳細なログ出力\n\n### 🔮 Advanced Topics\n\n#### 最新の発展\n- **適応的ブロッキング**: データ駆動的ブロック決定\n- **幾何学的エルゴード性**: 理論的収束保証\n- **GPU並列化**: 大規模データでの高速化\n\n#### 研究フロンティア\n- **変分ギブス**: 近似推論との融合\n- **量子アニーリング**: 量子計算との組み合わせ\n- **オンライン学習**: ストリーミングデータへの適用\n\n### 💡 成功の秘訣\n\n> **「適切な分解が効率の9割を決める」** - 問題の数学的構造を理解し、最も自然な変数分割を見つけることがギブスサンプリング成功の鍵です。\n\n**記憶すべき原則:**\n- 🎯 **共役性の活用**: 解析解が得られる部分は積極的に利用\n- 🔗 **相関の理解**: 変数間の依存構造を把握してブロック設計\n- ⚖️ **バランス重視**: 効率性とロバスト性のトレードオフ\n- 🔄 **反復改善**: 初期実装から段階的な最適化\n\n### 🌐 実世界での応用例\n\n**🔬 科学研究:**\n- 遺伝子発現データの階層モデル\n- 気候変動の空間時間モデル\n- 疫学データの多レベル分析\n\n**💼 ビジネス:**\n- 顧客セグメンテーション\n- 需要予測の階層モデル\n- A/Bテストの多変量解析\n\n**🤖 機械学習:**\n- トピックモデル（LDA）\n- ベイジアンニューラルネット\n- 推薦システムの協調フィルタリング\n\nあなたは今、**ギブスサンプリングの真の力**を理解し、実際の問題に応用できる準備が整いました。次の章で学ぶ収束診断と組み合わせることで、信頼性の高いベイズ推論システムを構築できるでしょう！\n\n### 🎓 Next Challenge\n\n複雑な実問題（例：多変量時系列、空間統計、生存解析）にギブスサンプリングを適用し、**効率性と精度の両立**を実現してみてください。これが、真の専門性の証明となります。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}