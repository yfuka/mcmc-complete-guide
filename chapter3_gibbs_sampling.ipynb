{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: ギブスサンプリング\n",
    "\n",
    "## 学習目標\n",
    "- ギブスサンプリングの基本原理を理解する\n",
    "- 条件付き分布の導出方法を学ぶ\n",
    "- 多変量正規分布での実装を習得する\n",
    "- 混合モデルや階層モデルへの応用を理解する\n",
    "- ブロックギブスサンプリングの概念を学ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 ギブスサンプリングの基本原理\n",
    "\n",
    "ギブスサンプリングは、多変量分布 $p(x_1, x_2, ..., x_k)$ から各変数を条件付き分布に基づいて順番に更新する手法です。\n",
    "\n",
    "### アルゴリズム（k変数の場合）\n",
    "1. 初期値 $(x_1^{(0)}, x_2^{(0)}, ..., x_k^{(0)})$ を設定\n",
    "2. 各イテレーション $t$ で以下を実行：\n",
    "   - $x_1^{(t+1)} \\sim p(x_1 | x_2^{(t)}, x_3^{(t)}, ..., x_k^{(t)})$\n",
    "   - $x_2^{(t+1)} \\sim p(x_2 | x_1^{(t+1)}, x_3^{(t)}, ..., x_k^{(t)})$\n",
    "   - $\\vdots$\n",
    "   - $x_k^{(t+1)} \\sim p(x_k | x_1^{(t+1)}, x_2^{(t+1)}, ..., x_{k-1}^{(t+1)})$\n",
    "\n",
    "### 重要な性質\n",
    "- **受理率100%**：条件付き分布から直接サンプリング\n",
    "- **自動的な詳細釣り合い**：条件付き分布の性質により満たされる\n",
    "- **計算効率**：複雑な受理確率計算が不要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 例1：2変量正規分布からのサンプリング\n",
    "\n",
    "まず、解析的に条件付き分布を導出できる2変量正規分布でギブスサンプリングを実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling_bivariate_normal(mu, cov, n_samples, initial_value=None):\n",
    "    \"\"\"\n",
    "    2変量正規分布からのギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - mu: 平均ベクトル [mu_x, mu_y]\n",
    "    - cov: 共分散行列 [[var_x, cov_xy], [cov_xy, var_y]]\n",
    "    - n_samples: サンプル数\n",
    "    - initial_value: 初期値 [x0, y0]\n",
    "    \n",
    "    Returns:\n",
    "    - samples: shape (n_samples, 2) のサンプル配列\n",
    "    \"\"\"\n",
    "    samples = np.zeros((n_samples, 2))\n",
    "    \n",
    "    # 条件付き分布のパラメータを事前計算\n",
    "    mu_x, mu_y = mu[0], mu[1]\n",
    "    var_x, var_y = cov[0, 0], cov[1, 1]\n",
    "    cov_xy = cov[0, 1]\n",
    "    \n",
    "    # 相関係数\n",
    "    rho = cov_xy / np.sqrt(var_x * var_y)\n",
    "    \n",
    "    # 条件付き分布の標準偏差\n",
    "    sigma_x_given_y = np.sqrt(var_x * (1 - rho**2))\n",
    "    sigma_y_given_x = np.sqrt(var_y * (1 - rho**2))\n",
    "    \n",
    "    # 初期値の設定\n",
    "    if initial_value is None:\n",
    "        x, y = mu_x, mu_y\n",
    "    else:\n",
    "        x, y = initial_value[0], initial_value[1]\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # x | y からサンプリング\n",
    "        # p(x|y) ~ N(mu_x + rho*(sigma_x/sigma_y)*(y - mu_y), sigma_x^2*(1-rho^2))\n",
    "        mu_x_given_y = mu_x + rho * np.sqrt(var_x / var_y) * (y - mu_y)\n",
    "        x = np.random.normal(mu_x_given_y, sigma_x_given_y)\n",
    "        \n",
    "        # y | x からサンプリング\n",
    "        # p(y|x) ~ N(mu_y + rho*(sigma_y/sigma_x)*(x - mu_x), sigma_y^2*(1-rho^2))\n",
    "        mu_y_given_x = mu_y + rho * np.sqrt(var_y / var_x) * (x - mu_x)\n",
    "        y = np.random.normal(mu_y_given_x, sigma_y_given_x)\n",
    "        \n",
    "        samples[i] = [x, y]\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# パラメータ設定\n",
    "mu = np.array([1.0, 2.0])\n",
    "cov = np.array([[2.0, 1.5], [1.5, 3.0]])\n",
    "\n",
    "print(f\"目標分布の平均: {mu}\")\n",
    "print(f\"目標分布の共分散:\\n{cov}\")\n",
    "print(f\"相関係数: {cov[0,1]/np.sqrt(cov[0,0]*cov[1,1]):.3f}\")\n",
    "\n",
    "# ギブスサンプリング実行\n",
    "samples_gibbs = gibbs_sampling_bivariate_normal(mu, cov, 10000)\n",
    "\n",
    "# 結果の統計\n",
    "burnin = 1000\n",
    "sample_mean = np.mean(samples_gibbs[burnin:], axis=0)\n",
    "sample_cov = np.cov(samples_gibbs[burnin:].T)\n",
    "\n",
    "print(f\"\\nサンプル平均: {sample_mean}\")\n",
    "print(f\"サンプル共分散:\\n{sample_cov}\")\n",
    "print(f\"サンプル相関係数: {sample_cov[0,1]/np.sqrt(sample_cov[0,0]*sample_cov[1,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ギブスサンプリング結果の可視化\n",
    "def plot_gibbs_results(samples, mu, cov, title=\"Gibbs Sampling Results\"):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    burnin = len(samples) // 10\n",
    "    samples_clean = samples[burnin:]\n",
    "    \n",
    "    # サンプルの軌跡（最初の500サンプル）\n",
    "    trajectory = samples[:500]\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b-', alpha=0.7, linewidth=0.8)\n",
    "    axes[0, 0].plot(trajectory[:, 0], trajectory[:, 1], 'b.', markersize=2, alpha=0.8)\n",
    "    axes[0, 0].plot(trajectory[0, 0], trajectory[0, 1], 'go', markersize=8, label='Start')\n",
    "    axes[0, 0].plot(trajectory[-1, 0], trajectory[-1, 1], 'ro', markersize=8, label='End')\n",
    "    axes[0, 0].set_title('Gibbs Sampling Trajectory (first 500)')\n",
    "    axes[0, 0].set_xlabel('X1')\n",
    "    axes[0, 0].set_ylabel('X2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 散布図と真の分布の等高線\n",
    "    axes[0, 1].scatter(samples_clean[::5, 0], samples_clean[::5, 1], alpha=0.6, s=1)\n",
    "    \n",
    "    # 真の分布の等高線\n",
    "    x1_range = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 50)\n",
    "    x2_range = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 50)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    pos = np.dstack((X1, X2))\n",
    "    rv = stats.multivariate_normal(mu, cov)\n",
    "    axes[0, 1].contour(X1, X2, rv.pdf(pos), colors='red', alpha=0.8, linewidths=2)\n",
    "    axes[0, 1].set_title('Samples with True Distribution')\n",
    "    axes[0, 1].set_xlabel('X1')\n",
    "    axes[0, 1].set_ylabel('X2')\n",
    "    axes[0, 1].set_aspect('equal')\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 2].plot(samples[:2000, 0], alpha=0.7, label='X1', linewidth=0.8)\n",
    "    axes[0, 2].plot(samples[:2000, 1], alpha=0.7, label='X2', linewidth=0.8)\n",
    "    axes[0, 2].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[0, 2].set_title('Trace Plot')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Value')\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # X1のマージナル分布\n",
    "    axes[1, 0].hist(samples_clean[:, 0], bins=50, density=True, alpha=0.7, \n",
    "                    color='lightblue', label='X1 samples')\n",
    "    x1_theory = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 100)\n",
    "    axes[1, 0].plot(x1_theory, stats.norm.pdf(x1_theory, mu[0], np.sqrt(cov[0, 0])), \n",
    "                    'r-', linewidth=2, label='X1 true')\n",
    "    axes[1, 0].set_title('Marginal Distribution X1')\n",
    "    axes[1, 0].set_xlabel('X1')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # X2のマージナル分布\n",
    "    axes[1, 1].hist(samples_clean[:, 1], bins=50, density=True, alpha=0.7, \n",
    "                    color='lightgreen', label='X2 samples')\n",
    "    x2_theory = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 100)\n",
    "    axes[1, 1].plot(x2_theory, stats.norm.pdf(x2_theory, mu[1], np.sqrt(cov[1, 1])), \n",
    "                    'r-', linewidth=2, label='X2 true')\n",
    "    axes[1, 1].set_title('Marginal Distribution X2')\n",
    "    axes[1, 1].set_xlabel('X2')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # 自己相関（X1について）\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    lags = min(100, len(samples_clean) // 10)\n",
    "    autocorr_x1 = acf(samples_clean[:, 0], nlags=lags, fft=True)\n",
    "    autocorr_x2 = acf(samples_clean[:, 1], nlags=lags, fft=True)\n",
    "    \n",
    "    axes[1, 2].plot(autocorr_x1, label='X1', alpha=0.8)\n",
    "    axes[1, 2].plot(autocorr_x2, label='X2', alpha=0.8)\n",
    "    axes[1, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].axhline(-0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 2].set_title('Autocorrelation Functions')\n",
    "    axes[1, 2].set_xlabel('Lag')\n",
    "    axes[1, 2].set_ylabel('ACF')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gibbs_results(samples_gibbs, mu, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 メトロポリス・ヘイスティングス法との比較\n",
    "\n",
    "同じ分布に対してメトロポリス・ヘイスティングス法も適用し、性能を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メトロポリス・ヘイスティングス法の実装（前章から）\n",
    "def multivariate_normal_log_pdf(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度\"\"\"\n",
    "    k = len(mu)\n",
    "    diff = x - mu\n",
    "    \n",
    "    try:\n",
    "        chol = np.linalg.cholesky(cov)\n",
    "        log_det = 2 * np.sum(np.log(np.diag(chol)))\n",
    "        solve = np.linalg.solve(chol, diff)\n",
    "        mahalanobis_sq = np.sum(solve**2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf\n",
    "    \n",
    "    return -0.5 * (k * np.log(2 * np.pi) + log_det + mahalanobis_sq)\n",
    "\n",
    "def mh_multivariate_normal(mu, cov, n_samples, step_size=0.5):\n",
    "    \"\"\"多変量正規分布からのMHサンプリング\"\"\"\n",
    "    samples = np.zeros((n_samples, len(mu)))\n",
    "    current = np.copy(mu)  # 平均から開始\n",
    "    current_log_prob = multivariate_normal_log_pdf(current, mu, cov)\n",
    "    n_accepted = 0\n",
    "    \n",
    "    cov_proposal = step_size * np.eye(len(mu))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 提案\n",
    "        proposed = np.random.multivariate_normal(current, cov_proposal)\n",
    "        proposed_log_prob = multivariate_normal_log_pdf(proposed, mu, cov)\n",
    "        \n",
    "        # 受理確率（対称提案なので簡単）\n",
    "        log_alpha = proposed_log_prob - current_log_prob\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却\n",
    "        if np.random.rand() < alpha:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        samples[i] = current\n",
    "    \n",
    "    return samples, n_accepted / n_samples\n",
    "\n",
    "# MHサンプリング実行\n",
    "print(\"メトロポリス・ヘイスティングス法でサンプリング中...\")\n",
    "samples_mh, acceptance_rate = mh_multivariate_normal(mu, cov, 10000, step_size=0.8)\n",
    "\n",
    "print(f\"MH法受理率: {acceptance_rate:.3f}\")\n",
    "\n",
    "# 統計の比較\n",
    "burnin = 1000\n",
    "\n",
    "# ギブス統計\n",
    "gibbs_mean = np.mean(samples_gibbs[burnin:], axis=0)\n",
    "gibbs_cov = np.cov(samples_gibbs[burnin:].T)\n",
    "\n",
    "# MH統計\n",
    "mh_mean = np.mean(samples_mh[burnin:], axis=0)\n",
    "mh_cov = np.cov(samples_mh[burnin:].T)\n",
    "\n",
    "print(f\"\\n=== 統計比較 ===\")\n",
    "print(f\"真の平均:     {mu}\")\n",
    "print(f\"ギブス平均:   {gibbs_mean}\")\n",
    "print(f\"MH平均:       {mh_mean}\")\n",
    "print(f\"\\n真の共分散:\")\n",
    "print(cov)\n",
    "print(f\"ギブス共分散:\")\n",
    "print(gibbs_cov)\n",
    "print(f\"MH共分散:\")\n",
    "print(mh_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 効率の比較\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def compute_efficiency_metrics(samples, burnin_frac=0.1):\n",
    "    \"\"\"効率指標の計算\"\"\"\n",
    "    burnin = int(len(samples) * burnin_frac)\n",
    "    clean_samples = samples[burnin:]\n",
    "    \n",
    "    # 各次元の自己相関時間を計算\n",
    "    autocorr_times = []\n",
    "    eff_sample_sizes = []\n",
    "    \n",
    "    for dim in range(clean_samples.shape[1]):\n",
    "        data = clean_samples[:, dim]\n",
    "        lags = min(200, len(data) // 4)\n",
    "        autocorr = acf(data, nlags=lags, fft=True)\n",
    "        \n",
    "        # 最初に閾値を下回るラグを見つける\n",
    "        tau_int = 1\n",
    "        for lag in range(1, len(autocorr)):\n",
    "            if autocorr[lag] < 0.05:\n",
    "                tau_int = lag\n",
    "                break\n",
    "        \n",
    "        autocorr_times.append(tau_int)\n",
    "        eff_sample_sizes.append(len(data) / (2 * tau_int + 1))\n",
    "    \n",
    "    return autocorr_times, eff_sample_sizes\n",
    "\n",
    "# 効率比較\n",
    "gibbs_autocorr, gibbs_eff = compute_efficiency_metrics(samples_gibbs)\n",
    "mh_autocorr, mh_eff = compute_efficiency_metrics(samples_mh)\n",
    "\n",
    "print(\"=== 効率比較 ===\")\n",
    "print(f\"{'Method':<10} {'Dim':<5} {'Autocorr Time':<15} {'Eff Sample Size':<18}\")\n",
    "print(\"-\" * 50)\n",
    "for dim in range(2):\n",
    "    print(f\"{'Gibbs':<10} {'X'+str(dim+1):<5} {gibbs_autocorr[dim]:<15d} {gibbs_eff[dim]:<18.1f}\")\n",
    "    print(f\"{'MH':<10} {'X'+str(dim+1):<5} {mh_autocorr[dim]:<15d} {mh_eff[dim]:<18.1f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"平均効率サンプルサイズ:\")\n",
    "print(f\"  ギブス: {np.mean(gibbs_eff):.1f}\")\n",
    "print(f\"  MH:     {np.mean(mh_eff):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 例2：混合正規分布の推定\n",
    "\n",
    "より実践的な例として、潜在変数を持つ混合正規分布のパラメータ推定をギブスサンプリングで行ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "def generate_mixture_data(n_samples, weights, means, variances):\n",
    "    \"\"\"\n",
    "    混合正規分布からデータを生成\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: サンプル数\n",
    "    - weights: 混合重み\n",
    "    - means: 各成分の平均\n",
    "    - variances: 各成分の分散\n",
    "    \"\"\"\n",
    "    n_components = len(weights)\n",
    "    \n",
    "    # 成分の割り当て\n",
    "    components = np.random.choice(n_components, size=n_samples, p=weights)\n",
    "    \n",
    "    # データ生成\n",
    "    data = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        comp = components[i]\n",
    "        data[i] = np.random.normal(means[comp], np.sqrt(variances[comp]))\n",
    "    \n",
    "    return data, components\n",
    "\n",
    "# 真のパラメータ\n",
    "true_weights = np.array([0.3, 0.7])\n",
    "true_means = np.array([-2.0, 2.0])\n",
    "true_variances = np.array([0.5, 1.0])\n",
    "\n",
    "# データ生成\n",
    "n_obs = 200\n",
    "data, true_components = generate_mixture_data(n_obs, true_weights, true_means, true_variances)\n",
    "\n",
    "print(f\"真のパラメータ:\")\n",
    "print(f\"  重み: {true_weights}\")\n",
    "print(f\"  平均: {true_means}\")\n",
    "print(f\"  分散: {true_variances}\")\n",
    "\n",
    "# データの可視化\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=30, density=True, alpha=0.7, color='lightblue')\n",
    "x_range = np.linspace(data.min(), data.max(), 1000)\n",
    "true_density = (true_weights[0] * stats.norm.pdf(x_range, true_means[0], np.sqrt(true_variances[0])) +\n",
    "                true_weights[1] * stats.norm.pdf(x_range, true_means[1], np.sqrt(true_variances[1])))\n",
    "plt.plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "plt.title('Generated Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = ['red', 'blue']\n",
    "for k in range(2):\n",
    "    mask = true_components == k\n",
    "    plt.hist(data[mask], bins=15, alpha=0.7, color=colors[k], \n",
    "             label=f'Component {k+1}', density=True)\n",
    "plt.title('Data by True Components')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_mixture_gaussian(data, n_components, n_iterations, \n",
    "                          prior_alpha=1.0, prior_mu_var=10.0, \n",
    "                          prior_sigma_shape=1.0, prior_sigma_scale=1.0):\n",
    "    \"\"\"\n",
    "    混合正規分布のギブスサンプリング\n",
    "    \n",
    "    Parameters:\n",
    "    - data: 観測データ\n",
    "    - n_components: 混合成分数\n",
    "    - n_iterations: イテレーション数\n",
    "    - prior_*: 事前分布のパラメータ\n",
    "    \"\"\"\n",
    "    n_obs = len(data)\n",
    "    \n",
    "    # パラメータ保存用配列\n",
    "    weights_samples = np.zeros((n_iterations, n_components))\n",
    "    means_samples = np.zeros((n_iterations, n_components))\n",
    "    variances_samples = np.zeros((n_iterations, n_components))\n",
    "    components_samples = np.zeros((n_iterations, n_obs), dtype=int)\n",
    "    \n",
    "    # 初期値\n",
    "    weights = np.ones(n_components) / n_components\n",
    "    means = np.random.normal(0, 2, n_components)\n",
    "    variances = np.ones(n_components)\n",
    "    components = np.random.choice(n_components, n_obs)\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        # 1. 潜在変数（成分割り当て）の更新\n",
    "        for i in range(n_obs):\n",
    "            # 各成分への所属確率を計算\n",
    "            log_probs = np.zeros(n_components)\n",
    "            for k in range(n_components):\n",
    "                log_probs[k] = (np.log(weights[k]) + \n",
    "                               stats.norm.logpdf(data[i], means[k], np.sqrt(variances[k])))\n",
    "            \n",
    "            # 安定な確率計算\n",
    "            log_probs -= logsumexp(log_probs)\n",
    "            probs = np.exp(log_probs)\n",
    "            \n",
    "            # サンプリング\n",
    "            components[i] = np.random.choice(n_components, p=probs)\n",
    "        \n",
    "        # 2. 混合重みの更新（ディリクレ分布から）\n",
    "        counts = np.bincount(components, minlength=n_components)\n",
    "        weights = np.random.dirichlet(prior_alpha + counts)\n",
    "        \n",
    "        # 3. 平均の更新（正規分布から）\n",
    "        for k in range(n_components):\n",
    "            mask = components == k\n",
    "            n_k = np.sum(mask)\n",
    "            \n",
    "            if n_k > 0:\n",
    "                data_k = data[mask]\n",
    "                sample_mean = np.mean(data_k)\n",
    "                \n",
    "                # 事後分布のパラメータ\n",
    "                posterior_var = 1 / (1/prior_mu_var + n_k/variances[k])\n",
    "                posterior_mean = posterior_var * (n_k * sample_mean / variances[k])\n",
    "                \n",
    "                means[k] = np.random.normal(posterior_mean, np.sqrt(posterior_var))\n",
    "            else:\n",
    "                # データが割り当てられていない場合は事前分布から\n",
    "                means[k] = np.random.normal(0, np.sqrt(prior_mu_var))\n",
    "        \n",
    "        # 4. 分散の更新（逆ガンマ分布から）\n",
    "        for k in range(n_components):\n",
    "            mask = components == k\n",
    "            n_k = np.sum(mask)\n",
    "            \n",
    "            if n_k > 0:\n",
    "                data_k = data[mask]\n",
    "                ss = np.sum((data_k - means[k])**2)\n",
    "                \n",
    "                # 事後分布のパラメータ\n",
    "                posterior_shape = prior_sigma_shape + n_k / 2\n",
    "                posterior_scale = prior_sigma_scale + ss / 2\n",
    "                \n",
    "                # 逆ガンマからサンプリング（ガンマの逆数）\n",
    "                variances[k] = 1 / np.random.gamma(posterior_shape, 1/posterior_scale)\n",
    "            else:\n",
    "                # データが割り当てられていない場合は事前分布から\n",
    "                variances[k] = 1 / np.random.gamma(prior_sigma_shape, 1/prior_sigma_scale)\n",
    "        \n",
    "        # サンプル保存\n",
    "        weights_samples[iteration] = weights\n",
    "        means_samples[iteration] = means\n",
    "        variances_samples[iteration] = variances\n",
    "        components_samples[iteration] = components\n",
    "        \n",
    "        if iteration % 200 == 0:\n",
    "            print(f\"Iteration {iteration}: weights={weights:.3f}, \"\n",
    "                  f\"means=[{means[0]:.2f}, {means[1]:.2f}], \"\n",
    "                  f\"vars=[{variances[0]:.2f}, {variances[1]:.2f}]\")\n",
    "    \n",
    "    return {\n",
    "        'weights': weights_samples,\n",
    "        'means': means_samples,\n",
    "        'variances': variances_samples,\n",
    "        'components': components_samples\n",
    "    }\n",
    "\n",
    "# ギブスサンプリング実行\n",
    "print(\"混合正規分布のパラメータ推定中...\")\n",
    "results = gibbs_mixture_gaussian(data, n_components=2, n_iterations=2000)\n",
    "\n",
    "# 結果の統計\n",
    "burnin = 500\n",
    "weights_post = results['weights'][burnin:]\n",
    "means_post = results['means'][burnin:]\n",
    "variances_post = results['variances'][burnin:]\n",
    "\n",
    "print(f\"\\n=== 推定結果 ===\")\n",
    "print(f\"重み:\")\n",
    "print(f\"  真値:   {true_weights}\")\n",
    "print(f\"  推定値: {np.mean(weights_post, axis=0)}\")\n",
    "print(f\"平均:\")\n",
    "print(f\"  真値:   {true_means}\")\n",
    "print(f\"  推定値: {np.mean(means_post, axis=0)}\")\n",
    "print(f\"分散:\")\n",
    "print(f\"  真値:   {true_variances}\")\n",
    "print(f\"  推定値: {np.mean(variances_post, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合モデル結果の可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# パラメータのトレースプロット\n",
    "iterations = np.arange(len(results['weights']))\n",
    "\n",
    "# 重み\n",
    "axes[0, 0].plot(iterations, results['weights'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 0].plot(iterations, results['weights'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 0].axhline(true_weights[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].axhline(true_weights[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 0].set_title('Mixture Weights')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Weight')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 平均\n",
    "axes[0, 1].plot(iterations, results['means'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 1].plot(iterations, results['means'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 1].axhline(true_means[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].axhline(true_means[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 1].set_title('Component Means')\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Mean')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 分散\n",
    "axes[0, 2].plot(iterations, results['variances'][:, 0], alpha=0.8, label='Component 1')\n",
    "axes[0, 2].plot(iterations, results['variances'][:, 1], alpha=0.8, label='Component 2')\n",
    "axes[0, 2].axhline(true_variances[0], color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 2].axhline(true_variances[1], color='blue', linestyle='--', alpha=0.7)\n",
    "axes[0, 2].axvline(burnin, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[0, 2].set_title('Component Variances')\n",
    "axes[0, 2].set_xlabel('Iteration')\n",
    "axes[0, 2].set_ylabel('Variance')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 事後分布のヒストグラム\n",
    "axes[1, 0].hist(weights_post[:, 0], bins=30, alpha=0.7, density=True, label='Component 1')\n",
    "axes[1, 0].hist(weights_post[:, 1], bins=30, alpha=0.7, density=True, label='Component 2')\n",
    "axes[1, 0].axvline(true_weights[0], color='red', linestyle='--', label='True values')\n",
    "axes[1, 0].axvline(true_weights[1], color='blue', linestyle='--')\n",
    "axes[1, 0].set_title('Posterior Distribution of Weights')\n",
    "axes[1, 0].set_xlabel('Weight')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].hist(means_post[:, 0], bins=30, alpha=0.7, density=True, label='Component 1')\n",
    "axes[1, 1].hist(means_post[:, 1], bins=30, alpha=0.7, density=True, label='Component 2')\n",
    "axes[1, 1].axvline(true_means[0], color='red', linestyle='--', label='True values')\n",
    "axes[1, 1].axvline(true_means[1], color='blue', linestyle='--')\n",
    "axes[1, 1].set_title('Posterior Distribution of Means')\n",
    "axes[1, 1].set_xlabel('Mean')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 推定分布 vs 真の分布\n",
    "x_range = np.linspace(data.min(), data.max(), 1000)\n",
    "\n",
    "# 事後平均を使った推定分布\n",
    "est_weights = np.mean(weights_post, axis=0)\n",
    "est_means = np.mean(means_post, axis=0)\n",
    "est_variances = np.mean(variances_post, axis=0)\n",
    "\n",
    "est_density = (est_weights[0] * stats.norm.pdf(x_range, est_means[0], np.sqrt(est_variances[0])) +\n",
    "               est_weights[1] * stats.norm.pdf(x_range, est_means[1], np.sqrt(est_variances[1])))\n",
    "\n",
    "true_density = (true_weights[0] * stats.norm.pdf(x_range, true_means[0], np.sqrt(true_variances[0])) +\n",
    "                true_weights[1] * stats.norm.pdf(x_range, true_means[1], np.sqrt(true_variances[1])))\n",
    "\n",
    "axes[1, 2].hist(data, bins=30, density=True, alpha=0.7, color='lightgray', label='Data')\n",
    "axes[1, 2].plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "axes[1, 2].plot(x_range, est_density, 'b--', linewidth=2, label='Estimated distribution')\n",
    "axes[1, 2].set_title('Distribution Comparison')\n",
    "axes[1, 2].set_xlabel('Value')\n",
    "axes[1, 2].set_ylabel('Density')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 ブロックギブスサンプリング\n",
    "\n",
    "変数を個別に更新する代わりに、変数のブロック（グループ）を同時に更新する手法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_gibbs_bivariate_normal(mu, cov, n_samples, block_prob=0.5):\n",
    "    \"\"\"\n",
    "    ブロックギブスサンプリング（2変量正規分布）\n",
    "    \n",
    "    Parameters:\n",
    "    - mu, cov: 分布パラメータ\n",
    "    - n_samples: サンプル数\n",
    "    - block_prob: ブロック更新を行う確率\n",
    "    \"\"\"\n",
    "    samples = np.zeros((n_samples, 2))\n",
    "    \n",
    "    # 条件付き分布のパラメータ（通常のギブスサンプリング用）\n",
    "    mu_x, mu_y = mu[0], mu[1]\n",
    "    var_x, var_y = cov[0, 0], cov[1, 1]\n",
    "    cov_xy = cov[0, 1]\n",
    "    rho = cov_xy / np.sqrt(var_x * var_y)\n",
    "    sigma_x_given_y = np.sqrt(var_x * (1 - rho**2))\n",
    "    sigma_y_given_x = np.sqrt(var_y * (1 - rho**2))\n",
    "    \n",
    "    # 初期値\n",
    "    x, y = mu_x, mu_y\n",
    "    \n",
    "    block_updates = 0\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        if np.random.rand() < block_prob:\n",
    "            # ブロック更新：両変数を同時に更新\n",
    "            new_sample = np.random.multivariate_normal(mu, cov)\n",
    "            x, y = new_sample[0], new_sample[1]\n",
    "            block_updates += 1\n",
    "        else:\n",
    "            # 通常のギブス更新\n",
    "            # x | y\n",
    "            mu_x_given_y = mu_x + rho * np.sqrt(var_x / var_y) * (y - mu_y)\n",
    "            x = np.random.normal(mu_x_given_y, sigma_x_given_y)\n",
    "            \n",
    "            # y | x\n",
    "            mu_y_given_x = mu_y + rho * np.sqrt(var_y / var_x) * (x - mu_x)\n",
    "            y = np.random.normal(mu_y_given_x, sigma_y_given_x)\n",
    "        \n",
    "        samples[i] = [x, y]\n",
    "    \n",
    "    print(f\"ブロック更新の割合: {block_updates / n_samples:.2%}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 高い相関を持つ分布でテスト\n",
    "high_corr_cov = np.array([[1.0, 0.95], [0.95, 1.0]])\n",
    "\n",
    "print(\"高相関分布での比較...\")\n",
    "print(f\"相関係数: {high_corr_cov[0,1]/np.sqrt(high_corr_cov[0,0]*high_corr_cov[1,1]):.3f}\")\n",
    "\n",
    "# 通常のギブス\n",
    "samples_gibbs_high = gibbs_sampling_bivariate_normal(mu, high_corr_cov, 5000)\n",
    "\n",
    "# ブロックギブス（50%の確率でブロック更新）\n",
    "samples_block_gibbs = block_gibbs_bivariate_normal(mu, high_corr_cov, 5000, block_prob=0.5)\n",
    "\n",
    "# 効率比較\n",
    "gibbs_high_autocorr, gibbs_high_eff = compute_efficiency_metrics(samples_gibbs_high)\n",
    "block_autocorr, block_eff = compute_efficiency_metrics(samples_block_gibbs)\n",
    "\n",
    "print(f\"\\n=== 高相関での効率比較 ===\")\n",
    "print(f\"{'Method':<15} {'Dim':<5} {'Autocorr Time':<15} {'Eff Sample Size':<18}\")\n",
    "print(\"-\" * 55)\n",
    "for dim in range(2):\n",
    "    print(f\"{'Regular Gibbs':<15} {'X'+str(dim+1):<5} {gibbs_high_autocorr[dim]:<15d} {gibbs_high_eff[dim]:<18.1f}\")\n",
    "    print(f\"{'Block Gibbs':<15} {'X'+str(dim+1):<5} {block_autocorr[dim]:<15d} {block_eff[dim]:<18.1f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"平均効率サンプルサイズ:\")\n",
    "print(f\"  通常ギブス:   {np.mean(gibbs_high_eff):.1f}\")\n",
    "print(f\"  ブロックギブス: {np.mean(block_eff):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 演習問題\n",
    "\n",
    "### 問題1：3変量正規分布のギブスサンプリング\n",
    "3変量正規分布に対してギブスサンプリングを実装しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1の解答欄\n",
    "def gibbs_sampling_trivariate_normal(mu, cov, n_samples):\n",
    "    \"\"\"\n",
    "    3変量正規分布からのギブスサンプリング\n",
    "    \n",
    "    ヒント：\n",
    "    3変量正規分布 N(μ, Σ) において、\n",
    "    X1 | X2, X3 ~ N(μ1 + Σ12 Σ22^-1 (X23 - μ23), Σ11 - Σ12 Σ22^-1 Σ21)\n",
    "    ここで X23 = [X2, X3]^T, μ23 = [μ2, μ3]^T\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テスト用パラメータ\n",
    "mu_3d = np.array([1.0, 2.0, 3.0])\n",
    "cov_3d = np.array([\n",
    "    [2.0, 0.8, 0.3],\n",
    "    [0.8, 1.5, 0.6],\n",
    "    [0.3, 0.6, 1.0]\n",
    "])\n",
    "\n",
    "# samples_3d = gibbs_sampling_trivariate_normal(mu_3d, cov_3d, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2：線形回帰のベイズ推定\n",
    "ギブスサンプリングを用いて線形回帰のベイズ推定を実装しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2の解答欄\n",
    "def gibbs_bayesian_regression(X, y, n_iterations, \n",
    "                             prior_beta_var=10.0, \n",
    "                             prior_sigma_shape=1.0, prior_sigma_rate=1.0):\n",
    "    \"\"\"\n",
    "    線形回帰のベイズ推定\n",
    "    \n",
    "    モデル: y = X β + ε, ε ~ N(0, σ²)\n",
    "    事前分布: β ~ N(0, prior_beta_var * I), σ² ~ InvGamma(shape, rate)\n",
    "    \n",
    "    ヒント：\n",
    "    - β | σ², y ~ N(posterior_mean, posterior_cov)\n",
    "    - σ² | β, y ~ InvGamma(posterior_shape, posterior_rate)\n",
    "    \"\"\"\n",
    "    # ここに実装してください\n",
    "    pass  # 学習者が実装\n",
    "\n",
    "# テストデータ生成\n",
    "np.random.seed(42)\n",
    "n_obs = 100\n",
    "X_reg = np.column_stack([np.ones(n_obs), np.random.randn(n_obs, 2)])\n",
    "true_beta = np.array([1.0, 2.0, -1.5])\n",
    "y_reg = X_reg @ true_beta + np.random.normal(0, 0.8, n_obs)\n",
    "\n",
    "print(f\"真の回帰係数: {true_beta}\")\n",
    "print(f\"真の誤差分散: 0.64\")\n",
    "\n",
    "# results_reg = gibbs_bayesian_regression(X_reg, y_reg, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "この章では、ギブスサンプリングについて以下を学習しました：\n",
    "\n",
    "1. **基本原理**：条件付き分布からの順次サンプリング\n",
    "2. **利点**：\n",
    "   - 受理率100%\n",
    "   - 自動的な詳細釣り合い\n",
    "   - 計算効率の良さ\n",
    "3. **実装例**：\n",
    "   - 多変量正規分布\n",
    "   - 混合モデルのパラメータ推定\n",
    "4. **応用技術**：\n",
    "   - ブロックギブスサンプリング\n",
    "   - 潜在変数モデル\n",
    "\n",
    "### 重要なポイント\n",
    "- **条件付き分布の導出**：解析的に求められることが前提\n",
    "- **高相関時の問題**：変数間の相関が高いと収束が遅い\n",
    "- **ブロック更新**：相関問題の解決策の一つ\n",
    "- **潜在変数**：観測されない変数も自然に扱える\n",
    "\n",
    "### メトロポリス・ヘイスティングス法との使い分け\n",
    "- **ギブス**：条件付き分布が既知で簡単にサンプリングできる場合\n",
    "- **MH**：条件付き分布が複雑で直接サンプリングが困難な場合\n",
    "- **混合**：部分的にギブス、部分的にMHを使うハイブリッド手法も有効\n",
    "\n",
    "次の章では、これらのMCMC手法の収束を診断し、性能を評価する方法を学習します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}