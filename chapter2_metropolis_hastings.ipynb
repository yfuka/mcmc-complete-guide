{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Chapter 2: メトロポリス・ヘイスティングス法 - 直感的理解から実装まで\n\n## 学習目標\n- メトロポリス・ヘイスティングス法の**革新的アイデア**を直感的に理解する\n- 受理確率の導出と**数学的美しさ**を体感する\n- 提案分布の選択と**探索効率**への影響を定量的に評価できる\n- 実装と性能評価方法を習得し、**実践的診断スキル**を身につける\n- 様々な分布からのサンプリング例を通じて**汎用性**を体験する\n\n## 🚀 なぜMH法は革命的なのか？\n\n### 従来の数値積分との決定的違い\n\n**従来の数値積分**:\n- 格子点を規則的に配置してf(x)を評価\n- 次元が増えると格子点数が指数的に増加（次元の呪い）\n- 10次元で各軸100点→10^20 格子点（現実的に不可能）\n\n**MH法の革新**:\n- **適応的サンプリング**: 重要な領域により多くの点を配置\n- **確率的探索**: ランダムウォークによる効率的な空間探索\n- **詳細釣り合い条件**: 目標分布に確実に収束する理論保証\n\n### 「賢いランダムウォーク」としての直感\n\nMH法は、**確率地形図**を見ながら歩く賢いハイカーです：\n\n- 🏔️ **高い確率の領域**（山頂）: 積極的に向かう\n- 🏜️ **低い確率の領域**（谷）: 時々訪れるが短時間\n- 🎯 **バランス**: 各領域の滞在時間 ∝ その領域の確率\n\nこのバランスを実現するのが**受理確率α**の巧妙な設計です。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.1 メトロポリス・ヘイスティングス法：MCMCの最も基本的で汎用的なアルゴリズム\n\nメトロポリス・ヘイスティングス法（MH法）は、MCMCの中でも最も基本的かつ汎用性の高いアルゴリズムです。詳細釣り合い条件という強力な設計指針を具体的なアルゴリズムとして実装した、真に革命的な手法です。\n\n### MH法の核心的アイデア\n\nMH法が画期的である理由は、その巧妙な設計にあります：\n\n1. **正規化定数の相殺**: 目標分布の比率を使うことで、計算困難な正規化定数が相殺される\n2. **詳細釣り合いの充足**: 採択/棄却メカニズムが詳細釣り合い条件を自動的に満たす\n3. **汎用性**: 目標分布の密度関数（正規化不要）が計算できれば適用可能\n\n### アルゴリズムの流れ\n\n1. **初期化**: パラメータの初期値 $x^{(t)}$ を設定\n2. **提案**: 提案分布 $q(x'|x^{(t)})$ から次の状態候補 $x'$ をサンプリング\n3. **受理確率の計算**:\n   $$\\alpha = \\min\\left(1, \\frac{p(x')q(x^{(t)}|x')}{p(x^{(t)})q(x'|x^{(t)})}\\right)$$\n4. **採択/棄却**: 確率 $\\alpha$ で提案を採択、そうでなければ現在の状態に留まる\n5. **繰り返し**: ステップ2に戻る\n\n### 「賢いランダムウォーク」としての直感\n\nMH法は、目標分布という「地形図」を常に見ながら歩く、賢いランダムウォークと見なせます：\n- **確率の高い場所**（標高の高い場所）へは積極的に移動（高い採択確率）\n- **確率の低い場所**（標高の低い場所）へはためらいながら移動（低い採択確率）\n\nこの「賢さ」を実装しているのが採択確率 $\\alpha$ です。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.2 MH法の最も巧妙な点：正規化定数の相殺\n\n### ベイズ推論における問題の再確認\n\nベイズ推論で困っていたのは、事後分布の正規化定数が計算できないことでした：\n\n$$p(\\theta|X) = \\frac{p(X|\\theta)p(\\theta)}{p(X)} = \\frac{1}{C} \\cdot f(\\theta)$$\n\nここで：\n- $f(\\theta) = p(X|\\theta)p(\\theta)$（計算可能）\n- $C = p(X) = \\int p(X|\\theta)p(\\theta)d\\theta$（計算困難）\n\n### MH法による見事な解決\n\nMH法の採択確率を見てみましょう：\n\n$$\\alpha = \\min\\left(1, \\frac{p(\\theta')q(\\theta^{(t)}|\\theta')}{p(\\theta^{(t)})q(\\theta'|\\theta^{(t)})}\\right)$$\n\n比率 $\\frac{p(\\theta')}{p(\\theta^{(t)})}$ を計算すると：\n\n$$\\frac{p(\\theta')}{p(\\theta^{(t)})} = \\frac{\\frac{1}{C} \\cdot f(\\theta')}{\\frac{1}{C} \\cdot f(\\theta^{(t)})} = \\frac{f(\\theta')}{f(\\theta^{(t)})}$$\n\n**未知の正規化定数 $C$ が分子と分母で見事に相殺されます！**\n\n### これが意味すること\n\n1. **事後分布の正確な式を知らなくても**サンプリングを進められる\n2. **計算困難な積分を回避**できる\n3. **比例関係** $p(\\theta) \\propto f(\\theta)$ だけ分かれば十分\n\nこれが、MH法が「積分の壁」を回避できる最大の理由です。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 基本実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(target_log_pdf, proposal_sampler, proposal_log_pdf, \n",
    "                       initial_value, n_samples, verbose=False):\n",
    "    \"\"\"\n",
    "    メトロポリス・ヘイスティングス法の汎用実装\n",
    "    \n",
    "    Parameters:\n",
    "    - target_log_pdf: 目標分布の対数確率密度関数\n",
    "    - proposal_sampler: 提案分布からのサンプラー関数 (current_state) -> proposed_state\n",
    "    - proposal_log_pdf: 提案分布の対数確率密度関数 (proposed, current) -> log_q\n",
    "    - initial_value: 初期値\n",
    "    - n_samples: サンプル数\n",
    "    - verbose: 詳細情報の表示\n",
    "    \n",
    "    Returns:\n",
    "    - samples: サンプル配列\n",
    "    - acceptance_rate: 受理率\n",
    "    - log_probs: 各サンプルの対数確率\n",
    "    \"\"\"\n",
    "    # 初期化\n",
    "    if np.isscalar(initial_value):\n",
    "        samples = np.zeros(n_samples)\n",
    "        dim = 1\n",
    "    else:\n",
    "        samples = np.zeros((n_samples, len(initial_value)))\n",
    "        dim = len(initial_value)\n",
    "    \n",
    "    current = np.copy(initial_value)\n",
    "    current_log_prob = target_log_pdf(current)\n",
    "    n_accepted = 0\n",
    "    log_probs = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 新しい状態を提案\n",
    "        proposed = proposal_sampler(current)\n",
    "        proposed_log_prob = target_log_pdf(proposed)\n",
    "        \n",
    "        # 受理確率を計算（対数スケールで安全に計算）\n",
    "        log_alpha = (proposed_log_prob + proposal_log_pdf(current, proposed) - \n",
    "                    current_log_prob - proposal_log_pdf(proposed, current))\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却を決定\n",
    "        if np.random.rand() < alpha:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        if dim == 1:\n",
    "            samples[i] = current\n",
    "        else:\n",
    "            samples[i] = current\n",
    "        log_probs[i] = current_log_prob\n",
    "        \n",
    "        if verbose and (i + 1) % (n_samples // 10) == 0:\n",
    "            print(f\"Progress: {i+1}/{n_samples}, Acceptance Rate: {n_accepted/(i+1):.3f}\")\n",
    "    \n",
    "    acceptance_rate = n_accepted / n_samples\n",
    "    return samples, acceptance_rate, log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 例1：混合正規分布からのサンプリング\n",
    "\n",
    "まず、1次元の混合正規分布からサンプリングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合正規分布の定義\n",
    "def mixture_log_pdf(x):\n",
    "    \"\"\"2つの正規分布の混合の対数確率密度\"\"\"\n",
    "    component1 = stats.norm.logpdf(x, -2, 0.5)\n",
    "    component2 = stats.norm.logpdf(x, 2, 1.0)\n",
    "    # log(0.3 * exp(component1) + 0.7 * exp(component2))\n",
    "    max_comp = np.maximum(component1, component2)\n",
    "    return max_comp + np.log(0.3 * np.exp(component1 - max_comp) + \n",
    "                            0.7 * np.exp(component2 - max_comp))\n",
    "\n",
    "# 対称な提案分布（ランダムウォーク）\n",
    "def random_walk_sampler(current, step_size=0.5):\n",
    "    return current + np.random.normal(0, step_size)\n",
    "\n",
    "def symmetric_proposal_log_pdf(proposed, current):\n",
    "    return 0.0  # 対称な提案分布の場合、比は1（対数で0）\n",
    "\n",
    "# サンプリング実行\n",
    "samples, acceptance_rate, log_probs = metropolis_hastings(\n",
    "    target_log_pdf=mixture_log_pdf,\n",
    "    proposal_sampler=lambda x: random_walk_sampler(x, 0.8),\n",
    "    proposal_log_pdf=symmetric_proposal_log_pdf,\n",
    "    initial_value=0.0,\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n最終受理率: {acceptance_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の可視化\n",
    "def plot_mcmc_results_1d(samples, target_log_pdf, burnin=1000, title=\"MCMC Results\"):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 0].plot(samples[:2000], alpha=0.7, linewidth=0.8)\n",
    "    axes[0, 0].set_title('Trace Plot (first 2000 samples)')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Value')\n",
    "    axes[0, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # ヒストグラムと真の分布の比較\n",
    "    axes[0, 1].hist(samples[burnin:], bins=60, density=True, alpha=0.7, \n",
    "                    color='skyblue', label='MCMC samples')\n",
    "    x_range = np.linspace(samples.min(), samples.max(), 1000)\n",
    "    true_density = np.exp(target_log_pdf(x_range))\n",
    "    axes[0, 1].plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "    axes[0, 1].set_title('Sample Distribution vs True Distribution')\n",
    "    axes[0, 1].set_xlabel('Value')\n",
    "    axes[0, 1].set_ylabel('Density')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 自己相関関数\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    lags = min(200, len(samples[burnin:]) // 10)\n",
    "    autocorr = acf(samples[burnin:], nlags=lags, fft=True)\n",
    "    axes[0, 2].plot(autocorr)\n",
    "    axes[0, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].axhline(0.05, color='r', linestyle='--', alpha=0.5, label='5%')\n",
    "    axes[0, 2].axhline(-0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].set_title('Autocorrelation Function')\n",
    "    axes[0, 2].set_xlabel('Lag')\n",
    "    axes[0, 2].set_ylabel('ACF')\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # 累積平均\n",
    "    cumulative_mean = np.cumsum(samples[burnin:]) / np.arange(1, len(samples[burnin:]) + 1)\n",
    "    axes[1, 0].plot(cumulative_mean)\n",
    "    true_mean = np.sum([0.3 * (-2), 0.7 * 2])  # 混合分布の理論平均\n",
    "    axes[1, 0].axhline(true_mean, color='r', linestyle='--', label=f'True mean = {true_mean:.2f}')\n",
    "    axes[1, 0].set_title('Cumulative Mean')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Mean')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 受理率の推移\n",
    "    window_size = len(samples) // 100\n",
    "    running_acceptance = []\n",
    "    for i in range(window_size, len(samples), window_size):\n",
    "        # 簡易的な受理率計算（連続する値の変化で判定）\n",
    "        window_samples = samples[i-window_size:i]\n",
    "        changes = np.sum(np.diff(window_samples) != 0)\n",
    "        running_acceptance.append(changes / window_size)\n",
    "    \n",
    "    axes[1, 1].plot(running_acceptance)\n",
    "    axes[1, 1].axhline(acceptance_rate, color='r', linestyle='--', \n",
    "                       label=f'Overall: {acceptance_rate:.3f}')\n",
    "    axes[1, 1].set_title('Running Acceptance Rate')\n",
    "    axes[1, 1].set_xlabel('Window')\n",
    "    axes[1, 1].set_ylabel('Acceptance Rate')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # QQプロット（理論分布との比較は困難なので、正規性のテスト）\n",
    "    from scipy.stats import probplot\n",
    "    probplot(samples[burnin:], dist=\"norm\", plot=axes[1, 2])\n",
    "    axes[1, 2].set_title('Q-Q Plot (vs Normal)')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mcmc_results_1d(samples, mixture_log_pdf, title=\"Mixture Gaussian Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.4 提案分布の選択：「歩幅」の科学\n\n提案分布 $q(x'|x^{(t)})$ は、MCMCウォーカーの「歩幅」を決定します。この歩幅の適切なチューニングが、探索効率を劇的に左右する極めて重要な要素です。\n\n### 🚶‍♂️ 歩幅のアナロジー：街歩きからの洞察\n\nimagine you're exploring an unknown city to find popular areas:\n\n**🐌 歩幅が小さすぎる（慎重すぎるウォーカー）:**\n- 一歩ずつ慎重に進む → どこに行っても「まあ、いいか」と受け入れる\n- ✅ 採択率は高い（ほぼ100%近く）\n- ❌ 同じブロックをちまちまと歩き回るだけ\n- ❌ 街全体の人気エリアを把握できない（非効率な探索）\n\n**🏃‍♂️ 歩幅が大きすぎる（冒険的すぎるウォーカー）:**\n- 大きくジャンプしてみる → でも殆どの場所が「微妙...」で元に戻る\n- ❌ 採択率が極端に低い（10%以下）\n- ❌ ほぼ同じ場所に留まり続ける\n- ❌ 新しい場所を受け入れてもらえない（探索停滞）\n\n**🎯 歩幅が適切（賢いウォーカー）:**\n- 程よいステップで着実に探索 → 良い場所は受け入れ、悪い場所は時々スキップ\n- ✅ 適度な採択率（理論最適値：1D→44%, 高次元→23%）\n- ✅ 街全体を効率よく探索\n- ✅ 人気エリアには長く滞在、そうでない場所もバランスよく訪問\n\n### 📊 採択率と探索効率の関係\n\n```\n採択率 100% → 移動距離が極小 → 探索が非効率\n採択率  50% → 適度な移動距離 → 良好なバランス  \n採択率  10% → 移動がほぼ停止 → 探索が停滞\n採択率   0% → 完全に停止    → 探索不可能\n```\n\n### 🔬 理論最適値の深い意味\n\n最適採択率（1D: 44%, 高次元: 23%）は、**探索距離の2乗平均**（つまり効率）を最大化します：\n\n$$\\text{効率} = \\lim_{t \\to \\infty} \\frac{E[|X_t - X_0|^2]}{t}$$\n\nこの値は、以下の微妙なバランスの最適解：\n- **採択頻度**: 新しい場所を受け入れる頻度\n- **移動距離**: 一回の採択での移動距離\n\n採択率が高すぎると移動距離が小さく、低すぎると採択頻度が低くなります。\n\n### 🎨 視覚的理解：歩幅と軌跡パターン\n\n異なる歩幅設定での典型的なトレースプロット：\n\n```\n小さい歩幅: ~~~~~~~~ (細かい振動、局所的)\n適切な歩幅: ∩∪∩∪∩∪ (適度な起伏、広域探索)  \n大きい歩幅: ------   (平坦、停滞)\n```\n\n次のセクションで、これらの違いを実際のデータで確認してみましょう。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_step_sizes(step_sizes, n_samples=5000):\n",
    "    \"\"\"\n",
    "    異なるステップサイズでの性能比較\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for step_size in step_sizes:\n",
    "        print(f\"Testing step size: {step_size}\")\n",
    "        \n",
    "        samples, acc_rate, _ = metropolis_hastings(\n",
    "            target_log_pdf=mixture_log_pdf,\n",
    "            proposal_sampler=lambda x: random_walk_sampler(x, step_size),\n",
    "            proposal_log_pdf=symmetric_proposal_log_pdf,\n",
    "            initial_value=0.0,\n",
    "            n_samples=n_samples\n",
    "        )\n",
    "        \n",
    "        # 有効サンプルサイズの計算（自己相関を考慮）\n",
    "        from statsmodels.tsa.stattools import acf\n",
    "        burnin = n_samples // 5\n",
    "        autocorr = acf(samples[burnin:], nlags=min(200, len(samples[burnin:])//4), fft=True)\n",
    "        \n",
    "        # 最初に0.05を下回るラグを見つける\n",
    "        tau_int = 1\n",
    "        for lag in range(1, len(autocorr)):\n",
    "            if autocorr[lag] < 0.05:\n",
    "                tau_int = lag\n",
    "                break\n",
    "        \n",
    "        eff_sample_size = len(samples[burnin:]) / (2 * tau_int + 1)\n",
    "        \n",
    "        results[step_size] = {\n",
    "            'samples': samples,\n",
    "            'acceptance_rate': acc_rate,\n",
    "            'autocorr_time': tau_int,\n",
    "            'eff_sample_size': eff_sample_size,\n",
    "            'efficiency': eff_sample_size * acc_rate  # 総合効率の指標\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 異なるステップサイズで比較\n",
    "step_sizes = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "comparison_results = compare_step_sizes(step_sizes)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"\\n=== Step Size Comparison ===\")\n",
    "print(f\"{'Step Size':<10} {'Acc Rate':<10} {'Autocorr':<10} {'Eff Size':<12} {'Efficiency':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for step_size in step_sizes:\n",
    "    result = comparison_results[step_size]\n",
    "    print(f\"{step_size:<10.1f} {result['acceptance_rate']:<10.3f} \"\n",
    "          f\"{result['autocorr_time']:<10d} {result['eff_sample_size']:<12.1f} \"\n",
    "          f\"{result['efficiency']:<12.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ステップサイズ比較の包括的可視化\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\n\n# パフォーマンス指標の抽出\nstep_sizes_plot = list(comparison_results.keys())\nacc_rates = [comparison_results[s]['acceptance_rate'] for s in step_sizes_plot]\nautocorr_times = [comparison_results[s]['autocorr_time'] for s in step_sizes_plot]\neff_sizes = [comparison_results[s]['eff_sample_size'] for s in step_sizes_plot]\nefficiencies = [comparison_results[s]['efficiency'] for s in step_sizes_plot]\n\n# 1. 受理率 vs ステップサイズ\naxes[0, 0].semilogx(step_sizes_plot, acc_rates, 'bo-', markersize=8, linewidth=2)\naxes[0, 0].axhline(0.44, color='red', linestyle='--', alpha=0.8, linewidth=2, label='理論最適 (44%)')\naxes[0, 0].axhspan(0.2, 0.7, alpha=0.2, color='green', label='推奨範囲')\naxes[0, 0].set_xlabel('ステップサイズ', fontsize=12)\naxes[0, 0].set_ylabel('受理率', fontsize=12)\naxes[0, 0].set_title('🎯 受理率 vs ステップサイズ', fontsize=14)\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. 自己相関時間 vs ステップサイズ\naxes[0, 1].semilogx(step_sizes_plot, autocorr_times, 'go-', markersize=8, linewidth=2)\naxes[0, 1].set_xlabel('ステップサイズ', fontsize=12)\naxes[0, 1].set_ylabel('自己相関時間', fontsize=12)\naxes[0, 1].set_title('⏱️ 自己相関時間 vs ステップサイズ', fontsize=14)\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. 有効サンプルサイズ vs ステップサイズ\naxes[0, 2].semilogx(step_sizes_plot, eff_sizes, 'mo-', markersize=8, linewidth=2)\naxes[0, 2].set_xlabel('ステップサイズ', fontsize=12)\naxes[0, 2].set_ylabel('有効サンプルサイズ', fontsize=12)\naxes[0, 2].set_title('📊 有効サンプルサイズ vs ステップサイズ', fontsize=14)\naxes[0, 2].grid(True, alpha=0.3)\n\n# 4. 総合効率 vs ステップサイズ\naxes[0, 3].semilogx(step_sizes_plot, efficiencies, 'ro-', markersize=8, linewidth=2)\noptimal_idx = np.argmax(efficiencies)\naxes[0, 3].scatter(step_sizes_plot[optimal_idx], efficiencies[optimal_idx], \n                  color='gold', s=200, marker='*', zorder=5, label=f'最適値 ({step_sizes_plot[optimal_idx]})')\naxes[0, 3].set_xlabel('ステップサイズ', fontsize=12)\naxes[0, 3].set_ylabel('総合効率', fontsize=12)\naxes[0, 3].set_title('⭐ 総合効率 vs ステップサイズ', fontsize=14)\naxes[0, 3].legend()\naxes[0, 3].grid(True, alpha=0.3)\n\n# 5-8. トレースプロットの比較（最初の1000サンプル）\ncolors = ['blue', 'green', 'orange', 'red']\nstep_examples = [0.1, 0.5, 1.0, 5.0]\ntitles = ['🐌 過小ステップ (0.1)', '✅ 適切ステップ (0.5)', '⚡ やや大ステップ (1.0)', '🏃‍♂️ 過大ステップ (5.0)']\n\nfor i, (step_size, title, color) in enumerate(zip(step_examples, titles, colors)):\n    if step_size in comparison_results:\n        samples = comparison_results[step_size]['samples'][:1000]\n        acc_rate = comparison_results[step_size]['acceptance_rate']\n        autocorr = comparison_results[step_size]['autocorr_time']\n        \n        axes[1, i].plot(samples, alpha=0.8, color=color, linewidth=1)\n        axes[1, i].set_title(f'{title}\\nAcc:{acc_rate:.3f}, ACT:{autocorr}', fontsize=11)\n        axes[1, i].set_xlabel('イテレーション')\n        axes[1, i].set_ylabel('値')\n        axes[1, i].grid(True, alpha=0.3)\n\n# 9-12. ヒストグラムの比較\nx_range = np.linspace(-6, 6, 1000)\ntrue_density = np.exp(mixture_log_pdf(x_range))\n\nfor i, (step_size, color) in enumerate(zip(step_examples, colors)):\n    if step_size in comparison_results:\n        samples = comparison_results[step_size]['samples'][1000:]  # burnin除去\n        \n        axes[2, i].hist(samples, bins=50, density=True, alpha=0.7, color=color, \n                       edgecolor='black', linewidth=0.5)\n        axes[2, i].plot(x_range, true_density, 'r-', linewidth=3, label='真の分布')\n        axes[2, i].set_title(f'ステップ {step_size}: 分布比較', fontsize=11)\n        axes[2, i].set_xlabel('値')\n        axes[2, i].set_ylabel('密度')\n        axes[2, i].legend()\n\nplt.tight_layout()\nplt.suptitle('🔬 ステップサイズ最適化の包括的分析', fontsize=16, y=1.02)\nplt.show()\n\n# パフォーマンステーブルの表示\nprint(\"\\n\" + \"=\"*80)\nprint(\"📈 ステップサイズ最適化レポート\")\nprint(\"=\"*80)\nprint(f\"{'ステップ':<8} {'受理率':<8} {'自己相関':<10} {'有効サンプル':<12} {'総合効率':<10} {'評価':<15}\")\nprint(\"-\"*80)\n\nfor i, step_size in enumerate(step_sizes_plot):\n    result = comparison_results[step_size]\n    acc_rate = result['acceptance_rate']\n    \n    # 評価ロジック\n    if 0.35 <= acc_rate <= 0.55:\n        rating = \"✅ 優秀\"\n    elif 0.25 <= acc_rate <= 0.65:\n        rating = \"⚡ 良好\"\n    elif 0.15 <= acc_rate <= 0.75:\n        rating = \"⚠️ 注意\"\n    else:\n        rating = \"❌ 不良\"\n    \n    print(f\"{step_size:<8.1f} {acc_rate:<8.3f} {result['autocorr_time']:<10d} \"\n          f\"{result['eff_sample_size']:<12.1f} {result['efficiency']:<10.1f} {rating:<15}\")\n\nprint(\"-\"*80)\nprint(\"💡 最適化のガイドライン:\")\nprint(\"• 受理率 35-55%: 理想的な範囲\")\nprint(\"• 受理率 25-65%: 許容範囲\") \nprint(\"• 受理率 < 25% or > 65%: 要調整\")\nprint(\"• 自己相関時間: 小さいほど良い\")\nprint(\"• 総合効率: 受理率 × 有効サンプルサイズ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 例2：非対称な提案分布\n",
    "\n",
    "今度は非対称な提案分布を使った例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数分布からのサンプリング\n",
    "def exponential_log_pdf(x, rate=1.0):\n",
    "    \"\"\"指数分布の対数確率密度\"\"\"\n",
    "    if x < 0:\n",
    "        return -np.inf\n",
    "    return np.log(rate) - rate * x\n",
    "\n",
    "# 非対称な提案分布（対数正規分布）\n",
    "def lognormal_proposal_sampler(current, sigma=0.5):\n",
    "    \"\"\"対数正規分布による提案\"\"\"\n",
    "    return current * np.exp(np.random.normal(0, sigma))\n",
    "\n",
    "def lognormal_proposal_log_pdf(proposed, current, sigma=0.5):\n",
    "    \"\"\"対数正規提案分布の対数確率密度\"\"\"\n",
    "    if proposed <= 0 or current <= 0:\n",
    "        return -np.inf\n",
    "    log_ratio = np.log(proposed / current)\n",
    "    return -0.5 * (log_ratio / sigma)**2 - 0.5 * np.log(2 * np.pi * sigma**2) - np.log(proposed)\n",
    "\n",
    "# サンプリング実行\n",
    "rate_param = 2.0\n",
    "samples_exp, acceptance_rate_exp, _ = metropolis_hastings(\n",
    "    target_log_pdf=lambda x: exponential_log_pdf(x, rate_param),\n",
    "    proposal_sampler=lambda x: lognormal_proposal_sampler(x, 0.3),\n",
    "    proposal_log_pdf=lambda p, c: lognormal_proposal_log_pdf(p, c, 0.3),\n",
    "    initial_value=1.0,\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n指数分布サンプリング受理率: {acceptance_rate_exp:.3f}\")\n",
    "print(f\"理論平均: {1/rate_param:.3f}, サンプル平均: {np.mean(samples_exp[2000:]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数分布サンプリング結果の可視化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "burnin = 2000\n",
    "\n",
    "# トレースプロット\n",
    "axes[0, 0].plot(samples_exp[:3000], alpha=0.7)\n",
    "axes[0, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "axes[0, 0].set_title('Trace Plot')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# ヒストグラムと真の分布\n",
    "axes[0, 1].hist(samples_exp[burnin:], bins=50, density=True, alpha=0.7, \n",
    "                color='lightblue', label='MCMC samples')\n",
    "x_range = np.linspace(0, np.percentile(samples_exp[burnin:], 95), 1000)\n",
    "true_density = rate_param * np.exp(-rate_param * x_range)\n",
    "axes[0, 1].plot(x_range, true_density, 'r-', linewidth=2, label='True exponential')\n",
    "axes[0, 1].set_title('Sample Distribution vs True Distribution')\n",
    "axes[0, 1].set_xlabel('Value')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Q-Qプロット（指数分布と比較）\n",
    "from scipy.stats import probplot\n",
    "probplot(samples_exp[burnin:], dist=stats.expon, sparams=(0, 1/rate_param), plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot vs Exponential Distribution')\n",
    "\n",
    "# 累積分布関数の比較\n",
    "sorted_samples = np.sort(samples_exp[burnin:])\n",
    "empirical_cdf = np.arange(1, len(sorted_samples) + 1) / len(sorted_samples)\n",
    "theoretical_cdf = 1 - np.exp(-rate_param * sorted_samples)\n",
    "\n",
    "axes[1, 1].plot(sorted_samples, empirical_cdf, 'b-', alpha=0.7, label='Empirical CDF')\n",
    "axes[1, 1].plot(sorted_samples, theoretical_cdf, 'r-', linewidth=2, label='Theoretical CDF')\n",
    "axes[1, 1].set_title('CDF Comparison')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Cumulative Probability')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 多変量分布への拡張\n",
    "\n",
    "2次元の多変量正規分布からサンプリングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2次元多変量正規分布\n",
    "def multivariate_normal_log_pdf(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度\"\"\"\n",
    "    k = len(mu)\n",
    "    diff = x - mu\n",
    "    \n",
    "    # 数値安定性のための計算\n",
    "    try:\n",
    "        chol = np.linalg.cholesky(cov)\n",
    "        log_det = 2 * np.sum(np.log(np.diag(chol)))\n",
    "        solve = np.linalg.solve(chol, diff)\n",
    "        mahalanobis_sq = np.sum(solve**2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf\n",
    "    \n",
    "    return -0.5 * (k * np.log(2 * np.pi) + log_det + mahalanobis_sq)\n",
    "\n",
    "# 多変量提案分布\n",
    "def multivariate_proposal_sampler(current, cov_proposal):\n",
    "    \"\"\"多変量正規提案分布\"\"\"\n",
    "    return np.random.multivariate_normal(current, cov_proposal)\n",
    "\n",
    "def multivariate_proposal_log_pdf(proposed, current, cov_proposal):\n",
    "    \"\"\"多変量正規提案分布の対数確率密度（対称なので0）\"\"\"\n",
    "    return 0.0\n",
    "\n",
    "# パラメータ設定\n",
    "mu_target = np.array([1.0, 2.0])\n",
    "cov_target = np.array([[1.0, 0.7], [0.7, 2.0]])\n",
    "cov_proposal = 0.5 * np.eye(2)\n",
    "\n",
    "# サンプリング実行\n",
    "samples_mv, acceptance_rate_mv, _ = metropolis_hastings(\n",
    "    target_log_pdf=lambda x: multivariate_normal_log_pdf(x, mu_target, cov_target),\n",
    "    proposal_sampler=lambda x: multivariate_proposal_sampler(x, cov_proposal),\n",
    "    proposal_log_pdf=lambda p, c: multivariate_proposal_log_pdf(p, c, cov_proposal),\n",
    "    initial_value=np.array([0.0, 0.0]),\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n多変量正規分布サンプリング受理率: {acceptance_rate_mv:.3f}\")\n",
    "print(f\"理論平均: {mu_target}\")\n",
    "print(f\"サンプル平均: {np.mean(samples_mv[2000:], axis=0)}\")\n",
    "print(f\"理論共分散:\\n{cov_target}\")\n",
    "print(f\"サンプル共分散:\\n{np.cov(samples_mv[2000:].T)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多変量結果の可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "burnin = 2000\n",
    "samples_clean = samples_mv[burnin:]\n",
    "\n",
    "# 散布図\n",
    "axes[0, 0].scatter(samples_clean[:, 0], samples_clean[:, 1], alpha=0.6, s=1)\n",
    "axes[0, 0].set_xlabel('X1')\n",
    "axes[0, 0].set_ylabel('X2')\n",
    "axes[0, 0].set_title('Scatter Plot of Samples')\n",
    "axes[0, 0].set_aspect('equal')\n",
    "\n",
    "# 等高線プロット\n",
    "x1_range = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 50)\n",
    "x2_range = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 50)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "pos = np.dstack((X1, X2))\n",
    "\n",
    "# 真の分布の等高線\n",
    "rv = stats.multivariate_normal(mu_target, cov_target)\n",
    "axes[0, 1].contour(X1, X2, rv.pdf(pos), colors='red', alpha=0.8)\n",
    "axes[0, 1].scatter(samples_clean[::10, 0], samples_clean[::10, 1], alpha=0.3, s=1)\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].set_title('Samples with True Distribution Contours')\n",
    "\n",
    "# マージナル分布\n",
    "axes[0, 2].hist(samples_clean[:, 0], bins=50, density=True, alpha=0.7, label='X1 samples')\n",
    "x1_theory = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 100)\n",
    "axes[0, 2].plot(x1_theory, stats.norm.pdf(x1_theory, mu_target[0], np.sqrt(cov_target[0, 0])), \n",
    "                'r-', label='X1 true')\n",
    "axes[0, 2].set_title('Marginal Distribution X1')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# トレースプロット\n",
    "axes[1, 0].plot(samples_mv[:3000, 0], alpha=0.7, label='X1')\n",
    "axes[1, 0].plot(samples_mv[:3000, 1], alpha=0.7, label='X2')\n",
    "axes[1, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "axes[1, 0].set_title('Trace Plot')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 第2マージナル分布\n",
    "axes[1, 1].hist(samples_clean[:, 1], bins=50, density=True, alpha=0.7, label='X2 samples')\n",
    "x2_theory = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 100)\n",
    "axes[1, 1].plot(x2_theory, stats.norm.pdf(x2_theory, mu_target[1], np.sqrt(cov_target[1, 1])), \n",
    "                'r-', label='X2 true')\n",
    "axes[1, 1].set_title('Marginal Distribution X2')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 相関の収束\n",
    "n_points = len(samples_clean)\n",
    "window_size = n_points // 100\n",
    "correlations = []\n",
    "for i in range(window_size, n_points, window_size):\n",
    "    window_samples = samples_clean[i-window_size:i]\n",
    "    corr = np.corrcoef(window_samples[:, 0], window_samples[:, 1])[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "axes[1, 2].plot(correlations)\n",
    "true_corr = cov_target[0, 1] / np.sqrt(cov_target[0, 0] * cov_target[1, 1])\n",
    "axes[1, 2].axhline(true_corr, color='red', linestyle='--', \n",
    "                   label=f'True correlation = {true_corr:.3f}')\n",
    "axes[1, 2].set_title('Running Correlation')\n",
    "axes[1, 2].set_xlabel('Window')\n",
    "axes[1, 2].set_ylabel('Correlation')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 演習問題\n",
    "\n",
    "### 問題1：ベータ分布からのサンプリング\n",
    "ベータ分布 $\\text{Beta}(\\alpha=2, \\beta=5)$ からメトロポリス・ヘイスティングス法でサンプリングしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1の解答欄\n",
    "def beta_log_pdf(x, alpha=2, beta=5):\n",
    "    \"\"\"ベータ分布の対数確率密度\"\"\"\n",
    "    if x <= 0 or x >= 1:\n",
    "        return -np.inf\n",
    "    return (alpha - 1) * np.log(x) + (beta - 1) * np.log(1 - x)\n",
    "\n",
    "# ここに実装してください\n",
    "# ヒント：[0,1]区間に制約があるので、提案が範囲外の場合の処理が必要\n",
    "\n",
    "pass  # 学習者が実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2：最適な受理率の調査\n",
    "1次元正規分布に対して、異なるステップサイズで受理率と効率を調べ、最適な受理率（約23%）が実際に効率的かを確認しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2の解答欄\n",
    "def standard_normal_log_pdf(x):\n",
    "    return -0.5 * x**2 - 0.5 * np.log(2 * np.pi)\n",
    "\n",
    "# ここに実装してください\n",
    "# ヒント：複数のステップサイズで実験し、受理率と自己相関時間の関係を調べる\n",
    "\n",
    "pass  # 学習者が実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## まとめ：MH法マスターへの道\n\nこの章では、メトロポリス・ヘイスティングス法について以下を包括的に学習しました：\n\n### 🧠 核心的理解\n\n1. **革命的アイデア**：\n   - 正規化定数の巧妙な相殺メカニズム\n   - 詳細釣り合い条件による理論的保証\n   - 「賢いランダムウォーク」としての直感的理解\n\n2. **数学的美しさ**：\n   - 受理確率α の導出と物理学的解釈\n   - 確率比による効率的計算\n   - 対数スケールでの数値安定性\n\n### 🔧 実践的スキル\n\n3. **提案分布の設計哲学**：\n   - **ステップサイズ**: MCMCウォーカーの「歩幅」\n   - **最適受理率**: 1D→44%, 高次元→23%の理論的根拠\n   - **効率指標**: 自己相関時間と有効サンプルサイズ\n\n4. **性能診断の体系**：\n   - トレースプロット：混合と収束の視覚的確認\n   - 受理率モニタリング：リアルタイム性能評価\n   - 分布比較：理論値との整合性検証\n\n### 🚀 実装における重要ポイント\n\n**技術的ベストプラクティス:**\n- **対数スケール計算**: 数値アンダーフロー回避\n- **対称性の活用**: 計算コスト削減\n- **境界条件の処理**: 制約付き分布での実装\n- **適応的調整**: 受理率に基づく自動チューニング\n\n**設計哲学:**\n- **汎用性**: あらゆる連続分布に適用可能\n- **堅牢性**: パラメータ誤設定に対する許容度\n- **拡張性**: 高次元問題への自然な拡張\n\n### 🎯 応用戦略\n\n**分布特性に応じた戦略:**\n- **単峰性分布**: 標準的ランダムウォーク\n- **多峰性分布**: 大きめステップサイズ\n- **制約付き分布**: 境界反射または変数変換\n- **高次元分布**: 成分別更新またはブロック更新\n\n### 🔮 次のステップ\n\nMH法をマスターしたあなたは、MCMCの**基盤技術**を完全に理解しました。\n\n**Chapter 3（ギブス サンプリング）**では：\n- MH法の**特殊化による効率化**\n- 条件付き分布の活用戦略\n- 高次元問題での実用的解決策\n- 階層ベイズモデルでの威力\n\n**Chapter 4（収束診断）**では：\n- MH法の**品質保証システム**\n- 自動診断による信頼性向上\n- 実際の研究での活用法\n\n### 💡 重要な哲学\n\n> MH法は「完璧な解」を求めるのではなく、「十分に良い近似」を効率的に得る手法です。この哲学は、現代のデータサイエンス全体に通じる重要な考え方です。\n\n**記憶すべき金言:**\n- 「受理率44%は拒絶を恐れない勇気の証」\n- 「完璧な提案より、適切な提案を継続する」\n- 「収束は目標ではなく、探索の質を示す指標」\n\nあなたは今、MCMCの心臓部であるMH法を使いこなせるようになりました。次はより洗練された手法で、さらに高い効率を追求していきましょう！"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}