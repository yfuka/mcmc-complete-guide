{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: メトロポリス・ヘイスティングス法\n",
    "\n",
    "## 学習目標\n",
    "- メトロポリス・ヘイスティングス法のアルゴリズムを理解する\n",
    "- 受理確率の導出と意味を学ぶ\n",
    "- 提案分布の選択とその影響を理解する\n",
    "- 実装と性能評価方法を習得する\n",
    "- 様々な分布からのサンプリング例を実践する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 メトロポリス・ヘイスティングス法の基本原理\n",
    "\n",
    "メトロポリス・ヘイスティングス法（MH法）は、目標分布$\\pi(x)$からサンプリングを行うために、以下の手順を繰り返します：\n",
    "\n",
    "### アルゴリズム\n",
    "1. 現在の状態を$x^{(t)}$とする\n",
    "2. 提案分布$q(x'|x^{(t)})$から新しい状態$x'$を提案\n",
    "3. 受理確率を計算：\n",
    "   $$\\alpha = \\min\\left(1, \\frac{\\pi(x')q(x^{(t)}|x')}{\\pi(x^{(t)})q(x'|x^{(t)})}\\right)$$\n",
    "4. 確率$\\alpha$で$x'$を受理、そうでなければ$x^{(t)}$に留まる\n",
    "5. $t \\leftarrow t+1$として2に戻る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 受理確率の導出\n",
    "\n",
    "詳細釣り合い条件を満たすために：\n",
    "$$\\pi(x) P(x \\rightarrow x') = \\pi(x') P(x' \\rightarrow x)$$\n",
    "\n",
    "遷移確率を $P(x \\rightarrow x') = q(x'|x) \\alpha(x, x')$ として、\n",
    "$$\\alpha(x, x') = \\min\\left(1, \\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)$$\n",
    "\n",
    "これにより詳細釣り合い条件が満たされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 基本実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(target_log_pdf, proposal_sampler, proposal_log_pdf, \n",
    "                       initial_value, n_samples, verbose=False):\n",
    "    \"\"\"\n",
    "    メトロポリス・ヘイスティングス法の汎用実装\n",
    "    \n",
    "    Parameters:\n",
    "    - target_log_pdf: 目標分布の対数確率密度関数\n",
    "    - proposal_sampler: 提案分布からのサンプラー関数 (current_state) -> proposed_state\n",
    "    - proposal_log_pdf: 提案分布の対数確率密度関数 (proposed, current) -> log_q\n",
    "    - initial_value: 初期値\n",
    "    - n_samples: サンプル数\n",
    "    - verbose: 詳細情報の表示\n",
    "    \n",
    "    Returns:\n",
    "    - samples: サンプル配列\n",
    "    - acceptance_rate: 受理率\n",
    "    - log_probs: 各サンプルの対数確率\n",
    "    \"\"\"\n",
    "    # 初期化\n",
    "    if np.isscalar(initial_value):\n",
    "        samples = np.zeros(n_samples)\n",
    "        dim = 1\n",
    "    else:\n",
    "        samples = np.zeros((n_samples, len(initial_value)))\n",
    "        dim = len(initial_value)\n",
    "    \n",
    "    current = np.copy(initial_value)\n",
    "    current_log_prob = target_log_pdf(current)\n",
    "    n_accepted = 0\n",
    "    log_probs = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 新しい状態を提案\n",
    "        proposed = proposal_sampler(current)\n",
    "        proposed_log_prob = target_log_pdf(proposed)\n",
    "        \n",
    "        # 受理確率を計算（対数スケールで安全に計算）\n",
    "        log_alpha = (proposed_log_prob + proposal_log_pdf(current, proposed) - \n",
    "                    current_log_prob - proposal_log_pdf(proposed, current))\n",
    "        alpha = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # 受理/棄却を決定\n",
    "        if np.random.rand() < alpha:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        if dim == 1:\n",
    "            samples[i] = current\n",
    "        else:\n",
    "            samples[i] = current\n",
    "        log_probs[i] = current_log_prob\n",
    "        \n",
    "        if verbose and (i + 1) % (n_samples // 10) == 0:\n",
    "            print(f\"Progress: {i+1}/{n_samples}, Acceptance Rate: {n_accepted/(i+1):.3f}\")\n",
    "    \n",
    "    acceptance_rate = n_accepted / n_samples\n",
    "    return samples, acceptance_rate, log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 例1：混合正規分布からのサンプリング\n",
    "\n",
    "まず、1次元の混合正規分布からサンプリングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合正規分布の定義\n",
    "def mixture_log_pdf(x):\n",
    "    \"\"\"2つの正規分布の混合の対数確率密度\"\"\"\n",
    "    component1 = stats.norm.logpdf(x, -2, 0.5)\n",
    "    component2 = stats.norm.logpdf(x, 2, 1.0)\n",
    "    # log(0.3 * exp(component1) + 0.7 * exp(component2))\n",
    "    max_comp = np.maximum(component1, component2)\n",
    "    return max_comp + np.log(0.3 * np.exp(component1 - max_comp) + \n",
    "                            0.7 * np.exp(component2 - max_comp))\n",
    "\n",
    "# 対称な提案分布（ランダムウォーク）\n",
    "def random_walk_sampler(current, step_size=0.5):\n",
    "    return current + np.random.normal(0, step_size)\n",
    "\n",
    "def symmetric_proposal_log_pdf(proposed, current):\n",
    "    return 0.0  # 対称な提案分布の場合、比は1（対数で0）\n",
    "\n",
    "# サンプリング実行\n",
    "samples, acceptance_rate, log_probs = metropolis_hastings(\n",
    "    target_log_pdf=mixture_log_pdf,\n",
    "    proposal_sampler=lambda x: random_walk_sampler(x, 0.8),\n",
    "    proposal_log_pdf=symmetric_proposal_log_pdf,\n",
    "    initial_value=0.0,\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n最終受理率: {acceptance_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の可視化\n",
    "def plot_mcmc_results_1d(samples, target_log_pdf, burnin=1000, title=\"MCMC Results\"):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # トレースプロット\n",
    "    axes[0, 0].plot(samples[:2000], alpha=0.7, linewidth=0.8)\n",
    "    axes[0, 0].set_title('Trace Plot (first 2000 samples)')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Value')\n",
    "    axes[0, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # ヒストグラムと真の分布の比較\n",
    "    axes[0, 1].hist(samples[burnin:], bins=60, density=True, alpha=0.7, \n",
    "                    color='skyblue', label='MCMC samples')\n",
    "    x_range = np.linspace(samples.min(), samples.max(), 1000)\n",
    "    true_density = np.exp(target_log_pdf(x_range))\n",
    "    axes[0, 1].plot(x_range, true_density, 'r-', linewidth=2, label='True distribution')\n",
    "    axes[0, 1].set_title('Sample Distribution vs True Distribution')\n",
    "    axes[0, 1].set_xlabel('Value')\n",
    "    axes[0, 1].set_ylabel('Density')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 自己相関関数\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    lags = min(200, len(samples[burnin:]) // 10)\n",
    "    autocorr = acf(samples[burnin:], nlags=lags, fft=True)\n",
    "    axes[0, 2].plot(autocorr)\n",
    "    axes[0, 2].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].axhline(0.05, color='r', linestyle='--', alpha=0.5, label='5%')\n",
    "    axes[0, 2].axhline(-0.05, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0, 2].set_title('Autocorrelation Function')\n",
    "    axes[0, 2].set_xlabel('Lag')\n",
    "    axes[0, 2].set_ylabel('ACF')\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # 累積平均\n",
    "    cumulative_mean = np.cumsum(samples[burnin:]) / np.arange(1, len(samples[burnin:]) + 1)\n",
    "    axes[1, 0].plot(cumulative_mean)\n",
    "    true_mean = np.sum([0.3 * (-2), 0.7 * 2])  # 混合分布の理論平均\n",
    "    axes[1, 0].axhline(true_mean, color='r', linestyle='--', label=f'True mean = {true_mean:.2f}')\n",
    "    axes[1, 0].set_title('Cumulative Mean')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Mean')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 受理率の推移\n",
    "    window_size = len(samples) // 100\n",
    "    running_acceptance = []\n",
    "    for i in range(window_size, len(samples), window_size):\n",
    "        # 簡易的な受理率計算（連続する値の変化で判定）\n",
    "        window_samples = samples[i-window_size:i]\n",
    "        changes = np.sum(np.diff(window_samples) != 0)\n",
    "        running_acceptance.append(changes / window_size)\n",
    "    \n",
    "    axes[1, 1].plot(running_acceptance)\n",
    "    axes[1, 1].axhline(acceptance_rate, color='r', linestyle='--', \n",
    "                       label=f'Overall: {acceptance_rate:.3f}')\n",
    "    axes[1, 1].set_title('Running Acceptance Rate')\n",
    "    axes[1, 1].set_xlabel('Window')\n",
    "    axes[1, 1].set_ylabel('Acceptance Rate')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # QQプロット（理論分布との比較は困難なので、正規性のテスト）\n",
    "    from scipy.stats import probplot\n",
    "    probplot(samples[burnin:], dist=\"norm\", plot=axes[1, 2])\n",
    "    axes[1, 2].set_title('Q-Q Plot (vs Normal)')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mcmc_results_1d(samples, mixture_log_pdf, title=\"Mixture Gaussian Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 提案分布の影響\n",
    "\n",
    "提案分布のステップサイズが性能に与える影響を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_step_sizes(step_sizes, n_samples=5000):\n",
    "    \"\"\"\n",
    "    異なるステップサイズでの性能比較\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for step_size in step_sizes:\n",
    "        print(f\"Testing step size: {step_size}\")\n",
    "        \n",
    "        samples, acc_rate, _ = metropolis_hastings(\n",
    "            target_log_pdf=mixture_log_pdf,\n",
    "            proposal_sampler=lambda x: random_walk_sampler(x, step_size),\n",
    "            proposal_log_pdf=symmetric_proposal_log_pdf,\n",
    "            initial_value=0.0,\n",
    "            n_samples=n_samples\n",
    "        )\n",
    "        \n",
    "        # 有効サンプルサイズの計算（自己相関を考慮）\n",
    "        from statsmodels.tsa.stattools import acf\n",
    "        burnin = n_samples // 5\n",
    "        autocorr = acf(samples[burnin:], nlags=min(200, len(samples[burnin:])//4), fft=True)\n",
    "        \n",
    "        # 最初に0.05を下回るラグを見つける\n",
    "        tau_int = 1\n",
    "        for lag in range(1, len(autocorr)):\n",
    "            if autocorr[lag] < 0.05:\n",
    "                tau_int = lag\n",
    "                break\n",
    "        \n",
    "        eff_sample_size = len(samples[burnin:]) / (2 * tau_int + 1)\n",
    "        \n",
    "        results[step_size] = {\n",
    "            'samples': samples,\n",
    "            'acceptance_rate': acc_rate,\n",
    "            'autocorr_time': tau_int,\n",
    "            'eff_sample_size': eff_sample_size,\n",
    "            'efficiency': eff_sample_size * acc_rate  # 総合効率の指標\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 異なるステップサイズで比較\n",
    "step_sizes = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "comparison_results = compare_step_sizes(step_sizes)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"\\n=== Step Size Comparison ===\")\n",
    "print(f\"{'Step Size':<10} {'Acc Rate':<10} {'Autocorr':<10} {'Eff Size':<12} {'Efficiency':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for step_size in step_sizes:\n",
    "    result = comparison_results[step_size]\n",
    "    print(f\"{step_size:<10.1f} {result['acceptance_rate']:<10.3f} \"\n",
    "          f\"{result['autocorr_time']:<10d} {result['eff_sample_size']:<12.1f} \"\n",
    "          f\"{result['efficiency']:<12.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ステップサイズ比較の可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 受理率 vs ステップサイズ\n",
    "step_sizes_plot = list(comparison_results.keys())\n",
    "acc_rates = [comparison_results[s]['acceptance_rate'] for s in step_sizes_plot]\n",
    "axes[0, 0].plot(step_sizes_plot, acc_rates, 'bo-')\n",
    "axes[0, 0].axhline(0.44, color='r', linestyle='--', alpha=0.7, label='Optimal (~44%)')\n",
    "axes[0, 0].set_xlabel('Step Size')\n",
    "axes[0, 0].set_ylabel('Acceptance Rate')\n",
    "axes[0, 0].set_title('Acceptance Rate vs Step Size')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xscale('log')\n",
    "\n",
    "# 自己相関時間 vs ステップサイズ\n",
    "autocorr_times = [comparison_results[s]['autocorr_time'] for s in step_sizes_plot]\n",
    "axes[0, 1].plot(step_sizes_plot, autocorr_times, 'go-')\n",
    "axes[0, 1].set_xlabel('Step Size')\n",
    "axes[0, 1].set_ylabel('Autocorrelation Time')\n",
    "axes[0, 1].set_title('Autocorrelation Time vs Step Size')\n",
    "axes[0, 1].set_xscale('log')\n",
    "\n",
    "# 効率 vs ステップサイズ\n",
    "efficiencies = [comparison_results[s]['efficiency'] for s in step_sizes_plot]\n",
    "axes[0, 2].plot(step_sizes_plot, efficiencies, 'ro-')\n",
    "axes[0, 2].set_xlabel('Step Size')\n",
    "axes[0, 2].set_ylabel('Efficiency (Eff Size × Acc Rate)')\n",
    "axes[0, 2].set_title('Efficiency vs Step Size')\n",
    "axes[0, 2].set_xscale('log')\n",
    "\n",
    "# トレースプロットの比較（最初の1000サンプル）\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "for i, step_size in enumerate([0.1, 0.5, 2.0]):\n",
    "    samples = comparison_results[step_size]['samples'][:1000]\n",
    "    axes[1, i].plot(samples, alpha=0.7, color=colors[i])\n",
    "    axes[1, i].set_title(f'Trace: Step Size = {step_size}')\n",
    "    axes[1, i].set_xlabel('Iteration')\n",
    "    axes[1, i].set_ylabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 例2：非対称な提案分布\n",
    "\n",
    "今度は非対称な提案分布を使った例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数分布からのサンプリング\n",
    "def exponential_log_pdf(x, rate=1.0):\n",
    "    \"\"\"指数分布の対数確率密度\"\"\"\n",
    "    if x < 0:\n",
    "        return -np.inf\n",
    "    return np.log(rate) - rate * x\n",
    "\n",
    "# 非対称な提案分布（対数正規分布）\n",
    "def lognormal_proposal_sampler(current, sigma=0.5):\n",
    "    \"\"\"対数正規分布による提案\"\"\"\n",
    "    return current * np.exp(np.random.normal(0, sigma))\n",
    "\n",
    "def lognormal_proposal_log_pdf(proposed, current, sigma=0.5):\n",
    "    \"\"\"対数正規提案分布の対数確率密度\"\"\"\n",
    "    if proposed <= 0 or current <= 0:\n",
    "        return -np.inf\n",
    "    log_ratio = np.log(proposed / current)\n",
    "    return -0.5 * (log_ratio / sigma)**2 - 0.5 * np.log(2 * np.pi * sigma**2) - np.log(proposed)\n",
    "\n",
    "# サンプリング実行\n",
    "rate_param = 2.0\n",
    "samples_exp, acceptance_rate_exp, _ = metropolis_hastings(\n",
    "    target_log_pdf=lambda x: exponential_log_pdf(x, rate_param),\n",
    "    proposal_sampler=lambda x: lognormal_proposal_sampler(x, 0.3),\n",
    "    proposal_log_pdf=lambda p, c: lognormal_proposal_log_pdf(p, c, 0.3),\n",
    "    initial_value=1.0,\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n指数分布サンプリング受理率: {acceptance_rate_exp:.3f}\")\n",
    "print(f\"理論平均: {1/rate_param:.3f}, サンプル平均: {np.mean(samples_exp[2000:]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数分布サンプリング結果の可視化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "burnin = 2000\n",
    "\n",
    "# トレースプロット\n",
    "axes[0, 0].plot(samples_exp[:3000], alpha=0.7)\n",
    "axes[0, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "axes[0, 0].set_title('Trace Plot')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# ヒストグラムと真の分布\n",
    "axes[0, 1].hist(samples_exp[burnin:], bins=50, density=True, alpha=0.7, \n",
    "                color='lightblue', label='MCMC samples')\n",
    "x_range = np.linspace(0, np.percentile(samples_exp[burnin:], 95), 1000)\n",
    "true_density = rate_param * np.exp(-rate_param * x_range)\n",
    "axes[0, 1].plot(x_range, true_density, 'r-', linewidth=2, label='True exponential')\n",
    "axes[0, 1].set_title('Sample Distribution vs True Distribution')\n",
    "axes[0, 1].set_xlabel('Value')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Q-Qプロット（指数分布と比較）\n",
    "from scipy.stats import probplot\n",
    "probplot(samples_exp[burnin:], dist=stats.expon, sparams=(0, 1/rate_param), plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot vs Exponential Distribution')\n",
    "\n",
    "# 累積分布関数の比較\n",
    "sorted_samples = np.sort(samples_exp[burnin:])\n",
    "empirical_cdf = np.arange(1, len(sorted_samples) + 1) / len(sorted_samples)\n",
    "theoretical_cdf = 1 - np.exp(-rate_param * sorted_samples)\n",
    "\n",
    "axes[1, 1].plot(sorted_samples, empirical_cdf, 'b-', alpha=0.7, label='Empirical CDF')\n",
    "axes[1, 1].plot(sorted_samples, theoretical_cdf, 'r-', linewidth=2, label='Theoretical CDF')\n",
    "axes[1, 1].set_title('CDF Comparison')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Cumulative Probability')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 多変量分布への拡張\n",
    "\n",
    "2次元の多変量正規分布からサンプリングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2次元多変量正規分布\n",
    "def multivariate_normal_log_pdf(x, mu, cov):\n",
    "    \"\"\"多変量正規分布の対数確率密度\"\"\"\n",
    "    k = len(mu)\n",
    "    diff = x - mu\n",
    "    \n",
    "    # 数値安定性のための計算\n",
    "    try:\n",
    "        chol = np.linalg.cholesky(cov)\n",
    "        log_det = 2 * np.sum(np.log(np.diag(chol)))\n",
    "        solve = np.linalg.solve(chol, diff)\n",
    "        mahalanobis_sq = np.sum(solve**2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf\n",
    "    \n",
    "    return -0.5 * (k * np.log(2 * np.pi) + log_det + mahalanobis_sq)\n",
    "\n",
    "# 多変量提案分布\n",
    "def multivariate_proposal_sampler(current, cov_proposal):\n",
    "    \"\"\"多変量正規提案分布\"\"\"\n",
    "    return np.random.multivariate_normal(current, cov_proposal)\n",
    "\n",
    "def multivariate_proposal_log_pdf(proposed, current, cov_proposal):\n",
    "    \"\"\"多変量正規提案分布の対数確率密度（対称なので0）\"\"\"\n",
    "    return 0.0\n",
    "\n",
    "# パラメータ設定\n",
    "mu_target = np.array([1.0, 2.0])\n",
    "cov_target = np.array([[1.0, 0.7], [0.7, 2.0]])\n",
    "cov_proposal = 0.5 * np.eye(2)\n",
    "\n",
    "# サンプリング実行\n",
    "samples_mv, acceptance_rate_mv, _ = metropolis_hastings(\n",
    "    target_log_pdf=lambda x: multivariate_normal_log_pdf(x, mu_target, cov_target),\n",
    "    proposal_sampler=lambda x: multivariate_proposal_sampler(x, cov_proposal),\n",
    "    proposal_log_pdf=lambda p, c: multivariate_proposal_log_pdf(p, c, cov_proposal),\n",
    "    initial_value=np.array([0.0, 0.0]),\n",
    "    n_samples=10000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n多変量正規分布サンプリング受理率: {acceptance_rate_mv:.3f}\")\n",
    "print(f\"理論平均: {mu_target}\")\n",
    "print(f\"サンプル平均: {np.mean(samples_mv[2000:], axis=0)}\")\n",
    "print(f\"理論共分散:\\n{cov_target}\")\n",
    "print(f\"サンプル共分散:\\n{np.cov(samples_mv[2000:].T)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多変量結果の可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "burnin = 2000\n",
    "samples_clean = samples_mv[burnin:]\n",
    "\n",
    "# 散布図\n",
    "axes[0, 0].scatter(samples_clean[:, 0], samples_clean[:, 1], alpha=0.6, s=1)\n",
    "axes[0, 0].set_xlabel('X1')\n",
    "axes[0, 0].set_ylabel('X2')\n",
    "axes[0, 0].set_title('Scatter Plot of Samples')\n",
    "axes[0, 0].set_aspect('equal')\n",
    "\n",
    "# 等高線プロット\n",
    "x1_range = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 50)\n",
    "x2_range = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 50)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "pos = np.dstack((X1, X2))\n",
    "\n",
    "# 真の分布の等高線\n",
    "rv = stats.multivariate_normal(mu_target, cov_target)\n",
    "axes[0, 1].contour(X1, X2, rv.pdf(pos), colors='red', alpha=0.8)\n",
    "axes[0, 1].scatter(samples_clean[::10, 0], samples_clean[::10, 1], alpha=0.3, s=1)\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].set_title('Samples with True Distribution Contours')\n",
    "\n",
    "# マージナル分布\n",
    "axes[0, 2].hist(samples_clean[:, 0], bins=50, density=True, alpha=0.7, label='X1 samples')\n",
    "x1_theory = np.linspace(samples_clean[:, 0].min(), samples_clean[:, 0].max(), 100)\n",
    "axes[0, 2].plot(x1_theory, stats.norm.pdf(x1_theory, mu_target[0], np.sqrt(cov_target[0, 0])), \n",
    "                'r-', label='X1 true')\n",
    "axes[0, 2].set_title('Marginal Distribution X1')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# トレースプロット\n",
    "axes[1, 0].plot(samples_mv[:3000, 0], alpha=0.7, label='X1')\n",
    "axes[1, 0].plot(samples_mv[:3000, 1], alpha=0.7, label='X2')\n",
    "axes[1, 0].axvline(burnin, color='red', linestyle='--', alpha=0.7, label='Burn-in')\n",
    "axes[1, 0].set_title('Trace Plot')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 第2マージナル分布\n",
    "axes[1, 1].hist(samples_clean[:, 1], bins=50, density=True, alpha=0.7, label='X2 samples')\n",
    "x2_theory = np.linspace(samples_clean[:, 1].min(), samples_clean[:, 1].max(), 100)\n",
    "axes[1, 1].plot(x2_theory, stats.norm.pdf(x2_theory, mu_target[1], np.sqrt(cov_target[1, 1])), \n",
    "                'r-', label='X2 true')\n",
    "axes[1, 1].set_title('Marginal Distribution X2')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 相関の収束\n",
    "n_points = len(samples_clean)\n",
    "window_size = n_points // 100\n",
    "correlations = []\n",
    "for i in range(window_size, n_points, window_size):\n",
    "    window_samples = samples_clean[i-window_size:i]\n",
    "    corr = np.corrcoef(window_samples[:, 0], window_samples[:, 1])[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "axes[1, 2].plot(correlations)\n",
    "true_corr = cov_target[0, 1] / np.sqrt(cov_target[0, 0] * cov_target[1, 1])\n",
    "axes[1, 2].axhline(true_corr, color='red', linestyle='--', \n",
    "                   label=f'True correlation = {true_corr:.3f}')\n",
    "axes[1, 2].set_title('Running Correlation')\n",
    "axes[1, 2].set_xlabel('Window')\n",
    "axes[1, 2].set_ylabel('Correlation')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 演習問題\n",
    "\n",
    "### 問題1：ベータ分布からのサンプリング\n",
    "ベータ分布 $\\text{Beta}(\\alpha=2, \\beta=5)$ からメトロポリス・ヘイスティングス法でサンプリングしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1の解答欄\n",
    "def beta_log_pdf(x, alpha=2, beta=5):\n",
    "    \"\"\"ベータ分布の対数確率密度\"\"\"\n",
    "    if x <= 0 or x >= 1:\n",
    "        return -np.inf\n",
    "    return (alpha - 1) * np.log(x) + (beta - 1) * np.log(1 - x)\n",
    "\n",
    "# ここに実装してください\n",
    "# ヒント：[0,1]区間に制約があるので、提案が範囲外の場合の処理が必要\n",
    "\n",
    "pass  # 学習者が実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2：最適な受理率の調査\n",
    "1次元正規分布に対して、異なるステップサイズで受理率と効率を調べ、最適な受理率（約23%）が実際に効率的かを確認しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2の解答欄\n",
    "def standard_normal_log_pdf(x):\n",
    "    return -0.5 * x**2 - 0.5 * np.log(2 * np.pi)\n",
    "\n",
    "# ここに実装してください\n",
    "# ヒント：複数のステップサイズで実験し、受理率と自己相関時間の関係を調べる\n",
    "\n",
    "pass  # 学習者が実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "この章では、メトロポリス・ヘイスティングス法について以下を学習しました：\n",
    "\n",
    "1. **基本アルゴリズム**：提案→受理確率計算→受理/棄却のサイクル\n",
    "2. **受理確率の導出**：詳細釣り合い条件から導かれる公式\n",
    "3. **提案分布の重要性**：ステップサイズが性能に大きく影響\n",
    "4. **対称・非対称提案**：提案分布の選択と実装の違い\n",
    "5. **多変量への拡張**：高次元分布での適用方法\n",
    "6. **性能評価**：受理率、自己相関時間、有効サンプルサイズ\n",
    "\n",
    "### 重要なポイント\n",
    "- **最適受理率**：1次元で約44%、高次元で約23%\n",
    "- **提案分布の調整**：問題に応じた適切な選択が重要\n",
    "- **数値安定性**：対数スケールでの計算で数値誤差を防ぐ\n",
    "- **診断の重要性**：トレースプロット、自己相関、収束チェック\n",
    "\n",
    "次の章では、特別な構造を持つ多変量分布に対してより効率的なギブスサンプリングを学習します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}